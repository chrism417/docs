{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home \u00b6 Promitor is an Azure Monitor scraper which makes the metrics available for metric systems such as Atlassian Statuspage, OpenTelemetry, Prometheus and StatsD. Running Promitor Scraper \u00b6 Running Promitor Scraper is super easy: docker run -d -p 8999 :80 --name promitor-agent-scraper \\ --env PROMITOR_AUTH_APPID = '<azure-ad-app-id>' \\ --env-file C:/Promitor/az-mon-auth.creds \\ --volume C:/Promitor/metrics-declaration.yaml:/config/metrics-declaration.yaml \\ --volume C:/Promitor/runtime.yaml:/config/runtime.yaml \\ ghcr.io/tomkerkhove/promitor-agent-scraper:2.5.0 Docker image is available on GitHub Container Registry . Features \u00b6 Automatically scrapes Azure Monitor metrics (single and multi-dimensional) across various subscription & resource groups Automatically pushes metrics to systems such as Atlassian Statuspage, OpenTelemetry, Prometheus and StatsD Easy to declare metrics to scrape via metrics-as-code or automatically discover resources Built-in support for a variety of Azure services ( overview ) Easily deployable via Docker & Kubernetes Sends telemetry to container logs & Azure Application Insights Available for Linux & Windows runtimes Support for all Azure clouds And there is more on the way - Check our backlog and vote for features! Support \u00b6 Promitor is actively maintained and developed with best-effort support. We do welcome PRs that implement features from our backlog and are always happy to help you incorporate Promitor in your infrastructure, but do not provide 24/7 support. Are you having issues or feature requests? Feel free to let us know ! Support Promitor End-users \u00b6 We are proud to have the following end-users(s) running Promitor in production: Are you a Promitor user? Let us know and get listed ! Learn more about how they are using Promitor: \"Monitor Azure Resources using Promitor\" by ResDiary Thank you \u00b6 We'd like to thank the following service(s) for supporting our open-source initiative! Netlify allows us to provide previews of our documentation changes in our pull requests that make it easier to review them. But they are not the only one we'd like to thank! For a full list of services, tooling & NuGet packages that support us - Have a look at our Thank you page! License Information \u00b6 This is licensed under The MIT License (MIT). Which means that you can use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the web application. But you always need to state that Tom Kerkhove is the original author of this web application.","title":"Overview"},{"location":"#home","text":"Promitor is an Azure Monitor scraper which makes the metrics available for metric systems such as Atlassian Statuspage, OpenTelemetry, Prometheus and StatsD.","title":"Home"},{"location":"#running-promitor-scraper","text":"Running Promitor Scraper is super easy: docker run -d -p 8999 :80 --name promitor-agent-scraper \\ --env PROMITOR_AUTH_APPID = '<azure-ad-app-id>' \\ --env-file C:/Promitor/az-mon-auth.creds \\ --volume C:/Promitor/metrics-declaration.yaml:/config/metrics-declaration.yaml \\ --volume C:/Promitor/runtime.yaml:/config/runtime.yaml \\ ghcr.io/tomkerkhove/promitor-agent-scraper:2.5.0 Docker image is available on GitHub Container Registry .","title":"Running Promitor Scraper"},{"location":"#features","text":"Automatically scrapes Azure Monitor metrics (single and multi-dimensional) across various subscription & resource groups Automatically pushes metrics to systems such as Atlassian Statuspage, OpenTelemetry, Prometheus and StatsD Easy to declare metrics to scrape via metrics-as-code or automatically discover resources Built-in support for a variety of Azure services ( overview ) Easily deployable via Docker & Kubernetes Sends telemetry to container logs & Azure Application Insights Available for Linux & Windows runtimes Support for all Azure clouds And there is more on the way - Check our backlog and vote for features!","title":"Features"},{"location":"#support","text":"Promitor is actively maintained and developed with best-effort support. We do welcome PRs that implement features from our backlog and are always happy to help you incorporate Promitor in your infrastructure, but do not provide 24/7 support. Are you having issues or feature requests? Feel free to let us know ! Support Promitor","title":"Support"},{"location":"#end-users","text":"We are proud to have the following end-users(s) running Promitor in production: Are you a Promitor user? Let us know and get listed ! Learn more about how they are using Promitor: \"Monitor Azure Resources using Promitor\" by ResDiary","title":"End-users"},{"location":"#thank-you","text":"We'd like to thank the following service(s) for supporting our open-source initiative! Netlify allows us to provide previews of our documentation changes in our pull requests that make it easier to review them. But they are not the only one we'd like to thank! For a full list of services, tooling & NuGet packages that support us - Have a look at our Thank you page!","title":"Thank you"},{"location":"#license-information","text":"This is licensed under The MIT License (MIT). Which means that you can use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the web application. But you always need to state that Tom Kerkhove is the original author of this web application.","title":"License Information"},{"location":"faq/","text":"Frequently asked questions (FAQs) \u00b6 Here are a list of questions you may have: Are multi-dimensional metrics supported? How does Promitor handle deleted resources? Is scraping multiple subscriptions supported? What Azure clouds are supported? Why does Azure Blob & File Storage only report account-level information? Why does my multi-dimensional metric report label value unknown with Prometheus? What operating systems are supported? Are multi-dimensional metrics supported? \u00b6 Yes, every scraper supports scraping multi-dimensional metrics except for Azure Storage queues. You can configure the dimension(s) you are interested in via azureMetricConfiguration.dimensions , for more information see our 'Metrics Declaration' page . However, you can only use it with metrics in Azure Monitor that support this, for a complete overview we recommend reading the official documentation . How does Promitor handle deleted resources? \u00b6 The approach depends if you are using declarative metrics or resource discovery but we highly recommend to enable Prometheus metric timestamps in our runtime configuration to indicate how old the metric is. When using declarative metrics \u00b6 Promitor will scrape all resources that are configured and report the metrics accordingly. If that resource is deleted, we will still serve the metrics as long as we can until it is no longer available and exceptions will be thrown . We recommend to update the metrics declaration when a resource is deleted to avoid polluting logs. When using resource discovery \u00b6 Promitor will automatically discover all matching resources which means that it will automatically scrape metrics for new/removed resources . Removed resources will immediately stop being scraped by Promitor, but still be reported in Prometheus scrape endpoint. Is scraping multiple subscriptions supported? \u00b6 No, we do not support scraping multiple subscriptions as of today as we consider that to be a security boundary. However, you can deploy multiple instances of Promitor that each scrape another subscription. We have it on our backlog to see if there is enough demand for it, feel free to give a . If that is the case, we will reconsider this limitation. What Azure clouds are supported? \u00b6 We support Global (default), China , UsGov & Germany Azure clouds. This can be configured in the metric configuration under azureMetadata . For more information see our 'Metric Configuration' page . Why does Azure Blob & File Storage only report account-level information? \u00b6 Azure Monitor currently only provides account-level metrics which we can serve. As part of #450 & #446 we plan to provide the capability to have more granular information. Why does my multi-dimensional metric report label value unknown with Prometheus? \u00b6 When Promitor is unable to find a metric for a multi-dimensional metric, it will report unknown for the dimension label given it was not able to determine what the dimension value is due to the lack of metrics. You can read more about it in our Prometheus sink documentation . What operating systems are supported? \u00b6 We support running on both Linux & Windows platforms.","title":"FAQ"},{"location":"faq/#frequently-asked-questions-faqs","text":"Here are a list of questions you may have: Are multi-dimensional metrics supported? How does Promitor handle deleted resources? Is scraping multiple subscriptions supported? What Azure clouds are supported? Why does Azure Blob & File Storage only report account-level information? Why does my multi-dimensional metric report label value unknown with Prometheus? What operating systems are supported?","title":"Frequently asked questions (FAQs)"},{"location":"faq/#are-multi-dimensional-metrics-supported","text":"Yes, every scraper supports scraping multi-dimensional metrics except for Azure Storage queues. You can configure the dimension(s) you are interested in via azureMetricConfiguration.dimensions , for more information see our 'Metrics Declaration' page . However, you can only use it with metrics in Azure Monitor that support this, for a complete overview we recommend reading the official documentation .","title":"Are multi-dimensional metrics supported?"},{"location":"faq/#how-does-promitor-handle-deleted-resources","text":"The approach depends if you are using declarative metrics or resource discovery but we highly recommend to enable Prometheus metric timestamps in our runtime configuration to indicate how old the metric is.","title":"How does Promitor handle deleted resources?"},{"location":"faq/#when-using-declarative-metrics","text":"Promitor will scrape all resources that are configured and report the metrics accordingly. If that resource is deleted, we will still serve the metrics as long as we can until it is no longer available and exceptions will be thrown . We recommend to update the metrics declaration when a resource is deleted to avoid polluting logs.","title":"When using declarative metrics"},{"location":"faq/#when-using-resource-discovery","text":"Promitor will automatically discover all matching resources which means that it will automatically scrape metrics for new/removed resources . Removed resources will immediately stop being scraped by Promitor, but still be reported in Prometheus scrape endpoint.","title":"When using resource discovery"},{"location":"faq/#is-scraping-multiple-subscriptions-supported","text":"No, we do not support scraping multiple subscriptions as of today as we consider that to be a security boundary. However, you can deploy multiple instances of Promitor that each scrape another subscription. We have it on our backlog to see if there is enough demand for it, feel free to give a . If that is the case, we will reconsider this limitation.","title":"Is scraping multiple subscriptions supported?"},{"location":"faq/#what-azure-clouds-are-supported","text":"We support Global (default), China , UsGov & Germany Azure clouds. This can be configured in the metric configuration under azureMetadata . For more information see our 'Metric Configuration' page .","title":"What Azure clouds are supported?"},{"location":"faq/#why-does-azure-blob-file-storage-only-report-account-level-information","text":"Azure Monitor currently only provides account-level metrics which we can serve. As part of #450 & #446 we plan to provide the capability to have more granular information.","title":"Why does Azure Blob &amp; File Storage only report account-level information?"},{"location":"faq/#why-does-my-multi-dimensional-metric-report-label-value-unknown-with-prometheus","text":"When Promitor is unable to find a metric for a multi-dimensional metric, it will report unknown for the dimension label given it was not able to determine what the dimension value is due to the lack of metrics. You can read more about it in our Prometheus sink documentation .","title":"Why does my multi-dimensional metric report label value unknown with Prometheus?"},{"location":"faq/#what-operating-systems-are-supported","text":"We support running on both Linux & Windows platforms.","title":"What operating systems are supported?"},{"location":"how-it-works/","text":"How it works \u00b6 Promitor is an Azure Monitor scraper which makes the metrics available to a variety of metric systems such as Atlassian Statuspage, OpenTelemetry, Prometheus and StatsD. Scraping Azure Monitor metrics \u00b6 When you want to scrape resources, you can use Promitor Scraper which uses a metrics-as-code approach. By writing a metric declaration, you will define what Azure Monitor metrics to scrape for a set of Azure resources and to what metric sink(s) they should be reported. Here's an overview of how it works: Using resource discovery \u00b6 While Promitor Scraper uses a declarative approach for defining Azure resources to scrape; as of Promitor Scraper 2.0 you can integrate with Promitor Resource Discovery ! With resource discovery, you can define resource discovery groups that represent Azure resources of a given type and optionally define criteria for the resources to comply with. By doing this, you can change your metric declaration for Promitor Scraper so that, instead of using declared resources, reference a resource discovery group which be used to determine what Azure resources it should scrape metrics for. Behind the scenes, Promitor Resource Discovery integrates with Azure Resource Graph which will query your Azure landscape to discover the corresponding resources. Here's an overview of how they work together: You can easily start discovering resources automatically: Declare resource discovery groups ( link ) Deploy Promitor Resource Discovery ( link ) Configure Promitor Scraper to use resource discovery ( link ) Deploy Promitor Scraper ( link ) What components do agents provide? \u00b6 Every Promitor agent provides a REST API which which you can integrate and uses background jobs to acquire the data to reduce latency. Here's a detailed overview: (*) Resources are still discovered synchronously but this will be implemented in Promitor Resource Discovery v0.2. \u2190 back","title":"How It Works"},{"location":"how-it-works/#how-it-works","text":"Promitor is an Azure Monitor scraper which makes the metrics available to a variety of metric systems such as Atlassian Statuspage, OpenTelemetry, Prometheus and StatsD.","title":"How it works"},{"location":"how-it-works/#scraping-azure-monitor-metrics","text":"When you want to scrape resources, you can use Promitor Scraper which uses a metrics-as-code approach. By writing a metric declaration, you will define what Azure Monitor metrics to scrape for a set of Azure resources and to what metric sink(s) they should be reported. Here's an overview of how it works:","title":"Scraping Azure Monitor metrics"},{"location":"how-it-works/#using-resource-discovery","text":"While Promitor Scraper uses a declarative approach for defining Azure resources to scrape; as of Promitor Scraper 2.0 you can integrate with Promitor Resource Discovery ! With resource discovery, you can define resource discovery groups that represent Azure resources of a given type and optionally define criteria for the resources to comply with. By doing this, you can change your metric declaration for Promitor Scraper so that, instead of using declared resources, reference a resource discovery group which be used to determine what Azure resources it should scrape metrics for. Behind the scenes, Promitor Resource Discovery integrates with Azure Resource Graph which will query your Azure landscape to discover the corresponding resources. Here's an overview of how they work together: You can easily start discovering resources automatically: Declare resource discovery groups ( link ) Deploy Promitor Resource Discovery ( link ) Configure Promitor Scraper to use resource discovery ( link ) Deploy Promitor Scraper ( link )","title":"Using resource discovery"},{"location":"how-it-works/#what-components-do-agents-provide","text":"Every Promitor agent provides a REST API which which you can integrate and uses background jobs to acquire the data to reduce latency. Here's a detailed overview: (*) Resources are still discovered synchronously but this will be implemented in Promitor Resource Discovery v0.2. \u2190 back","title":"What components do agents provide?"},{"location":"tags/","text":"Tags \u00b6 Following is a list of relevant tags: API \u00b6 Azure API Management Azure App Plan Automation \u00b6 Azure Automation account Caching \u00b6 Azure Cache for Redis Azure Cache for Redis Enterprise Containers \u00b6 Azure Container Instances Azure Container Registry Azure Kubernetes Service Data \u00b6 Azure Blob Storage Azure Cosmos DB Azure Data Factory Azure Data Share Azure File Storage Azure Log Analytics Azure Database for MariaDB Azure Database for MySQL Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Storage Queue Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) IaaS \u00b6 Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Integration \u00b6 Azure API Management Azure Data Factory Azure Logic Apps Azure Service Bus Namespace IoT \u00b6 Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Kubernetes \u00b6 Azure Kubernetes Service Messaging \u00b6 Azure Event Hubs Azure Service Bus Namespace Monitoring \u00b6 Azure Application Insights Azure Monitor Autoscale Networking \u00b6 Azure Application Gateway Azure Express Route Circuit Azure Front Door Azure Load Balancer Azure Network Gateway Azure Network Interface Azure Virtual Network Open Source \u00b6 Azure Cosmos DB Azure Event Hubs Azure Kubernetes Service Azure Database for MariaDB Azure Database for MySQL Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise PaaS \u00b6 Azure API Management Azure App Plan Azure Data Factory Azure Function App Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Logic Apps Azure SQL Database Azure SQL Elastic Pool Azure Web App Resource Discovery \u00b6 Azure API Management Azure App Plan Azure Application Gateway Azure Application Insights Azure Automation account Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Event Hubs Azure Express Route Circuit Azure File Storage Azure Front Door Azure Function App Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Logic Apps Azure Database for MariaDB Azure Monitor Autoscale Azure Database for MySQL Azure Network Gateway Azure Network Interface Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Azure Virtual Network Azure Web App SQL \u00b6 Azure Cosmos DB Azure Database for MySQL Azure Database for PostgreSQL Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Scraper \u00b6 Azure API Management Azure App Plan Azure Application Gateway Azure Application Insights Azure Automation account Azure Blob Storage Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Event Hubs Azure Express Route Circuit Azure File Storage Azure Front Door Azure Function App Generic Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Log Analytics Azure Logic Apps Azure Database for MariaDB Azure Monitor Autoscale Azure Database for MySQL Azure Network Gateway Azure Network Interface Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Storage Queue Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Azure Virtual Network Azure Web App Security \u00b6 Azure Key Vault Serverless \u00b6 Azure Function App Storage \u00b6 Azure Blob Storage Azure File Storage Azure Storage Account Azure Storage Queue Synapse \u00b6 Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Web \u00b6 Azure App Plan","title":"Tags"},{"location":"tags/#tags","text":"Following is a list of relevant tags:","title":"Tags"},{"location":"tags/#api","text":"Azure API Management Azure App Plan","title":"API"},{"location":"tags/#automation","text":"Azure Automation account","title":"Automation"},{"location":"tags/#caching","text":"Azure Cache for Redis Azure Cache for Redis Enterprise","title":"Caching"},{"location":"tags/#containers","text":"Azure Container Instances Azure Container Registry Azure Kubernetes Service","title":"Containers"},{"location":"tags/#data","text":"Azure Blob Storage Azure Cosmos DB Azure Data Factory Azure Data Share Azure File Storage Azure Log Analytics Azure Database for MariaDB Azure Database for MySQL Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Storage Queue Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace)","title":"Data"},{"location":"tags/#iaas","text":"Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM)","title":"IaaS"},{"location":"tags/#integration","text":"Azure API Management Azure Data Factory Azure Logic Apps Azure Service Bus Namespace","title":"Integration"},{"location":"tags/#iot","text":"Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub","title":"IoT"},{"location":"tags/#kubernetes","text":"Azure Kubernetes Service","title":"Kubernetes"},{"location":"tags/#messaging","text":"Azure Event Hubs Azure Service Bus Namespace","title":"Messaging"},{"location":"tags/#monitoring","text":"Azure Application Insights Azure Monitor Autoscale","title":"Monitoring"},{"location":"tags/#networking","text":"Azure Application Gateway Azure Express Route Circuit Azure Front Door Azure Load Balancer Azure Network Gateway Azure Network Interface Azure Virtual Network","title":"Networking"},{"location":"tags/#open-source","text":"Azure Cosmos DB Azure Event Hubs Azure Kubernetes Service Azure Database for MariaDB Azure Database for MySQL Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise","title":"Open Source"},{"location":"tags/#paas","text":"Azure API Management Azure App Plan Azure Data Factory Azure Function App Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Logic Apps Azure SQL Database Azure SQL Elastic Pool Azure Web App","title":"PaaS"},{"location":"tags/#resource-discovery","text":"Azure API Management Azure App Plan Azure Application Gateway Azure Application Insights Azure Automation account Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Event Hubs Azure Express Route Circuit Azure File Storage Azure Front Door Azure Function App Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Logic Apps Azure Database for MariaDB Azure Monitor Autoscale Azure Database for MySQL Azure Network Gateway Azure Network Interface Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Azure Virtual Network Azure Web App","title":"Resource Discovery"},{"location":"tags/#sql","text":"Azure Cosmos DB Azure Database for MySQL Azure Database for PostgreSQL Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server","title":"SQL"},{"location":"tags/#scraper","text":"Azure API Management Azure App Plan Azure Application Gateway Azure Application Insights Azure Automation account Azure Blob Storage Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Event Hubs Azure Express Route Circuit Azure File Storage Azure Front Door Azure Function App Generic Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Log Analytics Azure Logic Apps Azure Database for MariaDB Azure Monitor Autoscale Azure Database for MySQL Azure Network Gateway Azure Network Interface Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Storage Queue Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Azure Virtual Network Azure Web App","title":"Scraper"},{"location":"tags/#security","text":"Azure Key Vault","title":"Security"},{"location":"tags/#serverless","text":"Azure Function App","title":"Serverless"},{"location":"tags/#storage","text":"Azure Blob Storage Azure File Storage Azure Storage Account Azure Storage Queue","title":"Storage"},{"location":"tags/#synapse","text":"Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace)","title":"Synapse"},{"location":"tags/#web","text":"Azure App Plan","title":"Web"},{"location":"thank-you/","text":"Thank you! \u00b6 We'd like to thank the following service(s) for supporting our open-source initiative! Automation \u00b6 Here is an overview of the services that are so kind to support us: Azure Pipelines allows us to build automated process for building our Docker image and pushing it to Docker Hub, create GitHub release and more without manual intervention. CLA Assistant automates the process of signing our Contribution License Agreement (CLA). CloudFlare serves our documentation super fast via their fast global Content Delivery Network. Codefactor for continuously monitoring our code styling. Microsoft for providing Azure credits for open-source projects. ( Learn more ) Netlify allows us to provide previews of our documentation changes in our pull requests that make it easier to review them. Renovate saves us time and reduces risk by automating the tedious process of updating dependencies. Scarf for helping us host our container images reliably. Snyk continuously monitors our documentation, application & Docker image and lets you quickly respond when new vulnerabilities are disclosed. GitHub Apps \u00b6 We are using the following GitHub Apps: Semantic Pull Requests - Ensure PRs are using a consistent approach. Task list completed - Ensures all task lists in our PRs are completed. Triage New Issues - Automatically tag new issues & PRs with triage label. Request Info - Requests more info from newly opened Pull Requests and Issues. YAMBURGER - Finds YAML syntax errors. Reminders - Set reminders on Issues and Pull Requests. Check TODO - Check TODO allows you to discover added/edited TODO items in your code, when a Pull Request is created/updated. ImgBot - Optimizing images across our repo. Stale - Closes abandoned issues after a period of inactivity. WIP - Do Not Merge \u2013 as a service. NuGet Packages \u00b6 Here is an overview of the NuGet packages that we rely on: NetEscapades.Configuration.Yaml YAML configuration provider for .NET Core CronScheduler.AspNetCore Asp.Net Core 2.x Hosted or .Net Core 2.x Self-hosted Cron Scheduler Swashbuckle.AspNetCore Swagger tools for documenting API's built on ASP.NET Core Prometheus.Client .NET client for prometheus.io spectre.console - A library that makes it easier to create beautiful console applications. Humanizer - Humanizer meets all your .NET needs for manipulating and displaying strings, enums, dates, times, timespans, numbers and quantities YamlDotNet - .NET library for YAML Guard.NET - Library that facilitates runtime checks of code and allows to define preconditions and invariants within a method Cronos - Fully-featured .NET library for working with Cron expressions. Built with time zones in mind and intuitively handles daylight saving time transitions Bogus - A simple and sane data generator for populating objects xUnit - Free, open source, community-focused unit testing tool for the .NET","title":"Thank You"},{"location":"thank-you/#thank-you","text":"We'd like to thank the following service(s) for supporting our open-source initiative!","title":"Thank you!"},{"location":"thank-you/#automation","text":"Here is an overview of the services that are so kind to support us: Azure Pipelines allows us to build automated process for building our Docker image and pushing it to Docker Hub, create GitHub release and more without manual intervention. CLA Assistant automates the process of signing our Contribution License Agreement (CLA). CloudFlare serves our documentation super fast via their fast global Content Delivery Network. Codefactor for continuously monitoring our code styling. Microsoft for providing Azure credits for open-source projects. ( Learn more ) Netlify allows us to provide previews of our documentation changes in our pull requests that make it easier to review them. Renovate saves us time and reduces risk by automating the tedious process of updating dependencies. Scarf for helping us host our container images reliably. Snyk continuously monitors our documentation, application & Docker image and lets you quickly respond when new vulnerabilities are disclosed.","title":"Automation"},{"location":"thank-you/#github-apps","text":"We are using the following GitHub Apps: Semantic Pull Requests - Ensure PRs are using a consistent approach. Task list completed - Ensures all task lists in our PRs are completed. Triage New Issues - Automatically tag new issues & PRs with triage label. Request Info - Requests more info from newly opened Pull Requests and Issues. YAMBURGER - Finds YAML syntax errors. Reminders - Set reminders on Issues and Pull Requests. Check TODO - Check TODO allows you to discover added/edited TODO items in your code, when a Pull Request is created/updated. ImgBot - Optimizing images across our repo. Stale - Closes abandoned issues after a period of inactivity. WIP - Do Not Merge \u2013 as a service.","title":"GitHub Apps"},{"location":"thank-you/#nuget-packages","text":"Here is an overview of the NuGet packages that we rely on: NetEscapades.Configuration.Yaml YAML configuration provider for .NET Core CronScheduler.AspNetCore Asp.Net Core 2.x Hosted or .Net Core 2.x Self-hosted Cron Scheduler Swashbuckle.AspNetCore Swagger tools for documenting API's built on ASP.NET Core Prometheus.Client .NET client for prometheus.io spectre.console - A library that makes it easier to create beautiful console applications. Humanizer - Humanizer meets all your .NET needs for manipulating and displaying strings, enums, dates, times, timespans, numbers and quantities YamlDotNet - .NET library for YAML Guard.NET - Library that facilitates runtime checks of code and allows to define preconditions and invariants within a method Cronos - Fully-featured .NET library for working with Cron expressions. Built with time zones in mind and intuitively handles daylight saving time transitions Bogus - A simple and sane data generator for populating objects xUnit - Free, open source, community-focused unit testing tool for the .NET","title":"NuGet Packages"},{"location":"deployment/","text":"Deployment \u00b6 Here is an overview of the Promitor agents you can deploy: Deploying Promitor Scraper Deploying Promitor Resource Discovery Image Tagging Strategy \u00b6 Depending on your scenario you might need a different update cadence for Docker dependencies. We provide a few options by offering multiple Docker tags: latest - Ideal for experimentation and proof-of-concepts, but not recommended for running production workloads. {major}.{minor} - Representation of a specific feature set, but will be updated with feature & security patches. {major}.{minor}.{patch} - Run a specific version of the runtime. (Alternative could be to use image digest pinning ) All of the above tags are available for Linux. Every tag can be suffixed with -linux or -windows to target a specific OS. You can also pin to a specific digest of an image to ensure that you are running the same image across your infrastructure. However, you will not receive security patches unless you use a tool like Renovate to keep them up-to-date . \u2190 back","title":"Overview"},{"location":"deployment/#deployment","text":"Here is an overview of the Promitor agents you can deploy: Deploying Promitor Scraper Deploying Promitor Resource Discovery","title":"Deployment"},{"location":"deployment/#image-tagging-strategy","text":"Depending on your scenario you might need a different update cadence for Docker dependencies. We provide a few options by offering multiple Docker tags: latest - Ideal for experimentation and proof-of-concepts, but not recommended for running production workloads. {major}.{minor} - Representation of a specific feature set, but will be updated with feature & security patches. {major}.{minor}.{patch} - Run a specific version of the runtime. (Alternative could be to use image digest pinning ) All of the above tags are available for Linux. Every tag can be suffixed with -linux or -windows to target a specific OS. You can also pin to a specific digest of an image to ensure that you are running the same image across your infrastructure. However, you will not receive security patches unless you use a tool like Renovate to keep them up-to-date . \u2190 back","title":"Image Tagging Strategy"},{"location":"deployment/resource-discovery/","text":"","title":"Overview"},{"location":"deployment/resource-discovery/docker/","text":"Docker \u00b6 \u276f docker run -d -p 9999 :80 --name promitor-agent-resource-discovery \\ --env PROMITOR_AUTH_APPID = '<azure-ad-app-id>' \\ --env-file C:/Promitor/promitor-discovery-auth.creds \\ --volume C:/Promitor/resource-discovery-declaration.yaml:/config/resource-discovery-declaration.yaml \\ --volume C:/Promitor/resource-discovery-runtime.yaml:/config/runtime.yaml \\ ghcr.io/tomkerkhove/promitor-agent-resource-discovery","title":"Docker"},{"location":"deployment/resource-discovery/docker/#docker","text":"\u276f docker run -d -p 9999 :80 --name promitor-agent-resource-discovery \\ --env PROMITOR_AUTH_APPID = '<azure-ad-app-id>' \\ --env-file C:/Promitor/promitor-discovery-auth.creds \\ --volume C:/Promitor/resource-discovery-declaration.yaml:/config/resource-discovery-declaration.yaml \\ --volume C:/Promitor/resource-discovery-runtime.yaml:/config/runtime.yaml \\ ghcr.io/tomkerkhove/promitor-agent-resource-discovery","title":"Docker"},{"location":"deployment/resource-discovery/kubernetes/","text":"Kubernetes \u00b6 We provide a Helm Chart which deploys all the required infrastructure on your Kubernetes cluster. Getting the Helm Chart \u00b6 Install the Promitor Chart repository: \u276f helm repo add promitor https://charts.promitor.io/ Refresh your local Chart repositories: \u276f helm repo update If all goes well you should be able to list all Promitor charts: \u276f helm search hub promitor URL CHART VERSION APP VERSION DESCRIPTION https://hub.helm.sh/charts/promitor/promitor-ag... 2 .0.0-preview-3 2 .0.0-preview-3 Promitor, bringing Azure Monitor metrics where ... Using our Helm Chart \u00b6 You can easily install our Resource Discovery Agent as following: \u276f helm install promitor-agent-resource-discovery promitor/promitor-agent-resource-discovery \\ --set azureAuthentication.appId = '<azure-ad-app-id>' \\ --set azureAuthentication.appKey = '<azure-ad-app-key>' \\ --values /path/to/helm-configuration.yaml Next to Azure authentication, a resource discovery declaration must be provided through --values . Here is an example of resource discovery declaration which you can pass: azureLandscape : cloud : Global tenantId : e0372f7f-a362-47fb-9631-74a5c4ba8bbf subscriptionIds : - 0329dd2a-59dc-4493-aa54-cb01cb027dc2 resourceDiscoveryGroups : - name : api-gateways type : ApiManagement Our Helm chart provides a variety of configuration options which you can explore in our full values file . to see all configurable values. Sample configuration \u00b6 Want to get started easily? Here's a sample configuration to spin up the Resource Discovery agent which will be publicly exposed outside of the cluster on promitor-resource-discovery-sample.westeurope.cloudapp.azure.com:8889/api/docs/index.html. azureAuthentication : appId : 67882a00-21d3-4ee7-b32a-430ea0768cd3 appKey : <hidden> azureLandscape : cloud : Global tenantId : e0372f7f-a362-47fb-9631-74a5c4ba8bbf subscriptionIds : - 0329dd2a-59dc-4493-aa54-cb01cb027dc2 - 0f9d7fea-99e8-4768-8672-06a28514f77e resourceDiscoveryGroups : - name : service-bus-landscape type : ServiceBusQueue - name : api-gateways type : ApiManagement - name : app-plan-landscape type : AppPlan - name : container-instances type : ContainerInstance - name : container-registry-landscape type : ContainerRegistry - name : cosmos-accounts type : CosmosDb - name : dps type : DeviceProvisioningService - name : event-hubs-landscape type : EventHubs service : loadBalancer : dnsPrefix : promitor-resource-discovery-sample enabled : true telemetry : defaultLogLevel : information You can easily deploy it by passing the file through --values during installation. \u2190 back","title":"Kubernetes"},{"location":"deployment/resource-discovery/kubernetes/#kubernetes","text":"We provide a Helm Chart which deploys all the required infrastructure on your Kubernetes cluster.","title":"Kubernetes"},{"location":"deployment/resource-discovery/kubernetes/#getting-the-helm-chart","text":"Install the Promitor Chart repository: \u276f helm repo add promitor https://charts.promitor.io/ Refresh your local Chart repositories: \u276f helm repo update If all goes well you should be able to list all Promitor charts: \u276f helm search hub promitor URL CHART VERSION APP VERSION DESCRIPTION https://hub.helm.sh/charts/promitor/promitor-ag... 2 .0.0-preview-3 2 .0.0-preview-3 Promitor, bringing Azure Monitor metrics where ...","title":"Getting the Helm Chart"},{"location":"deployment/resource-discovery/kubernetes/#using-our-helm-chart","text":"You can easily install our Resource Discovery Agent as following: \u276f helm install promitor-agent-resource-discovery promitor/promitor-agent-resource-discovery \\ --set azureAuthentication.appId = '<azure-ad-app-id>' \\ --set azureAuthentication.appKey = '<azure-ad-app-key>' \\ --values /path/to/helm-configuration.yaml Next to Azure authentication, a resource discovery declaration must be provided through --values . Here is an example of resource discovery declaration which you can pass: azureLandscape : cloud : Global tenantId : e0372f7f-a362-47fb-9631-74a5c4ba8bbf subscriptionIds : - 0329dd2a-59dc-4493-aa54-cb01cb027dc2 resourceDiscoveryGroups : - name : api-gateways type : ApiManagement Our Helm chart provides a variety of configuration options which you can explore in our full values file . to see all configurable values.","title":"Using our Helm Chart"},{"location":"deployment/resource-discovery/kubernetes/#sample-configuration","text":"Want to get started easily? Here's a sample configuration to spin up the Resource Discovery agent which will be publicly exposed outside of the cluster on promitor-resource-discovery-sample.westeurope.cloudapp.azure.com:8889/api/docs/index.html. azureAuthentication : appId : 67882a00-21d3-4ee7-b32a-430ea0768cd3 appKey : <hidden> azureLandscape : cloud : Global tenantId : e0372f7f-a362-47fb-9631-74a5c4ba8bbf subscriptionIds : - 0329dd2a-59dc-4493-aa54-cb01cb027dc2 - 0f9d7fea-99e8-4768-8672-06a28514f77e resourceDiscoveryGroups : - name : service-bus-landscape type : ServiceBusQueue - name : api-gateways type : ApiManagement - name : app-plan-landscape type : AppPlan - name : container-instances type : ContainerInstance - name : container-registry-landscape type : ContainerRegistry - name : cosmos-accounts type : CosmosDb - name : dps type : DeviceProvisioningService - name : event-hubs-landscape type : EventHubs service : loadBalancer : dnsPrefix : promitor-resource-discovery-sample enabled : true telemetry : defaultLogLevel : information You can easily deploy it by passing the file through --values during installation. \u2190 back","title":"Sample configuration"},{"location":"deployment/scraper/","text":"Deploying Promitor Scraper \u00b6 Here is an overview of how you can deploy Promitor on your infrastructure, we support both Linux and Windows. You can learn more about our Helm chart on artifacthub.io . For more information about advanced configuration, read our documentation here .","title":"Overview"},{"location":"deployment/scraper/#deploying-promitor-scraper","text":"Here is an overview of how you can deploy Promitor on your infrastructure, we support both Linux and Windows. You can learn more about our Helm chart on artifacthub.io . For more information about advanced configuration, read our documentation here .","title":"Deploying Promitor Scraper"},{"location":"deployment/scraper/docker/","text":"Docker \u00b6 \u276f docker run -d -p 8999 :80 --name promitor-agent-scraper \\ --env PROMITOR_AUTH_APPID = '<azure-ad-app-id>' \\ --env-file C:/Promitor/az-mon-auth.creds \\ --volume C:/Promitor/metrics-declaration.yaml:/config/metrics-declaration.yaml \\ --volume C:/Promitor/runtime.yaml:/config/runtime.yaml \\ ghcr.io/tomkerkhove/promitor-agent-scraper","title":"Docker"},{"location":"deployment/scraper/docker/#docker","text":"\u276f docker run -d -p 8999 :80 --name promitor-agent-scraper \\ --env PROMITOR_AUTH_APPID = '<azure-ad-app-id>' \\ --env-file C:/Promitor/az-mon-auth.creds \\ --volume C:/Promitor/metrics-declaration.yaml:/config/metrics-declaration.yaml \\ --volume C:/Promitor/runtime.yaml:/config/runtime.yaml \\ ghcr.io/tomkerkhove/promitor-agent-scraper","title":"Docker"},{"location":"deployment/scraper/kubernetes/","text":"Kubernetes \u00b6 We provide a Helm Chart which deploys all the required infrastructure on your Kubernetes cluster. Getting the Helm Chart \u00b6 Install the Promitor Chart repository: \u276f helm repo add promitor https://charts.promitor.io/ Refresh your local Chart repositories: \u276f helm repo update If all goes well you should be able to list all Promitor charts: \u276f helm search hub promitor URL CHART VERSION APP VERSION DESCRIPTION https://hub.helm.sh/charts/promitor/promitor-ag... 1 .6.0 1 .6.1 A Helm chart to deploy Promitor, an Azure Monit... Using our Helm Chart \u00b6 To use this, you will need to provide parameters via --set or --values . Included here are the values that correspond with the local environment variables. In addition to these, you will need a metric declaration file as described in Metric Declaration . azureMetadata : tenantId : \"<azure-tenant-id>\" subscriptionId : \"<azure-subscription-id>\" runtime : metricSinks : atlassianStatuspage : enabled : true pageId : \"ABC\" systemMetricMapping : - id : nfkgnrwpn545 promitorMetricName : promitor_demo_appplan_percentage_cpu openTelemetryCollector : collectorUri : http://<dns>:4317 prometheusScrapingEndpoint : enabled : true baseUriPath : /metrics enableMetricTimestamps : True statsd : enabled : true host : graphite port : 8125 metricPrefix : poc.promitor. telemetry : applicationInsights : enabled : True key : \"<azure-app-insights-key>\" metrics : - name : promitor_demo_servicebusqueue_queue_size description : \"Amount of active messages of the 'orders' queue (determined with ServiceBusQueue provider)\" resourceType : ServiceBusQueue namespace : promitor-messaging queueName : orders azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Average Check the full values file to see all configurable values. If you have a metric-declaration.yaml file, you can create a basic deployment with this command: \u276f helm install promitor-agent-scraper promitor/promitor-agent-scraper \\ --set azureAuthentication.appId = '<azure-ad-app-id>' \\ --set azureAuthentication.appKey = '<azure-ad-app-key>' \\ --values /path/to/helm-configuration.yaml \u2190 back","title":"Kubernetes"},{"location":"deployment/scraper/kubernetes/#kubernetes","text":"We provide a Helm Chart which deploys all the required infrastructure on your Kubernetes cluster.","title":"Kubernetes"},{"location":"deployment/scraper/kubernetes/#getting-the-helm-chart","text":"Install the Promitor Chart repository: \u276f helm repo add promitor https://charts.promitor.io/ Refresh your local Chart repositories: \u276f helm repo update If all goes well you should be able to list all Promitor charts: \u276f helm search hub promitor URL CHART VERSION APP VERSION DESCRIPTION https://hub.helm.sh/charts/promitor/promitor-ag... 1 .6.0 1 .6.1 A Helm chart to deploy Promitor, an Azure Monit...","title":"Getting the Helm Chart"},{"location":"deployment/scraper/kubernetes/#using-our-helm-chart","text":"To use this, you will need to provide parameters via --set or --values . Included here are the values that correspond with the local environment variables. In addition to these, you will need a metric declaration file as described in Metric Declaration . azureMetadata : tenantId : \"<azure-tenant-id>\" subscriptionId : \"<azure-subscription-id>\" runtime : metricSinks : atlassianStatuspage : enabled : true pageId : \"ABC\" systemMetricMapping : - id : nfkgnrwpn545 promitorMetricName : promitor_demo_appplan_percentage_cpu openTelemetryCollector : collectorUri : http://<dns>:4317 prometheusScrapingEndpoint : enabled : true baseUriPath : /metrics enableMetricTimestamps : True statsd : enabled : true host : graphite port : 8125 metricPrefix : poc.promitor. telemetry : applicationInsights : enabled : True key : \"<azure-app-insights-key>\" metrics : - name : promitor_demo_servicebusqueue_queue_size description : \"Amount of active messages of the 'orders' queue (determined with ServiceBusQueue provider)\" resourceType : ServiceBusQueue namespace : promitor-messaging queueName : orders azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Average Check the full values file to see all configurable values. If you have a metric-declaration.yaml file, you can create a basic deployment with this command: \u276f helm install promitor-agent-scraper promitor/promitor-agent-scraper \\ --set azureAuthentication.appId = '<azure-ad-app-id>' \\ --set azureAuthentication.appKey = '<azure-ad-app-key>' \\ --values /path/to/helm-configuration.yaml \u2190 back","title":"Using our Helm Chart"},{"location":"operations/","text":"Operating Promitor \u00b6 Here is an overview of how you can operate Promitor. Health Consuming the health endpoint Discovery Subscription Resource Groups Performance Scraping Prometheus endpoint Scraping Azure Monitor System Consuming the System endpoint Exploring our REST APIs Integrations Azure Resource Manager API - Consumption & Throttling Azure Resource Graph Azure Monitor","title":"Overview"},{"location":"operations/#operating-promitor","text":"Here is an overview of how you can operate Promitor. Health Consuming the health endpoint Discovery Subscription Resource Groups Performance Scraping Prometheus endpoint Scraping Azure Monitor System Consuming the System endpoint Exploring our REST APIs Integrations Azure Resource Manager API - Consumption & Throttling Azure Resource Graph Azure Monitor","title":"Operating Promitor"},{"location":"operations/discovery/","text":"Discovery \u00b6 Promitor Resource Discovery provides a way to discover the resources for our Scraper agent to dynamically scrape resources. Next to that, it provides a variety of system metrics that provides information concerning your Azure landscape. Subscription \u00b6 Our promitor_azure_landscape_subscription_info metrics provides an overview of all the Azure subscriptions that Promitor is able to discover in your Azure Landscape. It provides the following tags with more information: tenant_id - Id of the Azure tenant subscription_name - Name of the Azure subscription subscription_id - Id of the Azure subscription state - Indication of the state of the subscription ( docs ) spending_limit - Indication whether or not there is a spending limit quota_id - Id of the Azure subscription used to manage quotas authorization - Type of authorization that is being used # HELP promitor_azure_landscape_subscription_info Provides information concerning the Azure subscriptions in the landscape that Promitor has access to. # TYPE promitor_azure_landscape_subscription_info gauge promitor_azure_landscape_subscription_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_name=\"Windows Azure MSDN - Visual Studio Ultimate\",subscription_id=\"0329dd2a-59dc-4493-aa54-cb01cb027dc2\",state=\"Enabled\",spending_limit=\"On\",quota_id=\"MSDN_2014-09-01\",authorization=\"RoleBased\"} 1 1628779903451 promitor_azure_landscape_subscription_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_name=\"Visual Studio Enterprise\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",state=\"Enabled\",spending_limit=\"Off\",quota_id=\"Sponsored_2016-01-01\",authorization=\"RoleBased\"} 1 1628779903451 Resource Groups \u00b6 Our promitor_azure_landscape_resource_group_info metrics provides an overview of all the Azure resource groups that Promitor is able to discover in your Azure Landscape across all your subscriptions. It provides the following tags with more information: tenant_id - Id of the Azure tenant subscription_id - Id of the Azure subscription resource_group_name - Name of the Azure resource group region - Region in which the resource group is located provisioning_state - State of the resource group managed_by - Id of the Azure resource managing this resource group, for example an Azure Kubernetes Service cluster. # HELP promitor_azure_landscape_resource_group_info Provides information concerning the Azure resource groups in the landscape that Promitor has access to. # TYPE promitor_azure_landscape_resource_group_info gauge promitor_azure_landscape_resource_group_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",resource_group_name=\"NetworkWatcherRG\",region=\"westeurope\",provisioning_state=\"Succeeded\",managed_by=\"n/a\"} 1 1628779903423 promitor_azure_landscape_resource_group_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",resource_group_name=\"promitor-testing-resource-discovery-eu\",region=\"westeurope\",provisioning_state=\"Succeeded\",managed_by=\"n/a\"} 1 1628779903423 promitor_azure_landscape_resource_group_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",resource_group_name=\"MC_keda-demos_keda-demos_westeurope\",region=\"westeurope\",provisioning_state=\"Succeeded\",managed_by=\"/subscriptions/0f9d7fea-99e8-4768-8672-06a28514f77e/resourcegroups/keda-demos/providers/Microsoft.ContainerService/managedClusters/keda-demos\"} 1 1628779903423","title":"Resource Discovery"},{"location":"operations/discovery/#discovery","text":"Promitor Resource Discovery provides a way to discover the resources for our Scraper agent to dynamically scrape resources. Next to that, it provides a variety of system metrics that provides information concerning your Azure landscape.","title":"Discovery"},{"location":"operations/discovery/#subscription","text":"Our promitor_azure_landscape_subscription_info metrics provides an overview of all the Azure subscriptions that Promitor is able to discover in your Azure Landscape. It provides the following tags with more information: tenant_id - Id of the Azure tenant subscription_name - Name of the Azure subscription subscription_id - Id of the Azure subscription state - Indication of the state of the subscription ( docs ) spending_limit - Indication whether or not there is a spending limit quota_id - Id of the Azure subscription used to manage quotas authorization - Type of authorization that is being used # HELP promitor_azure_landscape_subscription_info Provides information concerning the Azure subscriptions in the landscape that Promitor has access to. # TYPE promitor_azure_landscape_subscription_info gauge promitor_azure_landscape_subscription_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_name=\"Windows Azure MSDN - Visual Studio Ultimate\",subscription_id=\"0329dd2a-59dc-4493-aa54-cb01cb027dc2\",state=\"Enabled\",spending_limit=\"On\",quota_id=\"MSDN_2014-09-01\",authorization=\"RoleBased\"} 1 1628779903451 promitor_azure_landscape_subscription_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_name=\"Visual Studio Enterprise\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",state=\"Enabled\",spending_limit=\"Off\",quota_id=\"Sponsored_2016-01-01\",authorization=\"RoleBased\"} 1 1628779903451","title":"Subscription"},{"location":"operations/discovery/#resource-groups","text":"Our promitor_azure_landscape_resource_group_info metrics provides an overview of all the Azure resource groups that Promitor is able to discover in your Azure Landscape across all your subscriptions. It provides the following tags with more information: tenant_id - Id of the Azure tenant subscription_id - Id of the Azure subscription resource_group_name - Name of the Azure resource group region - Region in which the resource group is located provisioning_state - State of the resource group managed_by - Id of the Azure resource managing this resource group, for example an Azure Kubernetes Service cluster. # HELP promitor_azure_landscape_resource_group_info Provides information concerning the Azure resource groups in the landscape that Promitor has access to. # TYPE promitor_azure_landscape_resource_group_info gauge promitor_azure_landscape_resource_group_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",resource_group_name=\"NetworkWatcherRG\",region=\"westeurope\",provisioning_state=\"Succeeded\",managed_by=\"n/a\"} 1 1628779903423 promitor_azure_landscape_resource_group_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",resource_group_name=\"promitor-testing-resource-discovery-eu\",region=\"westeurope\",provisioning_state=\"Succeeded\",managed_by=\"n/a\"} 1 1628779903423 promitor_azure_landscape_resource_group_info{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",resource_group_name=\"MC_keda-demos_keda-demos_westeurope\",region=\"westeurope\",provisioning_state=\"Succeeded\",managed_by=\"/subscriptions/0f9d7fea-99e8-4768-8672-06a28514f77e/resourcegroups/keda-demos/providers/Microsoft.ContainerService/managedClusters/keda-demos\"} 1 1628779903423","title":"Resource Groups"},{"location":"operations/health/","text":"Health \u00b6 Promitor provides a basic health endpoint that indicates the state of the scraper. Health endpoints can be useful for monitoring the scraper, running sanity tests after deployments or use it for sending liveness / health probes. Consuming the health endpoint \u00b6 You can check the status with a simple GET : \u276f curl -i -X GET \"http://<uri>/api/v1/health\" Health is currently indicated via the HTTP response status: 200 OK - The scraper is healthy 503 Service Unavailable - The scraper is unhealthy The endpoint provides more details on integration with following dependencies: Promitor Resource Discovery (when configured)","title":"Health"},{"location":"operations/health/#health","text":"Promitor provides a basic health endpoint that indicates the state of the scraper. Health endpoints can be useful for monitoring the scraper, running sanity tests after deployments or use it for sending liveness / health probes.","title":"Health"},{"location":"operations/health/#consuming-the-health-endpoint","text":"You can check the status with a simple GET : \u276f curl -i -X GET \"http://<uri>/api/v1/health\" Health is currently indicated via the HTTP response status: 200 OK - The scraper is healthy 503 Service Unavailable - The scraper is unhealthy The endpoint provides more details on integration with following dependencies: Promitor Resource Discovery (when configured)","title":"Consuming the health endpoint"},{"location":"operations/integrations/","text":"Integrations \u00b6 Azure Resource Manager API - Consumption & Throttling \u00b6 Promitor exposes runtime metrics to provide insights on the API consumption of Azure Resource Manager API: promitor_ratelimit_arm - Indication how many calls are still available before Azure Resource Manager is going to throttle us. Metric provides following labels: tenant_id - Id of the tenant that is being interacted with subscription_id - Id of the subscription that is being interacted with app_id - Id of the application that is being used to interact with API promitor_ratelimit_arm_throttled - Indication whether or not we are being throttled by Azure Resource Manager (ARM). Metric provides following labels: tenant_id - Id of the tenant that is being interacted with subscription_id - Id of the subscription that is being interacted with app_id - Id of the application that is being used to interact with API # HELP promitor_ratelimit_arm Indication how many calls are still available before Azure Resource Manager (ARM) is going to throttle us. # TYPE promitor_ratelimit_arm gauge promitor_ratelimit_arm{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0329dd2a-59dc-4493-aa54-cb01cb027dc2\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 11995 1629719527020 promitor_ratelimit_arm{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 11989 1629719532626 # HELP promitor_ratelimit_arm_throttled Indication concerning Azure Resource Manager are being throttled. (1 = yes, 0 = no). # TYPE promitor_ratelimit_arm_throttled gauge promitor_ratelimit_arm_throttled{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0329dd2a-59dc-4493-aa54-cb01cb027dc2\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 0 1629719527020 promitor_ratelimit_arm_throttled{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 0 1629719532626 You can read more about the Azure Resource Manager limitations on docs.microsoft.com . Azure Resource Graph \u00b6 Promitor exposes runtime metrics to provide insights on the API consumption of Azure Resource Graph: promitor_ratelimit_resource_graph_remaining - Indication how many calls are still available before Azure Resource Manager is going to throttle us. Metric provides following labels: tenant_id - Id of the tenant that is being interacted with cloud - Name of the cloud auth_mode - Authentication mode to authenticate with app_id - Id of the application that is being used to interact with promitor_ratelimit_resource_graph_throttled - Indication whether or not we are being throttled by Azure Resource Graph. Metric provides following labels: tenant_id - Id of the tenant that is being interacted with cloud - Name of the cloud auth_mode - Authentication mode to authenticate with app_id - Id of the application that is being used to interact with # HELP promitor_ratelimit_resource_graph_remaining Indication how many calls are still available before Azure Resource Graph is going to throttle us. # TYPE promitor_ratelimit_resource_graph_remaining gauge promitor_ratelimit_resource_graph_remaining{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",cloud=\"Global\",auth_mode=\"ServicePrincipal\",app_id=\"67882a00-21d3-4ee7-b32a-430ea0768cd3\"} 9 1629719863738 # HELP promitor_ratelimit_resource_graph_throttled Indication concerning Azure Resource Graph are being throttled. (1 = yes, 0 = no). # TYPE promitor_ratelimit_resource_graph_throttled gauge promitor_ratelimit_resource_graph_throttled{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",cloud=\"Global\",auth_mode=\"ServicePrincipal\",app_id=\"67882a00-21d3-4ee7-b32a-430ea0768cd3\"} 0 1629719863738 You can read more about the Azure Resource Graph throttling on docs.microsoft.com . Azure Monitor \u00b6 Promitor interacts with Azure Monitor API to scrape all the required metrics. During troubleshooting it can be interesting to gain insights on what the API returns, for which you can opt-in. You can opt-in for it by configuring the runtime telemetry . \u2190 back","title":"Integrations"},{"location":"operations/integrations/#integrations","text":"","title":"Integrations"},{"location":"operations/integrations/#azure-resource-manager-api-consumption-throttling","text":"Promitor exposes runtime metrics to provide insights on the API consumption of Azure Resource Manager API: promitor_ratelimit_arm - Indication how many calls are still available before Azure Resource Manager is going to throttle us. Metric provides following labels: tenant_id - Id of the tenant that is being interacted with subscription_id - Id of the subscription that is being interacted with app_id - Id of the application that is being used to interact with API promitor_ratelimit_arm_throttled - Indication whether or not we are being throttled by Azure Resource Manager (ARM). Metric provides following labels: tenant_id - Id of the tenant that is being interacted with subscription_id - Id of the subscription that is being interacted with app_id - Id of the application that is being used to interact with API # HELP promitor_ratelimit_arm Indication how many calls are still available before Azure Resource Manager (ARM) is going to throttle us. # TYPE promitor_ratelimit_arm gauge promitor_ratelimit_arm{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0329dd2a-59dc-4493-aa54-cb01cb027dc2\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 11995 1629719527020 promitor_ratelimit_arm{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 11989 1629719532626 # HELP promitor_ratelimit_arm_throttled Indication concerning Azure Resource Manager are being throttled. (1 = yes, 0 = no). # TYPE promitor_ratelimit_arm_throttled gauge promitor_ratelimit_arm_throttled{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0329dd2a-59dc-4493-aa54-cb01cb027dc2\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 0 1629719527020 promitor_ratelimit_arm_throttled{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",app_id=\"ceb249a3-44ce-4c90-8863-6776336f5b7e\"} 0 1629719532626 You can read more about the Azure Resource Manager limitations on docs.microsoft.com .","title":"Azure Resource Manager API - Consumption &amp; Throttling"},{"location":"operations/integrations/#azure-resource-graph","text":"Promitor exposes runtime metrics to provide insights on the API consumption of Azure Resource Graph: promitor_ratelimit_resource_graph_remaining - Indication how many calls are still available before Azure Resource Manager is going to throttle us. Metric provides following labels: tenant_id - Id of the tenant that is being interacted with cloud - Name of the cloud auth_mode - Authentication mode to authenticate with app_id - Id of the application that is being used to interact with promitor_ratelimit_resource_graph_throttled - Indication whether or not we are being throttled by Azure Resource Graph. Metric provides following labels: tenant_id - Id of the tenant that is being interacted with cloud - Name of the cloud auth_mode - Authentication mode to authenticate with app_id - Id of the application that is being used to interact with # HELP promitor_ratelimit_resource_graph_remaining Indication how many calls are still available before Azure Resource Graph is going to throttle us. # TYPE promitor_ratelimit_resource_graph_remaining gauge promitor_ratelimit_resource_graph_remaining{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",cloud=\"Global\",auth_mode=\"ServicePrincipal\",app_id=\"67882a00-21d3-4ee7-b32a-430ea0768cd3\"} 9 1629719863738 # HELP promitor_ratelimit_resource_graph_throttled Indication concerning Azure Resource Graph are being throttled. (1 = yes, 0 = no). # TYPE promitor_ratelimit_resource_graph_throttled gauge promitor_ratelimit_resource_graph_throttled{tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\",cloud=\"Global\",auth_mode=\"ServicePrincipal\",app_id=\"67882a00-21d3-4ee7-b32a-430ea0768cd3\"} 0 1629719863738 You can read more about the Azure Resource Graph throttling on docs.microsoft.com .","title":"Azure Resource Graph"},{"location":"operations/integrations/#azure-monitor","text":"Promitor interacts with Azure Monitor API to scrape all the required metrics. During troubleshooting it can be interesting to gain insights on what the API returns, for which you can opt-in. You can opt-in for it by configuring the runtime telemetry . \u2190 back","title":"Azure Monitor"},{"location":"operations/performance/","text":"Performance \u00b6 You can easily monitor the performance of Promitor through the following Prometheus metrics: promitor_runtime_dotnet_collection_count_total - Provides information related to garbage collection count per generation promitor_runtime_dotnet_totalmemory - Provides information related to total known allocated memory promitor_runtime_process_cpu_seconds_total - Provides information related to total user & system CPU time spent in seconds promitor_runtime_process_virtual_bytes - Provides information related to virtual memory size promitor_runtime_process_working_set - Provides information related to process working set promitor_runtime_process_private_bytes - Provides information related to process private memory size promitor_runtime_process_num_threads - Provides information related to total number of threads promitor_runtime_process_processid - Provides information related to process ID promitor_runtime_process_start_time_seconds - Provides information related to the start time of the process since unix epoch in seconds promitor_runtime_http_request_duration_seconds - Provides information related to the performance of HTTP routes and outcomes # HELP promitor_runtime_http_request_duration_seconds duration histogram of http responses labeled with: status_code, method, path # TYPE promitor_runtime_http_request_duration_seconds histogram promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.005\"} 30 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.01\"} 31 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.025\"} 31 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.05\"} 32 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.075\"} 33 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.1\"} 33 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.25\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.5\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.75\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"1\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"2.5\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"5\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"7.5\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"10\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"+Inf\"} 34 promitor_runtime_http_request_duration_seconds_sum{status_code=\"200\",method=\"GET\",path=\"/scrape\"} 0.27116070000000003 promitor_runtime_http_request_duration_seconds_count{status_code=\"200\",method=\"GET\",path=\"/scrape\"} 34 Scraping Prometheus endpoint \u00b6 Every Promitor agent supports exposing Prometheus metrics: Resource Discovery agent - Exposed on /metrics endpoint Scraper agent - Exposed through Prometheus metric sink ( docs ) Scraping Azure Monitor \u00b6 You can easily monitor the performance of Promitor Scraper agent integrating with Azure Monitor through the following Prometheus metrics: promitor_scrape_error - Provides indication of all configured metrics that were unable to be scraped in Azure Monitor # HELP promitor_scrape_error Provides an indication that the scraping of the resource has failed # TYPE promitor_scrape_error gauge promitor_scrape_error{metric_name=\"promitor_demo_app_insights_dependency_duration_200_OK\",resource_group=\"docker-hub-metrics\",resource_name=\"Microsoft.Insights/Components/docker-hub-metrics\",resource_type=\"Generic\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\"} 1 1623691623231 promitor_scrape_success - Provides indication of all configured metrics that were successfully scraped and reported in the configured metric sinks # HELP promitor_scrape_success Provides an indication that the scraping of the resource was successful # TYPE promitor_scrape_success gauge promitor_scrape_success{metric_name=\"promitor_demo_automation_update_deployment_machine_runs\",resource_group=\"promitor-sources\",resource_name=\"promitor-sandbox\",resource_type=\"AutomationAccount\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\"} 1 1623691626335","title":"Performance"},{"location":"operations/performance/#performance","text":"You can easily monitor the performance of Promitor through the following Prometheus metrics: promitor_runtime_dotnet_collection_count_total - Provides information related to garbage collection count per generation promitor_runtime_dotnet_totalmemory - Provides information related to total known allocated memory promitor_runtime_process_cpu_seconds_total - Provides information related to total user & system CPU time spent in seconds promitor_runtime_process_virtual_bytes - Provides information related to virtual memory size promitor_runtime_process_working_set - Provides information related to process working set promitor_runtime_process_private_bytes - Provides information related to process private memory size promitor_runtime_process_num_threads - Provides information related to total number of threads promitor_runtime_process_processid - Provides information related to process ID promitor_runtime_process_start_time_seconds - Provides information related to the start time of the process since unix epoch in seconds promitor_runtime_http_request_duration_seconds - Provides information related to the performance of HTTP routes and outcomes # HELP promitor_runtime_http_request_duration_seconds duration histogram of http responses labeled with: status_code, method, path # TYPE promitor_runtime_http_request_duration_seconds histogram promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.005\"} 30 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.01\"} 31 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.025\"} 31 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.05\"} 32 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.075\"} 33 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.1\"} 33 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.25\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.5\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"0.75\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"1\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"2.5\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"5\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"7.5\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"10\"} 34 promitor_runtime_http_request_duration_seconds_bucket{status_code=\"200\",method=\"GET\",path=\"/scrape\",le=\"+Inf\"} 34 promitor_runtime_http_request_duration_seconds_sum{status_code=\"200\",method=\"GET\",path=\"/scrape\"} 0.27116070000000003 promitor_runtime_http_request_duration_seconds_count{status_code=\"200\",method=\"GET\",path=\"/scrape\"} 34","title":"Performance"},{"location":"operations/performance/#scraping-prometheus-endpoint","text":"Every Promitor agent supports exposing Prometheus metrics: Resource Discovery agent - Exposed on /metrics endpoint Scraper agent - Exposed through Prometheus metric sink ( docs )","title":"Scraping Prometheus endpoint"},{"location":"operations/performance/#scraping-azure-monitor","text":"You can easily monitor the performance of Promitor Scraper agent integrating with Azure Monitor through the following Prometheus metrics: promitor_scrape_error - Provides indication of all configured metrics that were unable to be scraped in Azure Monitor # HELP promitor_scrape_error Provides an indication that the scraping of the resource has failed # TYPE promitor_scrape_error gauge promitor_scrape_error{metric_name=\"promitor_demo_app_insights_dependency_duration_200_OK\",resource_group=\"docker-hub-metrics\",resource_name=\"Microsoft.Insights/Components/docker-hub-metrics\",resource_type=\"Generic\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\"} 1 1623691623231 promitor_scrape_success - Provides indication of all configured metrics that were successfully scraped and reported in the configured metric sinks # HELP promitor_scrape_success Provides an indication that the scraping of the resource was successful # TYPE promitor_scrape_success gauge promitor_scrape_success{metric_name=\"promitor_demo_automation_update_deployment_machine_runs\",resource_group=\"promitor-sources\",resource_name=\"promitor-sandbox\",resource_type=\"AutomationAccount\",subscription_id=\"0f9d7fea-99e8-4768-8672-06a28514f77e\",tenant_id=\"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\"} 1 1623691626335","title":"Scraping Azure Monitor"},{"location":"operations/system/","text":"System \u00b6 Promitor provides a basic system endpoint that provides information about itself such as its version. Consuming the System endpoint \u00b6 You can check the status with a simple GET : \u276f curl -i -X GET \"http://<uri>/api/v1/system\" Exploring our REST APIs \u00b6 We provide API documentation to make it easier for you to consume our REST APIs them: OpenAPI 3.0 format You can explore it with OpenAPI UI on /api/docs You can find the raw documentation on /api/v1/docs.json Swagger 2.0 format You can explore it with Swagger UI on /swagger You can find the raw documentation on /swagger/v1/swagger.json","title":"System"},{"location":"operations/system/#system","text":"Promitor provides a basic system endpoint that provides information about itself such as its version.","title":"System"},{"location":"operations/system/#consuming-the-system-endpoint","text":"You can check the status with a simple GET : \u276f curl -i -X GET \"http://<uri>/api/v1/system\"","title":"Consuming the System endpoint"},{"location":"operations/system/#exploring-our-rest-apis","text":"We provide API documentation to make it easier for you to consume our REST APIs them: OpenAPI 3.0 format You can explore it with OpenAPI UI on /api/docs You can find the raw documentation on /api/v1/docs.json Swagger 2.0 format You can explore it with Swagger UI on /swagger You can find the raw documentation on /swagger/v1/swagger.json","title":"Exploring our REST APIs"},{"location":"resource-discovery/declaring-resource-discovery-groups/","text":"Declaring resource discovery groups \u00b6 Promitor Resource Discovery allows you to declare the Azure landscape to explore and define resource discovery groups in YAML. Resource discovery groups represent a group of Azure resources of a given type that can be scraped by Promitor Scraper and supports an extensive list of supported services. As part of the resource discovery group declaration, you can choose to filter resources by adding inclusion criteria that resources must comply with based on: Subscription - Defines a subset of subscriptions defined in the Azure landscape Resource Group - Defines a list of resource groups which contains the resources. Tags - Defines a list of Azure tags with which the resources have to be annotated. Regions - Defines a list of Azure regions in which the regions the resources are located. Here is an example of a full declaration: version : v1 azureLandscape : tenantId : e0372f7f-a362-47fb-9631-74a5c4ba8bbf subscriptions : - SUBSCRIPTON-ID-ABC - SUBSCRIPTON-ID-DEF - SUBSCRIPTON-ID-GHI cloud : China resourceDiscoveryGroups : - name : container-registry-landscape type : ContainerRegistry - name : filtered-logic-apps-landscape type : LogicApp criteria : include : subscriptions : - SUBSCRIPTON-ID-ABC - SUBSCRIPTON-ID-GHI resourceGroups : - promitor-resource-group-1 - promitor-resource-group-2 tags : app : promitor-1|promitor-2 region : europe regions : - northeurope - westeurope Specification \u00b6 As Promitor evolves we need to change the structure of our resource discovery declaration. version: {version} - Version of declaration that is used. Allowed values are v1 . (Required) Azure Landscape \u00b6 azureLandscape.tenantId - The id of the Azure tenant that will be queried. (Required) azureLandscape.subscriptions - List of Azure subscriptions in the Azure tenant to discover resources in. (Required) azureLandscape.cloud - The name of the Azure cloud to use. Options are Global (default), China , UsGov & Germany . Resource Discovery Groups \u00b6 Every resource discovery group that is being declared needs to define the following fields: name - Name of the resource discovery group which will be used in metrics declaration of Promitor Scraper. (Required) type - Type of Azure resources that must be discovered, see \"Supported Azure Services\" for a full list of supported types. (Required) criteria - Criteria to fine-tune discovered resource. Criteria \u00b6 As of now, we only allow to define criteria that resources have to meet before they are included in the resource discovery group: subscriptions - A list of subscription(s) in which the resource is allowed to be located. resourceGroups - A list of resource group(s) in which the resource is allowed to be located. tags - A list of Azure tags and the expected values (exact or regular expression) with which the resources have to be annotated. (Uses or ) regions - A list of Azure region(s) in which the resource is allowed to be located.","title":"Declaring resource discovery groups"},{"location":"resource-discovery/declaring-resource-discovery-groups/#declaring-resource-discovery-groups","text":"Promitor Resource Discovery allows you to declare the Azure landscape to explore and define resource discovery groups in YAML. Resource discovery groups represent a group of Azure resources of a given type that can be scraped by Promitor Scraper and supports an extensive list of supported services. As part of the resource discovery group declaration, you can choose to filter resources by adding inclusion criteria that resources must comply with based on: Subscription - Defines a subset of subscriptions defined in the Azure landscape Resource Group - Defines a list of resource groups which contains the resources. Tags - Defines a list of Azure tags with which the resources have to be annotated. Regions - Defines a list of Azure regions in which the regions the resources are located. Here is an example of a full declaration: version : v1 azureLandscape : tenantId : e0372f7f-a362-47fb-9631-74a5c4ba8bbf subscriptions : - SUBSCRIPTON-ID-ABC - SUBSCRIPTON-ID-DEF - SUBSCRIPTON-ID-GHI cloud : China resourceDiscoveryGroups : - name : container-registry-landscape type : ContainerRegistry - name : filtered-logic-apps-landscape type : LogicApp criteria : include : subscriptions : - SUBSCRIPTON-ID-ABC - SUBSCRIPTON-ID-GHI resourceGroups : - promitor-resource-group-1 - promitor-resource-group-2 tags : app : promitor-1|promitor-2 region : europe regions : - northeurope - westeurope","title":"Declaring resource discovery groups"},{"location":"resource-discovery/declaring-resource-discovery-groups/#specification","text":"As Promitor evolves we need to change the structure of our resource discovery declaration. version: {version} - Version of declaration that is used. Allowed values are v1 . (Required)","title":"Specification"},{"location":"resource-discovery/declaring-resource-discovery-groups/#azure-landscape","text":"azureLandscape.tenantId - The id of the Azure tenant that will be queried. (Required) azureLandscape.subscriptions - List of Azure subscriptions in the Azure tenant to discover resources in. (Required) azureLandscape.cloud - The name of the Azure cloud to use. Options are Global (default), China , UsGov & Germany .","title":"Azure Landscape"},{"location":"resource-discovery/declaring-resource-discovery-groups/#resource-discovery-groups","text":"Every resource discovery group that is being declared needs to define the following fields: name - Name of the resource discovery group which will be used in metrics declaration of Promitor Scraper. (Required) type - Type of Azure resources that must be discovered, see \"Supported Azure Services\" for a full list of supported types. (Required) criteria - Criteria to fine-tune discovered resource.","title":"Resource Discovery Groups"},{"location":"resource-discovery/declaring-resource-discovery-groups/#criteria","text":"As of now, we only allow to define criteria that resources have to meet before they are included in the resource discovery group: subscriptions - A list of subscription(s) in which the resource is allowed to be located. resourceGroups - A list of resource group(s) in which the resource is allowed to be located. tags - A list of Azure tags and the expected values (exact or regular expression) with which the resources have to be annotated. (Uses or ) regions - A list of Azure region(s) in which the resource is allowed to be located.","title":"Criteria"},{"location":"resource-discovery/overview/","text":"Overview \u00b6 Resource discovery allows you to define criteria to automatically discover resources in your Azure tenant and scrape metrics for all of the Azure resources that are found. How it works \u00b6 While Promitor Scraper uses a declarative approach for defining Azure resources to scrape; as of Promitor Scraper 2.0 you can integrate with Promitor Resource Discovery ! With resource discovery, you can define resource discovery groups that represent Azure resources of a given type and optionally define criteria for the resources to comply with. By doing this, you can change your metric declaration for Promitor Scraper so that, instead of using declared resources, reference a resource discovery group which be used to determine what Azure resources it should scrape metrics for. Behind the scenes, Promitor Resource Discovery integrates with Azure Resource Graph which will query your Azure landscape to discover the corresponding resources. Here's an overview of how they work together:","title":"Overview"},{"location":"resource-discovery/overview/#overview","text":"Resource discovery allows you to define criteria to automatically discover resources in your Azure tenant and scrape metrics for all of the Azure resources that are found.","title":"Overview"},{"location":"resource-discovery/overview/#how-it-works","text":"While Promitor Scraper uses a declarative approach for defining Azure resources to scrape; as of Promitor Scraper 2.0 you can integrate with Promitor Resource Discovery ! With resource discovery, you can define resource discovery groups that represent Azure resources of a given type and optionally define criteria for the resources to comply with. By doing this, you can change your metric declaration for Promitor Scraper so that, instead of using declared resources, reference a resource discovery group which be used to determine what Azure resources it should scrape metrics for. Behind the scenes, Promitor Resource Discovery integrates with Azure Resource Graph which will query your Azure landscape to discover the corresponding resources. Here's an overview of how they work together:","title":"How it works"},{"location":"resource-discovery/runtime-configuration/","text":"Runtime Configuration \u00b6 This article covers an overview of all the knobs that you can tweak to align the Resource Discovery runtime with your needs. Promitor Resource Discovery runtime is configured by mounting the configuration to a volume. Depending on the operating system, it need to be available on : /config/runtime.yaml for Linux c:/config/runtime.yaml for Windows We provide the capability to override te runtime YAML via environment variables , if you have the need for it. Here is a complete example of the runtime YAML: authentication : # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity. mode : ServicePrincipal # Optional. Default: ServicePrincipal. identityId : xxxx-xxxx-xxxx # Optional. server : httpPort : 80 # Optional. Default: 80 cache : enabled : true # Optional. Default: true durationInMinutes : 5 # Optional. Default: 5 telemetry : applicationInsights : instrumentationKey : ABC # Optional. Note: Required to be specified when turned on isEnabled : false # Optional. Default: false verbosity : trace # Optional. Default: N/A containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error Authentication \u00b6 The Promitor runtime allows you to use various ways to authenticate to Azure: authentication.mode - Defines authentication mode to use. Options are ServicePrincipal , SystemAssignedManagedIdentity , UserAssignedManagedIdentity . (defaults to service principle) authentication.identityId - Id of the Azure AD entity to authenticate with when integrating with Microsoft Azure. Required when using ServicePrincipal or UserAssignedManagedIdentity . Example: authentication : # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity. mode : ServicePrincipal # Optional. Default: ServicePrincipal. identityId : xxxx-xxxx-xxxx # Optional. Runtime \u00b6 The Promitor runtime is flexible and allows you to configure it to meet your needs: server.httpPort - Defines the port to serve HTTP traffic (default 80) Example: server : httpPort : 80 # Optional. Default: 80 Cache \u00b6 The Promitor runtime allows you to cache discovered resources to optimize for performance and avoid hitting Azure throttling. You can configure how the cache should behave: cache.enabled - Indication whether or not discovered resources should be cached in-memory. (default true) cache.durationInMinutes - Amount of minutes to cache discovered resources. (default 5) Example: cache : enabled : true # Optional. Default: true durationInMinutes : 5 # Optional. Default: 5 Telemetry \u00b6 We provide insights in how our runtime is doing and is written to one or more sinks. You can determine what telemetry sinks you want and what the default verbosity should be via the runtime YAML. General telemetry information can be configured: telemetry.defaultVerbosity - Defines the default minimum log level that should be logged if a sink does not provide one. Allowed values are Trace , Debug , Information , Warning , Error , Critical , None ordered from most to least verbose. (Default: Error ) To learn more about the configured sinks and their configuration, see \"Telemetry Sinks\" . Example: telemetry : applicationInsights : # [...] containerLogs : # [...] defaultVerbosity : error # Optional. Default: error Telemetry Sinks \u00b6 Promitor provides the telemetry, but it's up to you to choose where you want to send it to. We currently support the following sinks: Container Logs (stdout/stderr) Azure Application Insights Container Logs \u00b6 Promitor can send telemetry to stdout / stderr . In order to enable use this sink, the following configuration needs to be provided: telemetry.containerLogs.isEnabled - Determines if the sink is used or not. (Default: true ) telemetry.containerLogs.verbosity - Verbosity to use for this sink, if not specified then the telemetry.defaultVerbosity will be used. (Optional) Example: telemetry : containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error Azure Application Insights \u00b6 Promitor can send telemetry to Azure Application Insights when there is a need to. It currently supports: Traces Exceptions In order to enable use this sink, the following configuration needs to be provided: telemetry.applicationInsights.isEnabled - Determines if the sink is used or not. (Default: true ) telemetry.applicationInsights.verbosity - Verbosity to use for this sink, if not specified then the telemetry.defaultVerbosity will be used. (Optional) telemetry.applicationInsights.instrumentationKey - Defines the instrumentation key to use when sending telemetry to Azure Application Insights Example: telemetry : applicationInsights : instrumentationKey : ABC # Optional. Note: Required to be specified when turned on isEnabled : false # Optional. Default: false verbosity : trace # Optional. Default: N/A containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error Overriding configuration with environment variables \u00b6 In certain scenarios you'd like to override what was configured in the runtime YAML. Therefore we provide the capability to override them via environment variables. Every environment variable should be prefixed with PROMITOR_YAML_OVERRIDE_ followed by the YAML hierarchy where every level is replaced with __ rather than a tab. Environment variables are not case sensitive. Our runtime configuration API endpoint allows you to verify if it was overriden and returns what will be used to run Promitor. Depending on the configuration that is changed it may be required to restart Promitor, for example changing the HTTP port. Example \u00b6 Let's say we want to override the following HTTP port: server : httpPort : 80 An environment variable called PROMITOR_YAML_OVERRIDE_server__httpPort can be provided which specifies the new port. \u2190 back","title":"Runtime Configuration"},{"location":"resource-discovery/runtime-configuration/#runtime-configuration","text":"This article covers an overview of all the knobs that you can tweak to align the Resource Discovery runtime with your needs. Promitor Resource Discovery runtime is configured by mounting the configuration to a volume. Depending on the operating system, it need to be available on : /config/runtime.yaml for Linux c:/config/runtime.yaml for Windows We provide the capability to override te runtime YAML via environment variables , if you have the need for it. Here is a complete example of the runtime YAML: authentication : # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity. mode : ServicePrincipal # Optional. Default: ServicePrincipal. identityId : xxxx-xxxx-xxxx # Optional. server : httpPort : 80 # Optional. Default: 80 cache : enabled : true # Optional. Default: true durationInMinutes : 5 # Optional. Default: 5 telemetry : applicationInsights : instrumentationKey : ABC # Optional. Note: Required to be specified when turned on isEnabled : false # Optional. Default: false verbosity : trace # Optional. Default: N/A containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error","title":"Runtime Configuration"},{"location":"resource-discovery/runtime-configuration/#authentication","text":"The Promitor runtime allows you to use various ways to authenticate to Azure: authentication.mode - Defines authentication mode to use. Options are ServicePrincipal , SystemAssignedManagedIdentity , UserAssignedManagedIdentity . (defaults to service principle) authentication.identityId - Id of the Azure AD entity to authenticate with when integrating with Microsoft Azure. Required when using ServicePrincipal or UserAssignedManagedIdentity . Example: authentication : # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity. mode : ServicePrincipal # Optional. Default: ServicePrincipal. identityId : xxxx-xxxx-xxxx # Optional.","title":"Authentication"},{"location":"resource-discovery/runtime-configuration/#runtime","text":"The Promitor runtime is flexible and allows you to configure it to meet your needs: server.httpPort - Defines the port to serve HTTP traffic (default 80) Example: server : httpPort : 80 # Optional. Default: 80","title":"Runtime"},{"location":"resource-discovery/runtime-configuration/#cache","text":"The Promitor runtime allows you to cache discovered resources to optimize for performance and avoid hitting Azure throttling. You can configure how the cache should behave: cache.enabled - Indication whether or not discovered resources should be cached in-memory. (default true) cache.durationInMinutes - Amount of minutes to cache discovered resources. (default 5) Example: cache : enabled : true # Optional. Default: true durationInMinutes : 5 # Optional. Default: 5","title":"Cache"},{"location":"resource-discovery/runtime-configuration/#telemetry","text":"We provide insights in how our runtime is doing and is written to one or more sinks. You can determine what telemetry sinks you want and what the default verbosity should be via the runtime YAML. General telemetry information can be configured: telemetry.defaultVerbosity - Defines the default minimum log level that should be logged if a sink does not provide one. Allowed values are Trace , Debug , Information , Warning , Error , Critical , None ordered from most to least verbose. (Default: Error ) To learn more about the configured sinks and their configuration, see \"Telemetry Sinks\" . Example: telemetry : applicationInsights : # [...] containerLogs : # [...] defaultVerbosity : error # Optional. Default: error","title":"Telemetry"},{"location":"resource-discovery/runtime-configuration/#telemetry-sinks","text":"Promitor provides the telemetry, but it's up to you to choose where you want to send it to. We currently support the following sinks: Container Logs (stdout/stderr) Azure Application Insights","title":"Telemetry Sinks"},{"location":"resource-discovery/runtime-configuration/#container-logs","text":"Promitor can send telemetry to stdout / stderr . In order to enable use this sink, the following configuration needs to be provided: telemetry.containerLogs.isEnabled - Determines if the sink is used or not. (Default: true ) telemetry.containerLogs.verbosity - Verbosity to use for this sink, if not specified then the telemetry.defaultVerbosity will be used. (Optional) Example: telemetry : containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error","title":"Container Logs"},{"location":"resource-discovery/runtime-configuration/#azure-application-insights","text":"Promitor can send telemetry to Azure Application Insights when there is a need to. It currently supports: Traces Exceptions In order to enable use this sink, the following configuration needs to be provided: telemetry.applicationInsights.isEnabled - Determines if the sink is used or not. (Default: true ) telemetry.applicationInsights.verbosity - Verbosity to use for this sink, if not specified then the telemetry.defaultVerbosity will be used. (Optional) telemetry.applicationInsights.instrumentationKey - Defines the instrumentation key to use when sending telemetry to Azure Application Insights Example: telemetry : applicationInsights : instrumentationKey : ABC # Optional. Note: Required to be specified when turned on isEnabled : false # Optional. Default: false verbosity : trace # Optional. Default: N/A containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error","title":"Azure Application Insights"},{"location":"resource-discovery/runtime-configuration/#overriding-configuration-with-environment-variables","text":"In certain scenarios you'd like to override what was configured in the runtime YAML. Therefore we provide the capability to override them via environment variables. Every environment variable should be prefixed with PROMITOR_YAML_OVERRIDE_ followed by the YAML hierarchy where every level is replaced with __ rather than a tab. Environment variables are not case sensitive. Our runtime configuration API endpoint allows you to verify if it was overriden and returns what will be used to run Promitor. Depending on the configuration that is changed it may be required to restart Promitor, for example changing the HTTP port.","title":"Overriding configuration with environment variables"},{"location":"resource-discovery/runtime-configuration/#example","text":"Let's say we want to override the following HTTP port: server : httpPort : 80 An environment variable called PROMITOR_YAML_OVERRIDE_server__httpPort can be provided which specifies the new port. \u2190 back","title":"Example"},{"location":"scraping/labels/","text":"Metric Labelling \u00b6 Here is an overview of how we label metrics. There are a couple of scenarios where labels are being added: Built-in labels Metric dimension labels Scaler-specific labels Bring-your-own labels In case of duplicate label names the above priority will be used. Built-in labels \u00b6 Every metric that is being reported in the scraping endpoint comes with the following built-in labels: resource_uri - Full resource URI of the instance. (ie subscriptions/xxx/resourceGroups/yyy/providers/Microsoft.ServiceBus/namespaces/promitor ) subscription_id - Id of the subscription. resource_group - Name of the resource group. instance_name - Name of the instance, if applicable. Metric dimension labels \u00b6 Metrics support specifying one or more dimension(s) which will be scraped in Azure Monitor. Every metric value will be reported under the configured metric name, but labels for the dimensions and their respective values will be added. Scraper-specific labels \u00b6 Every scraper can provide additional labels to provide more information. Currently we support this for: Azure API Management Azure Function App Azure Service Bus Azure SQL Database Azure Storage Queue Azure Web App For more information, we recommend reading the scraper-specific documentation . Custom Labels \u00b6 As of v1.0, you can define your own labels by configuring them for a specific metric. For more information, see \"Metrics\" .","title":"Metric Labelling"},{"location":"scraping/labels/#metric-labelling","text":"Here is an overview of how we label metrics. There are a couple of scenarios where labels are being added: Built-in labels Metric dimension labels Scaler-specific labels Bring-your-own labels In case of duplicate label names the above priority will be used.","title":"Metric Labelling"},{"location":"scraping/labels/#built-in-labels","text":"Every metric that is being reported in the scraping endpoint comes with the following built-in labels: resource_uri - Full resource URI of the instance. (ie subscriptions/xxx/resourceGroups/yyy/providers/Microsoft.ServiceBus/namespaces/promitor ) subscription_id - Id of the subscription. resource_group - Name of the resource group. instance_name - Name of the instance, if applicable.","title":"Built-in labels"},{"location":"scraping/labels/#metric-dimension-labels","text":"Metrics support specifying one or more dimension(s) which will be scraped in Azure Monitor. Every metric value will be reported under the configured metric name, but labels for the dimensions and their respective values will be added.","title":"Metric dimension labels"},{"location":"scraping/labels/#scraper-specific-labels","text":"Every scraper can provide additional labels to provide more information. Currently we support this for: Azure API Management Azure Function App Azure Service Bus Azure SQL Database Azure Storage Queue Azure Web App For more information, we recommend reading the scraper-specific documentation .","title":"Scraper-specific labels"},{"location":"scraping/labels/#custom-labels","text":"As of v1.0, you can define your own labels by configuring them for a specific metric. For more information, see \"Metrics\" .","title":"Custom Labels"},{"location":"scraping/overview/","text":"Metrics Declaration \u00b6 All the Azure Monitor metrics that need to be scraped are consolidated in one YAML file which is referred to as the metric declaration. This declaration defines the overall Azure metadata and all the metrics you want to expose. Every metric describes the Azure Monitor metric that it represents and what Azure resources that should be scraped. It allows you to statically declaring the resources to scrape and/or use automatic resource discovery . Supported Azure Services \u00b6 Generic Azure Resource allows you to scrape every Azure service supported by Azure Monitor. We also provide a simplified way to scrape the following Azure resources: Azure API Management Azure Application Gateway Azure Application Insights Azure App Plan Azure Cache for Redis Azure Cache for Redis Enterprise Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Database for PostgreSQL Azure Database for MariaDB Azure Database for MySQL Azure Event Hubs Azure Express Route Circuit Azure Front Door Azure Function App Azure IoT Hub Azure IoT Hub Device Provisioning Service (DPS) Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Logic Apps Azure Monitor Autoscale Azure Network Gateway Azure Network Interface Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage (Account) Azure Storage (Blob) Azure Storage (Files) Azure Storage (Queue) Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Azure Virtual Machine Scale Set (VMSS) Azure Virtual Network Azure Web App Want to help out? Create an issue and contribute a new scraper . General Declaration \u00b6 As Promitor evolves we need to change the structure of our metrics declaration. version: {version} - Version of declaration that is used. Allowed values are v1 . (Required) Azure \u00b6 azureMetadata.tenantId - The id of the Azure tenant that will be queried. azureMetadata.subscriptionId - The id of the default subscription to query. azureMetadata.resourceGroupName - The name of the default resource group to query. azureMetadata.cloud - The name of the Azure cloud to use. Options are Global (default), China , UsGov & Germany . Metric Defaults \u00b6 metricDefaults.aggregation.interval - The default interval which defines over what period measurements of a metric should be aggregated. a cron that fits your needs. metricDefaults.limit - The default maximum amount of resources to scrape when using dimensions or filters. metricDefaults.labels - The default labels that will be applied to all metrics. (starting as of v2.3) metricDefaults.scraping.schedule - A cron expression that controls the frequency of which all the configured metrics will be scraped from Azure Monitor. You can use crontab-generator.org to generate a cron that fits your needs. (Required) Metrics \u00b6 Every metric that is being declared needs to define the following fields: name - Name of the metric that will be reported. description - Description for the metric that will be reported. resourceType - Defines what type of resource needs to be queried. azureMetricConfiguration.metricName - The name of the metric in Azure Monitor to query azureMetricConfiguration.aggregation.type - The aggregation that needs to be used when querying Azure Monitor azureMetricConfiguration.aggregation.interval - Overrides the default aggregation interval defined in metricDefaults.aggregation.interval with a new interval resources - An array of one or more resources to get metrics for. The fields required vary depending on the resourceType being created, and are documented for each resource. azureMetricConfiguration.limit - The maximum amount of resources to scrape when using dimensions or filters. resourceDiscoveryGroups An array of one or more resource discovery groups that will be used to automatically discover all resources through Promitor Resource Discovery. For every found resource, it will get the metrics and report them. Learn more on resource discovery, in our documentation All resources provide the capability to override the default Azure metadata: subscriptionId - Changes the subscription id to which the resource belongs. (Overrides azureMetadata.subscriptionId ) resourceGroupName - Changes the resource group that contains resource. (Overrides azureMetadata.resourceGroupName ) Additionally, the following fields are optional: azureMetricConfiguration.dimensions - A list of dimensions that should be used to scrape a multi-dimensional metric in Azure Monitor. \u261d Promitor simply acts as a proxy and will not validate if the given dimensions are supported or not, we recommend verifying that they are in the official documentation labels - Defines a set of custom labels to include for a given metric. scraping.schedule - A scraping schedule for the individual metric; overrides the the one specified in metricDefaults Example \u00b6 Here is an example of how you can scrape two Azure Service Bus queues in different resource groups, one in the promitor resource group and one on the promitor-dev resource group: version : v1 azureMetadata : tenantId : xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx subscriptionId : yyyyyyyy-yyyy-yyyy-yyyy-yyyyyyyyyyyy resourceGroupName : promitor cloud : China metricDefaults : aggregation : interval : 00:05:00 limit : 10 labels : geo : china environment : dev scraping : # Every minute schedule : \"0 * * ? * *\" metrics : - name : azure_service_bus_active_messages description : \"The number of active messages on a service bus queue.\" resourceType : ServiceBusNamespace labels : app : promitor tier : messaging scraping : # Every 2 minutes schedule : \"0 */2 * ? * *\" azureMetricConfiguration : metricName : ActiveMessages limit : 5 # Deprecated, please use 'dimensions' instead dimension : name : <dimension-name> dimensions : - name : <first-dimension-name> - name : <second-dimension-name> aggregation : type : Total interval : 00:15:00 resources : # Optional, required when no resource discovery is configured - namespace : promitor-messaging queueName : orders - namespace : promitor-messaging-dev resourceGroupName : promitor-dev subscriptionId : ABC resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : service-bus-landscape \u2190 back","title":"Overview"},{"location":"scraping/overview/#metrics-declaration","text":"All the Azure Monitor metrics that need to be scraped are consolidated in one YAML file which is referred to as the metric declaration. This declaration defines the overall Azure metadata and all the metrics you want to expose. Every metric describes the Azure Monitor metric that it represents and what Azure resources that should be scraped. It allows you to statically declaring the resources to scrape and/or use automatic resource discovery .","title":"Metrics Declaration"},{"location":"scraping/overview/#supported-azure-services","text":"Generic Azure Resource allows you to scrape every Azure service supported by Azure Monitor. We also provide a simplified way to scrape the following Azure resources: Azure API Management Azure Application Gateway Azure Application Insights Azure App Plan Azure Cache for Redis Azure Cache for Redis Enterprise Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Database for PostgreSQL Azure Database for MariaDB Azure Database for MySQL Azure Event Hubs Azure Express Route Circuit Azure Front Door Azure Function App Azure IoT Hub Azure IoT Hub Device Provisioning Service (DPS) Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Logic Apps Azure Monitor Autoscale Azure Network Gateway Azure Network Interface Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage (Account) Azure Storage (Blob) Azure Storage (Files) Azure Storage (Queue) Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Azure Virtual Machine Scale Set (VMSS) Azure Virtual Network Azure Web App Want to help out? Create an issue and contribute a new scraper .","title":"Supported Azure Services"},{"location":"scraping/overview/#general-declaration","text":"As Promitor evolves we need to change the structure of our metrics declaration. version: {version} - Version of declaration that is used. Allowed values are v1 . (Required)","title":"General Declaration"},{"location":"scraping/overview/#azure","text":"azureMetadata.tenantId - The id of the Azure tenant that will be queried. azureMetadata.subscriptionId - The id of the default subscription to query. azureMetadata.resourceGroupName - The name of the default resource group to query. azureMetadata.cloud - The name of the Azure cloud to use. Options are Global (default), China , UsGov & Germany .","title":"Azure"},{"location":"scraping/overview/#metric-defaults","text":"metricDefaults.aggregation.interval - The default interval which defines over what period measurements of a metric should be aggregated. a cron that fits your needs. metricDefaults.limit - The default maximum amount of resources to scrape when using dimensions or filters. metricDefaults.labels - The default labels that will be applied to all metrics. (starting as of v2.3) metricDefaults.scraping.schedule - A cron expression that controls the frequency of which all the configured metrics will be scraped from Azure Monitor. You can use crontab-generator.org to generate a cron that fits your needs. (Required)","title":"Metric Defaults"},{"location":"scraping/overview/#metrics","text":"Every metric that is being declared needs to define the following fields: name - Name of the metric that will be reported. description - Description for the metric that will be reported. resourceType - Defines what type of resource needs to be queried. azureMetricConfiguration.metricName - The name of the metric in Azure Monitor to query azureMetricConfiguration.aggregation.type - The aggregation that needs to be used when querying Azure Monitor azureMetricConfiguration.aggregation.interval - Overrides the default aggregation interval defined in metricDefaults.aggregation.interval with a new interval resources - An array of one or more resources to get metrics for. The fields required vary depending on the resourceType being created, and are documented for each resource. azureMetricConfiguration.limit - The maximum amount of resources to scrape when using dimensions or filters. resourceDiscoveryGroups An array of one or more resource discovery groups that will be used to automatically discover all resources through Promitor Resource Discovery. For every found resource, it will get the metrics and report them. Learn more on resource discovery, in our documentation All resources provide the capability to override the default Azure metadata: subscriptionId - Changes the subscription id to which the resource belongs. (Overrides azureMetadata.subscriptionId ) resourceGroupName - Changes the resource group that contains resource. (Overrides azureMetadata.resourceGroupName ) Additionally, the following fields are optional: azureMetricConfiguration.dimensions - A list of dimensions that should be used to scrape a multi-dimensional metric in Azure Monitor. \u261d Promitor simply acts as a proxy and will not validate if the given dimensions are supported or not, we recommend verifying that they are in the official documentation labels - Defines a set of custom labels to include for a given metric. scraping.schedule - A scraping schedule for the individual metric; overrides the the one specified in metricDefaults","title":"Metrics"},{"location":"scraping/overview/#example","text":"Here is an example of how you can scrape two Azure Service Bus queues in different resource groups, one in the promitor resource group and one on the promitor-dev resource group: version : v1 azureMetadata : tenantId : xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx subscriptionId : yyyyyyyy-yyyy-yyyy-yyyy-yyyyyyyyyyyy resourceGroupName : promitor cloud : China metricDefaults : aggregation : interval : 00:05:00 limit : 10 labels : geo : china environment : dev scraping : # Every minute schedule : \"0 * * ? * *\" metrics : - name : azure_service_bus_active_messages description : \"The number of active messages on a service bus queue.\" resourceType : ServiceBusNamespace labels : app : promitor tier : messaging scraping : # Every 2 minutes schedule : \"0 */2 * ? * *\" azureMetricConfiguration : metricName : ActiveMessages limit : 5 # Deprecated, please use 'dimensions' instead dimension : name : <dimension-name> dimensions : - name : <first-dimension-name> - name : <second-dimension-name> aggregation : type : Total interval : 00:15:00 resources : # Optional, required when no resource discovery is configured - namespace : promitor-messaging queueName : orders - namespace : promitor-messaging-dev resourceGroupName : promitor-dev subscriptionId : ABC resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : service-bus-landscape \u2190 back","title":"Example"},{"location":"scraping/runtime-configuration/","text":"Runtime Configuration \u00b6 This article covers an overview of all the knobs that you can tweak to align the Scraper runtime with your needs. Promitor Scraper runtime is configured by mounting the configuration to a volume. Depending on the operating system, it need to be available on : /config/runtime.yaml for Linux c:/config/runtime.yaml for Windows We provide the capability to override te runtime YAML via environment variables , if you have the need for it. Here is a complete example of the runtime YAML: authentication : # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity. mode : ServicePrincipal # Optional. Default: ServicePrincipal. identityId : xxxx-xxxx-xxxx # Optional. server : httpPort : 80 # Optional. Default: 80 metricSinks : atlassianStatuspage : pageId : XXX # Mandatory systemMetricMapping : # Mandatory to have at least one mapping - id : ABC promitorMetricName : promitor_demo_appplan_percentage_cpu openTelemetryCollector : collectorUri : http://<dns>:4317 prometheusScrapingEndpoint : metricUnavailableValue : NaN # Optional. Default: NaN enableMetricTimestamps : false # Optional. Default: true baseUriPath : /metrics # Optional. Default: /metrics labels : transformation : None # Optional. Default: None. statsd : host : graphite port : 8125 # Optional. Default: 8125 metricPrefix : promitor. # Optional. Default: None metricsConfiguration : absolutePath : /config/metrics-declaration.yaml # Optional. Default: /config/metrics-declaration.yaml azureMonitor : logging : informationLevel : Basic # Optional. Default: Basic isEnabled : false # Optional. Default: false integration : history : startingFromInHours : 24 # Optional. Default: 12 telemetry : applicationInsights : instrumentationKey : ABC # Optional. Note: Required to be specified when turned on isEnabled : false # Optional. Default: false verbosity : trace # Optional. Default: N/A containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error resourceDiscovery : host : promitor.agents.resourcediscovery # Optional. DNS name of Promitor Resource Discovery agent enabled : true # Optional. Indication whether or not resource discovery is enabled through the Promitor Resource Discovery agent. port : 88 # Optional. Port of Promitor Resource Discovery agent Note: Using Promitor v0.x? Use environment variables to configure the runtime. Authentication \u00b6 The Promitor runtime allows you to use various ways to authenticate to Azure: authentication.mode - Defines authentication mode to use. Options are ServicePrincipal , SystemAssignedManagedIdentity , UserAssignedManagedIdentity . (defaults to service principle) authentication.identityId - Id of the Azure AD entity to authenticate with when integrating with Microsoft Azure. Required when using ServicePrincipal or UserAssignedManagedIdentity . Example: authentication : # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity. mode : ServicePrincipal # Optional. Default: ServicePrincipal. identityId : xxxx-xxxx-xxxx # Optional. Runtime \u00b6 The Promitor runtime is flexible and allows you to configure it to meet your needs: server.httpPort - Defines the port to serve HTTP traffic (default 80) Example: server : httpPort : 80 # Optional. Default: 80 Metric Sinks \u00b6 Promitor automatically scrapes Azure Monitor and makes the information available by providing the metric information to the configured sinks. As of today, we support the follow sinks: Atlassian Statuspage OpenTelemetry Collector Prometheus Scraping Endpoint StatsD Atlassian Statuspage \u00b6 In order to expose an Atlassian Statuspage endpoint, you'll need to configure the sink: atlassianStatuspage.pageId - Defines the id of the Atlassian Statuspage to report to. atlassianStatuspage.systemMetricMapping - Defines a mapping of the scraped metric by Promitor and to which Atlassian Statuspage system metric it should be reported to. Here's what we expect: id - Id of the Atlassian Statuspage system metric promitorMetricName - Name of the Promitor metric which needs to be reported Next to that, PROMITOR_ATLASSIAN_STATUSPAGE_APIKEY environment variable is required which contains the API Key for Atlassian Statuspage. metricSinks : atlassianStatuspage : pageId : XXX # Mandatory systemMetricMapping : # Mandatory to have at least one mapping - id : ABC promitorMetricName : promitor_demo_appplan_percentage_cpu As of today, metric labels, resource discovery and multi-resource scraping are not supported. This is because Promitor will report the different resource metrics to the same Atlassian metric which will mix metrics which becomes confusing. OpenTelemetry Collector \u00b6 In order to push metrics to an OpenTelemetry Collector, you'll need to configure the sink: openTelemetryCollector.collectorUri - Uri of the OpenTelemetry Collector. openTelemetryCollector : collectorUri : http://<dns>:4317 Prometheus Scraping Endpoint \u00b6 In order to expose a Prometheus Scraping endpoint, you'll need to configure the sink: prometheusScrapingEndpoint.metricUnavailableValue - Defines the value that will be reported if a metric is unavailable. (Default: NaN ) prometheusScrapingEndpoint.enableMetricTimestamps - Defines whether or not a timestamp should be included when the value was scraped on Azure Monitor. Supported values are True to opt-in & False to opt-out. (Default: true ) prometheusScrapingEndpoint.baseUriPath - Controls the path where the scraping endpoint for Prometheus is being exposed. (Default: /metrics ) prometheusScrapingEndpoint.labels.transformation - Controls how label values are reported to Prometheus by using transformation. Options are None & Lowercase . (Default: None ) metricSinks : prometheusScrapingEndpoint : metricUnavailableValue : NaN # Optional. Default: NaN enableMetricTimestamps : false # Optional. Default: true baseUriPath : /metrics # Optional. Default: /metrics labels : transformation : None # Optional. Default: None. What happens when metrics are unavailable for multi-dimensional metrics? \u00b6 Promitor allows you to use one or more dimension(s) in metrics so that it will report all values. For example, when scraping an Azure Event Hub namespace you can report the same metric for every entity inside the namespace. When Promitor reports the metric it will always add a label which clarifies the subresource. However, when it cannot find a metric for that dimension it will keep on reporting the metric, but with value unknown given it cannot determine the name of the dimension. StatsD \u00b6 In order to push metrics to a StatsD server, you'll need to configure the sink: metricSinks.statsd.host - DNS name or IP address of StatsD server. metricSinks.statsd.host - Port (UDP) address of StatsD server. (Default: 8125 ) metricSinks.statsd.metricPrefix - Prefix that will be added to every metric defined in the metric declaration. metricSinks : statsd : host : graphite port : 8125 metricPrefix : promitor. As of today, metric labels are not supported. Unfortunately, this is not supported in the specification. Using resource discovery \u00b6 Resource discovery can be used by integrating with Promitor Resource Discovery which allows you to scrape metrics by using discovery groups. In order to enable this, resource discovery must be configured first: resourceDiscovery.enabled - Indication whether or not resource discovery is enabled through the Promitor Resource Discovery agent. resourceDiscovery.host - DNS name of Promitor Resource Discovery agent. resourceDiscovery.port - Port of Promitor Resource Discovery agent. resourceDiscovery : host : promitor.agents.resourcediscovery enabled : true port : 88 # Optional. Default: 80 To learn more about how Promitor Scraper and Promitor Resource Discovery work together, read our documentation . Metric Configuration \u00b6 Promitor will scrape the Azure Monitor metrics that are configured via a metric declaration YAML. The behavior of this is configurable: metricsConfiguration.absolutePath - Defines the location of the YAML file that declares what Azure Monitor metrics to scrape. (Default: /config/metrics-declaration.yaml ) Example: metricsConfiguration : absolutePath : /config/metrics-declaration.yaml # Optional. Default: /config/metrics-declaration.yaml Telemetry \u00b6 We provide insights in how our runtime is doing and is written to one or more sinks. You can determine what telemetry sinks you want and what the default verbosity should be via the runtime YAML. General telemetry information can be configured: telemetry.defaultVerbosity - Defines the default minimum log level that should be logged if a sink does not provide one. Allowed values are Trace , Debug , Information , Warning , Error , Critical , None ordered from most to least verbose. (Default: Error ) To learn more about the configured sinks and their configuration, see \"Telemetry Sinks\" . Example: telemetry : applicationInsights : # [...] containerLogs : # [...] defaultVerbosity : error # Optional. Default: error Telemetry Sinks \u00b6 Promitor provides the telemetry, but it's up to you to choose where you want to send it to. We currently support the following sinks: Container Logs (stdout/stderr) Azure Application Insights Container Logs \u00b6 Promitor can send telemetry to stdout / stderr . In order to enable use this sink, the following configuration needs to be provided: telemetry.containerLogs.isEnabled - Determines if the sink is used or not. (Default: true ) telemetry.containerLogs.verbosity - Verbosity to use for this sink, if not specified then the telemetry.defaultVerbosity will be used. (Optional) Example: telemetry : containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error Azure Application Insights \u00b6 Promitor can send telemetry to Azure Application Insights when there is a need to. It currently supports: Traces Exceptions In order to enable use this sink, the following configuration needs to be provided: telemetry.applicationInsights.isEnabled - Determines if the sink is used or not. (Default: true ) telemetry.applicationInsights.verbosity - Verbosity to use for this sink, if not specified then the telemetry.defaultVerbosity will be used. (Optional) telemetry.applicationInsights.instrumentationKey - Defines the instrumentation key to use when sending telemetry to Azure Application Insights Example: telemetry : applicationInsights : instrumentationKey : ABC # Optional. Note: Required to be specified when turned on isEnabled : false # Optional. Default: false verbosity : trace # Optional. Default: N/A containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error Azure Monitor \u00b6 Promitor interacts with Azure Monitor API to scrape all the required metrics. During troubleshooting it can be interesting to gain insights on what the API returns, for which you can opt-in. The behavior of this can be configured to fit your needs: azureMonitor.logging.informationLevel - Defines granularity of information that should be reported. Available options are Basic , Headers , Body & BodyAndHeaders . (Default: Basic ) azureMonitor.logging.isEnabled - Defines whether or not information concerning the integration with Azure Monitor API. (Default: false ) azureMonitor.integration.history.startingFromInHours - Defines the amount of hours Promitor will use to define the starting point of the time window used for metric queries. As an example, the default is 12 hours which means Promitor will fetch all metrics between now - 12 hours and now to find a matching metric. Typically this window can be very small but Promitor provides a margin by default to prevent problems for long aggregation periods. (Default: 12 ) Example: azureMonitor : logging : informationLevel : Basic # Optional. Default: Basic isEnabled : false # Optional. Default: false integration : history : startingFromInHours : 24 # Optional. Default: 12 Note: All telemetry is emitted as trace so you have to make sure telemetry is configured correctly. Overriding configuration with environment variables \u00b6 In certain scenarios you'd like to override what was configured in the runtime YAML. Therefore we provide the capability to override them via environment variables. Every environment variable should be prefixed with PROMITOR_YAML_OVERRIDE_ followed by the YAML hierarchy where every level is replaced with __ rather than a tab. Environment variables are not case sensitive. Our runtime configuration API endpoint allows you to verify if it was overriden and returns what will be used to run Promitor. Depending on the configuration that is changed it may be required to restart Promitor, for example changing the HTTP port. Example \u00b6 Let's say we want to override the following HTTP port: server : httpPort : 80 An environment variable called PROMITOR_YAML_OVERRIDE_server__httpPort can be provided which specifies the new port. \u2190 back","title":"Runtime Configuration"},{"location":"scraping/runtime-configuration/#runtime-configuration","text":"This article covers an overview of all the knobs that you can tweak to align the Scraper runtime with your needs. Promitor Scraper runtime is configured by mounting the configuration to a volume. Depending on the operating system, it need to be available on : /config/runtime.yaml for Linux c:/config/runtime.yaml for Windows We provide the capability to override te runtime YAML via environment variables , if you have the need for it. Here is a complete example of the runtime YAML: authentication : # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity. mode : ServicePrincipal # Optional. Default: ServicePrincipal. identityId : xxxx-xxxx-xxxx # Optional. server : httpPort : 80 # Optional. Default: 80 metricSinks : atlassianStatuspage : pageId : XXX # Mandatory systemMetricMapping : # Mandatory to have at least one mapping - id : ABC promitorMetricName : promitor_demo_appplan_percentage_cpu openTelemetryCollector : collectorUri : http://<dns>:4317 prometheusScrapingEndpoint : metricUnavailableValue : NaN # Optional. Default: NaN enableMetricTimestamps : false # Optional. Default: true baseUriPath : /metrics # Optional. Default: /metrics labels : transformation : None # Optional. Default: None. statsd : host : graphite port : 8125 # Optional. Default: 8125 metricPrefix : promitor. # Optional. Default: None metricsConfiguration : absolutePath : /config/metrics-declaration.yaml # Optional. Default: /config/metrics-declaration.yaml azureMonitor : logging : informationLevel : Basic # Optional. Default: Basic isEnabled : false # Optional. Default: false integration : history : startingFromInHours : 24 # Optional. Default: 12 telemetry : applicationInsights : instrumentationKey : ABC # Optional. Note: Required to be specified when turned on isEnabled : false # Optional. Default: false verbosity : trace # Optional. Default: N/A containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error resourceDiscovery : host : promitor.agents.resourcediscovery # Optional. DNS name of Promitor Resource Discovery agent enabled : true # Optional. Indication whether or not resource discovery is enabled through the Promitor Resource Discovery agent. port : 88 # Optional. Port of Promitor Resource Discovery agent Note: Using Promitor v0.x? Use environment variables to configure the runtime.","title":"Runtime Configuration"},{"location":"scraping/runtime-configuration/#authentication","text":"The Promitor runtime allows you to use various ways to authenticate to Azure: authentication.mode - Defines authentication mode to use. Options are ServicePrincipal , SystemAssignedManagedIdentity , UserAssignedManagedIdentity . (defaults to service principle) authentication.identityId - Id of the Azure AD entity to authenticate with when integrating with Microsoft Azure. Required when using ServicePrincipal or UserAssignedManagedIdentity . Example: authentication : # Options are ServicePrincipal, SystemAssignedManagedIdentity, UserAssignedManagedIdentity. mode : ServicePrincipal # Optional. Default: ServicePrincipal. identityId : xxxx-xxxx-xxxx # Optional.","title":"Authentication"},{"location":"scraping/runtime-configuration/#runtime","text":"The Promitor runtime is flexible and allows you to configure it to meet your needs: server.httpPort - Defines the port to serve HTTP traffic (default 80) Example: server : httpPort : 80 # Optional. Default: 80","title":"Runtime"},{"location":"scraping/runtime-configuration/#metric-sinks","text":"Promitor automatically scrapes Azure Monitor and makes the information available by providing the metric information to the configured sinks. As of today, we support the follow sinks: Atlassian Statuspage OpenTelemetry Collector Prometheus Scraping Endpoint StatsD","title":"Metric Sinks"},{"location":"scraping/runtime-configuration/#atlassian-statuspage","text":"In order to expose an Atlassian Statuspage endpoint, you'll need to configure the sink: atlassianStatuspage.pageId - Defines the id of the Atlassian Statuspage to report to. atlassianStatuspage.systemMetricMapping - Defines a mapping of the scraped metric by Promitor and to which Atlassian Statuspage system metric it should be reported to. Here's what we expect: id - Id of the Atlassian Statuspage system metric promitorMetricName - Name of the Promitor metric which needs to be reported Next to that, PROMITOR_ATLASSIAN_STATUSPAGE_APIKEY environment variable is required which contains the API Key for Atlassian Statuspage. metricSinks : atlassianStatuspage : pageId : XXX # Mandatory systemMetricMapping : # Mandatory to have at least one mapping - id : ABC promitorMetricName : promitor_demo_appplan_percentage_cpu As of today, metric labels, resource discovery and multi-resource scraping are not supported. This is because Promitor will report the different resource metrics to the same Atlassian metric which will mix metrics which becomes confusing.","title":"Atlassian Statuspage"},{"location":"scraping/runtime-configuration/#opentelemetry-collector","text":"In order to push metrics to an OpenTelemetry Collector, you'll need to configure the sink: openTelemetryCollector.collectorUri - Uri of the OpenTelemetry Collector. openTelemetryCollector : collectorUri : http://<dns>:4317","title":"OpenTelemetry Collector"},{"location":"scraping/runtime-configuration/#prometheus-scraping-endpoint","text":"In order to expose a Prometheus Scraping endpoint, you'll need to configure the sink: prometheusScrapingEndpoint.metricUnavailableValue - Defines the value that will be reported if a metric is unavailable. (Default: NaN ) prometheusScrapingEndpoint.enableMetricTimestamps - Defines whether or not a timestamp should be included when the value was scraped on Azure Monitor. Supported values are True to opt-in & False to opt-out. (Default: true ) prometheusScrapingEndpoint.baseUriPath - Controls the path where the scraping endpoint for Prometheus is being exposed. (Default: /metrics ) prometheusScrapingEndpoint.labels.transformation - Controls how label values are reported to Prometheus by using transformation. Options are None & Lowercase . (Default: None ) metricSinks : prometheusScrapingEndpoint : metricUnavailableValue : NaN # Optional. Default: NaN enableMetricTimestamps : false # Optional. Default: true baseUriPath : /metrics # Optional. Default: /metrics labels : transformation : None # Optional. Default: None.","title":"Prometheus Scraping Endpoint"},{"location":"scraping/runtime-configuration/#what-happens-when-metrics-are-unavailable-for-multi-dimensional-metrics","text":"Promitor allows you to use one or more dimension(s) in metrics so that it will report all values. For example, when scraping an Azure Event Hub namespace you can report the same metric for every entity inside the namespace. When Promitor reports the metric it will always add a label which clarifies the subresource. However, when it cannot find a metric for that dimension it will keep on reporting the metric, but with value unknown given it cannot determine the name of the dimension.","title":"What happens when metrics are unavailable for multi-dimensional metrics?"},{"location":"scraping/runtime-configuration/#statsd","text":"In order to push metrics to a StatsD server, you'll need to configure the sink: metricSinks.statsd.host - DNS name or IP address of StatsD server. metricSinks.statsd.host - Port (UDP) address of StatsD server. (Default: 8125 ) metricSinks.statsd.metricPrefix - Prefix that will be added to every metric defined in the metric declaration. metricSinks : statsd : host : graphite port : 8125 metricPrefix : promitor. As of today, metric labels are not supported. Unfortunately, this is not supported in the specification.","title":"StatsD"},{"location":"scraping/runtime-configuration/#using-resource-discovery","text":"Resource discovery can be used by integrating with Promitor Resource Discovery which allows you to scrape metrics by using discovery groups. In order to enable this, resource discovery must be configured first: resourceDiscovery.enabled - Indication whether or not resource discovery is enabled through the Promitor Resource Discovery agent. resourceDiscovery.host - DNS name of Promitor Resource Discovery agent. resourceDiscovery.port - Port of Promitor Resource Discovery agent. resourceDiscovery : host : promitor.agents.resourcediscovery enabled : true port : 88 # Optional. Default: 80 To learn more about how Promitor Scraper and Promitor Resource Discovery work together, read our documentation .","title":"Using resource discovery"},{"location":"scraping/runtime-configuration/#metric-configuration","text":"Promitor will scrape the Azure Monitor metrics that are configured via a metric declaration YAML. The behavior of this is configurable: metricsConfiguration.absolutePath - Defines the location of the YAML file that declares what Azure Monitor metrics to scrape. (Default: /config/metrics-declaration.yaml ) Example: metricsConfiguration : absolutePath : /config/metrics-declaration.yaml # Optional. Default: /config/metrics-declaration.yaml","title":"Metric Configuration"},{"location":"scraping/runtime-configuration/#telemetry","text":"We provide insights in how our runtime is doing and is written to one or more sinks. You can determine what telemetry sinks you want and what the default verbosity should be via the runtime YAML. General telemetry information can be configured: telemetry.defaultVerbosity - Defines the default minimum log level that should be logged if a sink does not provide one. Allowed values are Trace , Debug , Information , Warning , Error , Critical , None ordered from most to least verbose. (Default: Error ) To learn more about the configured sinks and their configuration, see \"Telemetry Sinks\" . Example: telemetry : applicationInsights : # [...] containerLogs : # [...] defaultVerbosity : error # Optional. Default: error","title":"Telemetry"},{"location":"scraping/runtime-configuration/#telemetry-sinks","text":"Promitor provides the telemetry, but it's up to you to choose where you want to send it to. We currently support the following sinks: Container Logs (stdout/stderr) Azure Application Insights","title":"Telemetry Sinks"},{"location":"scraping/runtime-configuration/#container-logs","text":"Promitor can send telemetry to stdout / stderr . In order to enable use this sink, the following configuration needs to be provided: telemetry.containerLogs.isEnabled - Determines if the sink is used or not. (Default: true ) telemetry.containerLogs.verbosity - Verbosity to use for this sink, if not specified then the telemetry.defaultVerbosity will be used. (Optional) Example: telemetry : containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error","title":"Container Logs"},{"location":"scraping/runtime-configuration/#azure-application-insights","text":"Promitor can send telemetry to Azure Application Insights when there is a need to. It currently supports: Traces Exceptions In order to enable use this sink, the following configuration needs to be provided: telemetry.applicationInsights.isEnabled - Determines if the sink is used or not. (Default: true ) telemetry.applicationInsights.verbosity - Verbosity to use for this sink, if not specified then the telemetry.defaultVerbosity will be used. (Optional) telemetry.applicationInsights.instrumentationKey - Defines the instrumentation key to use when sending telemetry to Azure Application Insights Example: telemetry : applicationInsights : instrumentationKey : ABC # Optional. Note: Required to be specified when turned on isEnabled : false # Optional. Default: false verbosity : trace # Optional. Default: N/A containerLogs : isEnabled : true # Optional. Default: true verbosity : trace # Optional. Default: N/A defaultVerbosity : error # Optional. Default: error","title":"Azure Application Insights"},{"location":"scraping/runtime-configuration/#azure-monitor","text":"Promitor interacts with Azure Monitor API to scrape all the required metrics. During troubleshooting it can be interesting to gain insights on what the API returns, for which you can opt-in. The behavior of this can be configured to fit your needs: azureMonitor.logging.informationLevel - Defines granularity of information that should be reported. Available options are Basic , Headers , Body & BodyAndHeaders . (Default: Basic ) azureMonitor.logging.isEnabled - Defines whether or not information concerning the integration with Azure Monitor API. (Default: false ) azureMonitor.integration.history.startingFromInHours - Defines the amount of hours Promitor will use to define the starting point of the time window used for metric queries. As an example, the default is 12 hours which means Promitor will fetch all metrics between now - 12 hours and now to find a matching metric. Typically this window can be very small but Promitor provides a margin by default to prevent problems for long aggregation periods. (Default: 12 ) Example: azureMonitor : logging : informationLevel : Basic # Optional. Default: Basic isEnabled : false # Optional. Default: false integration : history : startingFromInHours : 24 # Optional. Default: 12 Note: All telemetry is emitted as trace so you have to make sure telemetry is configured correctly.","title":"Azure Monitor"},{"location":"scraping/runtime-configuration/#overriding-configuration-with-environment-variables","text":"In certain scenarios you'd like to override what was configured in the runtime YAML. Therefore we provide the capability to override them via environment variables. Every environment variable should be prefixed with PROMITOR_YAML_OVERRIDE_ followed by the YAML hierarchy where every level is replaced with __ rather than a tab. Environment variables are not case sensitive. Our runtime configuration API endpoint allows you to verify if it was overriden and returns what will be used to run Promitor. Depending on the configuration that is changed it may be required to restart Promitor, for example changing the HTTP port.","title":"Overriding configuration with environment variables"},{"location":"scraping/runtime-configuration/#example","text":"Let's say we want to override the following HTTP port: server : httpPort : 80 An environment variable called PROMITOR_YAML_OVERRIDE_server__httpPort can be provided which specifies the new port. \u2190 back","title":"Example"},{"location":"scraping/providers/api-management/","tags":["Scraper","Resource Discovery","API","Integration","PaaS"],"text":"Azure API Management \u00b6 You can scrape an Azure API Management via the ApiManagement resource type. When using declared resources, the following fields need to be provided: instanceName - The name of the Azure API Management instance. locationName - The name of the regional deployment of the gateway. (optional) All supported metrics are documented in the official Azure Monitor documentation . Multi-region support \u00b6 Azure API Management instances can be deployed to multiple regions across the world. Promitor supports different scenarios: Report metrics for metrics for all locations (default) Scope metric to a single region by configuring locationName . Report metrics but split it across all regions by using the Location dimension. The following scraper-specific metric label will be added for scenario 2 & 3: location - Name of the location Example \u00b6 Here is an example configuration: name : promitor_demo_azureapimanagement_capacity description : \"The amount of capacity used an Azure API Management instance.\" resourceType : ApiManagement azureMetricConfiguration : metricName : Capacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - instanceName : promitor-api-gateway resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : api-management-landscape","title":"Azure API Management"},{"location":"scraping/providers/api-management/#azure-api-management","text":"You can scrape an Azure API Management via the ApiManagement resource type. When using declared resources, the following fields need to be provided: instanceName - The name of the Azure API Management instance. locationName - The name of the regional deployment of the gateway. (optional) All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure API Management"},{"location":"scraping/providers/api-management/#multi-region-support","text":"Azure API Management instances can be deployed to multiple regions across the world. Promitor supports different scenarios: Report metrics for metrics for all locations (default) Scope metric to a single region by configuring locationName . Report metrics but split it across all regions by using the Location dimension. The following scraper-specific metric label will be added for scenario 2 & 3: location - Name of the location","title":"Multi-region support"},{"location":"scraping/providers/api-management/#example","text":"Here is an example configuration: name : promitor_demo_azureapimanagement_capacity description : \"The amount of capacity used an Azure API Management instance.\" resourceType : ApiManagement azureMetricConfiguration : metricName : Capacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - instanceName : promitor-api-gateway resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : api-management-landscape","title":"Example"},{"location":"scraping/providers/app-plan/","tags":["Scraper","Resource Discovery","PaaS","Web","API"],"text":"Azure App Plan \u00b6 You can declare to scrape an Azure App Plan via the AppPlan resource type. When using declared resources, the following fields need to be provided: appPlanName - The name of the Azure App Plan All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_app_plan_percentage_memory description : \"Average percentage of memory usage on an Azure App Plan\" resourceType : AppPlan azureMetricConfiguration : metricName : MemoryPercentage aggregation : type : Average resources : # Optional, required when no resource discovery is configured - appPlanName : promitor-app-plan resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : app-plans-landscape","title":"Azure App Plan"},{"location":"scraping/providers/app-plan/#azure-app-plan","text":"You can declare to scrape an Azure App Plan via the AppPlan resource type. When using declared resources, the following fields need to be provided: appPlanName - The name of the Azure App Plan All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure App Plan"},{"location":"scraping/providers/app-plan/#example","text":"Here is an example configuration: name : azure_app_plan_percentage_memory description : \"Average percentage of memory usage on an Azure App Plan\" resourceType : AppPlan azureMetricConfiguration : metricName : MemoryPercentage aggregation : type : Average resources : # Optional, required when no resource discovery is configured - appPlanName : promitor-app-plan resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : app-plans-landscape","title":"Example"},{"location":"scraping/providers/application-gateway/","tags":["Scraper","Resource Discovery","Networking"],"text":"Azure Application Gateway \u00b6 You can declare to scrape an Azure Application Gateway via the ApplicationGateway resource type. When using declared resources, the following fields need to be provided: applicationGatewayName - The name of the Azure Application Gateway All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_application_gateway_milli_total_time description : \"Average milliseconds of total time on an Azure application gateway\" resourceType : ApplicationGateway azureMetricConfiguration : metricName : ApplicationGatewayTotalTime aggregation : type : Average resources : # Optional, required when no resource discovery is configured - applicationGatewayName : promitor-application-gateway-1 - applicationGatewayName : promitor-application-gateway-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : application-gateway-landscape","title":"Azure Application Gateway"},{"location":"scraping/providers/application-gateway/#azure-application-gateway","text":"You can declare to scrape an Azure Application Gateway via the ApplicationGateway resource type. When using declared resources, the following fields need to be provided: applicationGatewayName - The name of the Azure Application Gateway All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Application Gateway"},{"location":"scraping/providers/application-gateway/#example","text":"Here is an example configuration: name : azure_application_gateway_milli_total_time description : \"Average milliseconds of total time on an Azure application gateway\" resourceType : ApplicationGateway azureMetricConfiguration : metricName : ApplicationGatewayTotalTime aggregation : type : Average resources : # Optional, required when no resource discovery is configured - applicationGatewayName : promitor-application-gateway-1 - applicationGatewayName : promitor-application-gateway-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : application-gateway-landscape","title":"Example"},{"location":"scraping/providers/application-insights/","tags":["Scraper","Resource Discovery","Monitoring"],"text":"Azure Application Insights \u00b6 You can declare to scrape an Azure Application Insights via the ApplicationInsights resource type. When using declared resources, the following fields need to be provided: name - The name of the Azure Application Insights All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_application_insights_exceptions description : \"Average amount of server exceptions in Azure Application Insights\" resourceType : ApplicationInsights azureMetricConfiguration : metricName : exceptions/server aggregation : type : Average resources : # Optional, required when no resource discovery is configured - name : promitor-application-gateway-1 - name : promitor-application-gateway-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : application-insights-landscape","title":"Azure Application Insights"},{"location":"scraping/providers/application-insights/#azure-application-insights","text":"You can declare to scrape an Azure Application Insights via the ApplicationInsights resource type. When using declared resources, the following fields need to be provided: name - The name of the Azure Application Insights All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Application Insights"},{"location":"scraping/providers/application-insights/#example","text":"Here is an example configuration: name : azure_application_insights_exceptions description : \"Average amount of server exceptions in Azure Application Insights\" resourceType : ApplicationInsights azureMetricConfiguration : metricName : exceptions/server aggregation : type : Average resources : # Optional, required when no resource discovery is configured - name : promitor-application-gateway-1 - name : promitor-application-gateway-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : application-insights-landscape","title":"Example"},{"location":"scraping/providers/automation-account/","tags":["Scraper","Resource Discovery","Automation"],"text":"Azure Automation account \u00b6 You can scrape an Azure Automation account via the AutomationAccount resource type. When using declared resources, the following fields need to be provided: accountName - The name of the Azure Automation account. runbookName - The name of the runbook. (optional and only supported on limited metrics) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added : runbook_name - Name of the runbook Example \u00b6 Here is an example configuration: name : promitor_demo_automation_job_count description : \"Amount of jobs per Azure Automation account & job\" resourceType : AutomationAccount azureMetricConfiguration : metricName : TotalJob aggregation : type : Total resources : # Optional, required when no resource discovery is configured - resourceGroupName : promitor-sources accountName : promitor-sandbox runbookName : Example # Optional, currently only supported for 'TotalJob' metric resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : automation-accounts","title":"Azure Automation account"},{"location":"scraping/providers/automation-account/#azure-automation-account","text":"You can scrape an Azure Automation account via the AutomationAccount resource type. When using declared resources, the following fields need to be provided: accountName - The name of the Azure Automation account. runbookName - The name of the runbook. (optional and only supported on limited metrics) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added : runbook_name - Name of the runbook","title":"Azure Automation account"},{"location":"scraping/providers/automation-account/#example","text":"Here is an example configuration: name : promitor_demo_automation_job_count description : \"Amount of jobs per Azure Automation account & job\" resourceType : AutomationAccount azureMetricConfiguration : metricName : TotalJob aggregation : type : Total resources : # Optional, required when no resource discovery is configured - resourceGroupName : promitor-sources accountName : promitor-sandbox runbookName : Example # Optional, currently only supported for 'TotalJob' metric resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : automation-accounts","title":"Example"},{"location":"scraping/providers/blob-storage/","tags":["Scraper","Data","Storage"],"text":"Azure Blob Storage \u00b6 You can declare to scrape an Azure Queue via the BlobStorage resource type. The following fields need to be provided: accountName - The name of the Azure Storage account All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_storage_blobs_capacity description : \"The average capacity used by blobs in the storage account\" resourceType : BlobStorage azureMetricConfiguration : metricName : BlobCapacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - accountName : promitor-1 - accountName : promitor-2","title":"Azure Blob Storage"},{"location":"scraping/providers/blob-storage/#azure-blob-storage","text":"You can declare to scrape an Azure Queue via the BlobStorage resource type. The following fields need to be provided: accountName - The name of the Azure Storage account All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Blob Storage"},{"location":"scraping/providers/blob-storage/#example","text":"Here is an example configuration: name : azure_storage_blobs_capacity description : \"The average capacity used by blobs in the storage account\" resourceType : BlobStorage azureMetricConfiguration : metricName : BlobCapacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - accountName : promitor-1 - accountName : promitor-2","title":"Example"},{"location":"scraping/providers/cdn/","tags":["Scraper","Resource Discovery"],"text":"Azure Content Delivery Network (CDN) \u00b6 You can declare to scrape an Azure CDN via the Cdn resource type. When using declared resources, the following fields need to be provided: cdnName - The name of the Azure CDN resource All supported metrics are documented in the official Azure Monitor documentation . \ud83d\udea8 The availability of metrics depends on the SKU of the Azure CDN resource. Example \u00b6 Here is an example configuration: name : azure_cdn_requests description : \"Amount of requests sent to Azure CDN\" resourceType : Cdn azureMetricConfiguration : metricName : RequestCount aggregation : type : Total resources : # Optional, required when no resource discovery is configured - cdnName : promitor-cdn-1 - cdnName : promitor-cdn-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : cdn-landscape","title":"Azure Content Delivery Network (CDN)"},{"location":"scraping/providers/cdn/#azure-content-delivery-network-cdn","text":"You can declare to scrape an Azure CDN via the Cdn resource type. When using declared resources, the following fields need to be provided: cdnName - The name of the Azure CDN resource All supported metrics are documented in the official Azure Monitor documentation . \ud83d\udea8 The availability of metrics depends on the SKU of the Azure CDN resource.","title":"Azure Content Delivery Network (CDN)"},{"location":"scraping/providers/cdn/#example","text":"Here is an example configuration: name : azure_cdn_requests description : \"Amount of requests sent to Azure CDN\" resourceType : Cdn azureMetricConfiguration : metricName : RequestCount aggregation : type : Total resources : # Optional, required when no resource discovery is configured - cdnName : promitor-cdn-1 - cdnName : promitor-cdn-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : cdn-landscape","title":"Example"},{"location":"scraping/providers/container-instances/","tags":["Scraper","Resource Discovery","Containers"],"text":"Azure Container Instances \u00b6 You can declare to scrape an Azure Container Instances via the ContainerInstance resource type. When using declared resources, the following fields need to be provided: containerGroup - The name of the container group All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_container_instance_cpu_usage description : \"Average cpu usage of our 'promitor-container-instance' container instance\" resourceType : ContainerInstance azureMetricConfiguration : metricName : CpuUsage aggregation : type : Average resources : # Optional, required when no resource discovery is configured - containerGroup : promitor-container-instance-1 - containerGroup : promitor-container-instance-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : container-instances-landscape","title":"Azure Container Instances"},{"location":"scraping/providers/container-instances/#azure-container-instances","text":"You can declare to scrape an Azure Container Instances via the ContainerInstance resource type. When using declared resources, the following fields need to be provided: containerGroup - The name of the container group All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Container Instances"},{"location":"scraping/providers/container-instances/#example","text":"Here is an example configuration: name : azure_container_instance_cpu_usage description : \"Average cpu usage of our 'promitor-container-instance' container instance\" resourceType : ContainerInstance azureMetricConfiguration : metricName : CpuUsage aggregation : type : Average resources : # Optional, required when no resource discovery is configured - containerGroup : promitor-container-instance-1 - containerGroup : promitor-container-instance-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : container-instances-landscape","title":"Example"},{"location":"scraping/providers/container-registry/","tags":["Scraper","Resource Discovery","Containers"],"text":"Azure Container Registry \u00b6 You can declare to scrape an Azure Container Registry via the ContainerRegistry resource type. When using declared resources, the following fields need to be provided: registryName - The name of the registry All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_container_registry_total_pull_count description : \"Amount of images that were pulled from the container registry\" resourceType : ContainerRegistry azureMetricConfiguration : metricName : TotalPullCount aggregation : type : Average resources : # Optional, required when no resource discovery is configured - registryName : promitor-1 - registryName : promitor-2 resourceDiscoveryGroups : - name : registry-group resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : container-registry-landscape","title":"Azure Container Registry"},{"location":"scraping/providers/container-registry/#azure-container-registry","text":"You can declare to scrape an Azure Container Registry via the ContainerRegistry resource type. When using declared resources, the following fields need to be provided: registryName - The name of the registry All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Container Registry"},{"location":"scraping/providers/container-registry/#example","text":"Here is an example configuration: name : azure_container_registry_total_pull_count description : \"Amount of images that were pulled from the container registry\" resourceType : ContainerRegistry azureMetricConfiguration : metricName : TotalPullCount aggregation : type : Average resources : # Optional, required when no resource discovery is configured - registryName : promitor-1 - registryName : promitor-2 resourceDiscoveryGroups : - name : registry-group resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : container-registry-landscape","title":"Example"},{"location":"scraping/providers/cosmos-db/","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"],"text":"Azure Cosmos DB \u00b6 You can declare to scrape Cosmos Db via the CosmosDb resource type. When using declared resources, the following fields need to be provided: dbName - The name of the Cosmos Db to be scraped All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_cosmos_db_total_requests description : \"Demo cosmos query\" resourceType : CosmosDb azureMetricConfiguration : metricName : TotalRequests aggregation : type : Count resources : # Optional, required when no resource discovery is configured - dbName : cosmos-database-1 - dbName : cosmos-database-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : cosmos-db-landscape","title":"Azure Cosmos DB"},{"location":"scraping/providers/cosmos-db/#azure-cosmos-db","text":"You can declare to scrape Cosmos Db via the CosmosDb resource type. When using declared resources, the following fields need to be provided: dbName - The name of the Cosmos Db to be scraped All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Cosmos DB"},{"location":"scraping/providers/cosmos-db/#example","text":"Here is an example configuration: name : azure_cosmos_db_total_requests description : \"Demo cosmos query\" resourceType : CosmosDb azureMetricConfiguration : metricName : TotalRequests aggregation : type : Count resources : # Optional, required when no resource discovery is configured - dbName : cosmos-database-1 - dbName : cosmos-database-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : cosmos-db-landscape","title":"Example"},{"location":"scraping/providers/data-factory/","tags":["Scraper","Resource Discovery","Data","Integration","PaaS"],"text":"Azure Data Factory \u00b6 You can declare to scrape an Azure Data Factory resource via the DataFactory resource type. When using declared resources, the following fields need to be provided: factoryName - The name of the Azure Data Factory resource pipelineName - The name of the data pipeline (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: pipeline_name - Name of the data pipeline. Example \u00b6 Here is an example configuration: - name : azure_data_factory_pipeline_run_successful description : \"Amount of successful runs for 'data-pipeline-example' pipline in Azure Data Factory\" resourceType : DataFactory azureMetricConfiguration : metricName : PipelineSucceededRuns aggregation : type : Total resources : # Optional, required when no resource discovery is configured - factoryName : promitor-data-factory pipelineName : data-pipeline-example resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : data-factory-landscape","title":"Azure Data Factory"},{"location":"scraping/providers/data-factory/#azure-data-factory","text":"You can declare to scrape an Azure Data Factory resource via the DataFactory resource type. When using declared resources, the following fields need to be provided: factoryName - The name of the Azure Data Factory resource pipelineName - The name of the data pipeline (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: pipeline_name - Name of the data pipeline.","title":"Azure Data Factory"},{"location":"scraping/providers/data-factory/#example","text":"Here is an example configuration: - name : azure_data_factory_pipeline_run_successful description : \"Amount of successful runs for 'data-pipeline-example' pipline in Azure Data Factory\" resourceType : DataFactory azureMetricConfiguration : metricName : PipelineSucceededRuns aggregation : type : Total resources : # Optional, required when no resource discovery is configured - factoryName : promitor-data-factory pipelineName : data-pipeline-example resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : data-factory-landscape","title":"Example"},{"location":"scraping/providers/data-share/","tags":["Scraper","Resource Discovery","Data"],"text":"Azure Data Share \u00b6 You can declare to scrape an Azure Data Share resource via the DataShare resource type. When using declared resources, the following fields need to be provided: accountName - The name of the Azure Data Share account shareName - The name of the share (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: share_name - Name of the share. Example \u00b6 Here is an example configuration: - name : promitor_demo_data_share_received description : \"Amount of shares received from other parties per Azure Data Share account\" resourceType : DataShare azureMetricConfiguration : metricName : ShareSubscriptionCount aggregation : type : Maximum resources : # Optional, required when no resource discovery is configured - accountName : promitor-data-share shareName : Promitor resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : data-share-landscape","title":"Azure Data Share"},{"location":"scraping/providers/data-share/#azure-data-share","text":"You can declare to scrape an Azure Data Share resource via the DataShare resource type. When using declared resources, the following fields need to be provided: accountName - The name of the Azure Data Share account shareName - The name of the share (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: share_name - Name of the share.","title":"Azure Data Share"},{"location":"scraping/providers/data-share/#example","text":"Here is an example configuration: - name : promitor_demo_data_share_received description : \"Amount of shares received from other parties per Azure Data Share account\" resourceType : DataShare azureMetricConfiguration : metricName : ShareSubscriptionCount aggregation : type : Maximum resources : # Optional, required when no resource discovery is configured - accountName : promitor-data-share shareName : Promitor resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : data-share-landscape","title":"Example"},{"location":"scraping/providers/event-hubs/","tags":["Scraper","Resource Discovery","Messaging","Open Source"],"text":"Azure Event Hubs \u00b6 You can declare to scrape an Azure Event Hubs Queue via the EventHubs resource type. When using declared resources, the following fields need to be provided: namespace - The name of the Azure Event Hubs namespace. topicName - The name of the topic. (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: entity_name - Name of the topic Limitations \u00b6 As of today, it is not supported to combine topicName with EntityPath as a dimension. Example \u00b6 Here is an example configuration: name : azure_event_hubs_incoming_messages description : \"The number of incoming messages on an Azure Event Hubs topic\" resourceType : EventHubs azureMetricConfiguration : metricName : IncomingMessages aggregation : type : Total resources : # Optional, required when no resource discovery is configured - namespace : promitor-streaming topicName : orders - namespace : promitor-messaging topicName : sales resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : event-hubs-landscape","title":"Azure Event Hubs"},{"location":"scraping/providers/event-hubs/#azure-event-hubs","text":"You can declare to scrape an Azure Event Hubs Queue via the EventHubs resource type. When using declared resources, the following fields need to be provided: namespace - The name of the Azure Event Hubs namespace. topicName - The name of the topic. (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: entity_name - Name of the topic","title":"Azure Event Hubs"},{"location":"scraping/providers/event-hubs/#limitations","text":"As of today, it is not supported to combine topicName with EntityPath as a dimension.","title":"Limitations"},{"location":"scraping/providers/event-hubs/#example","text":"Here is an example configuration: name : azure_event_hubs_incoming_messages description : \"The number of incoming messages on an Azure Event Hubs topic\" resourceType : EventHubs azureMetricConfiguration : metricName : IncomingMessages aggregation : type : Total resources : # Optional, required when no resource discovery is configured - namespace : promitor-streaming topicName : orders - namespace : promitor-messaging topicName : sales resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : event-hubs-landscape","title":"Example"},{"location":"scraping/providers/express-route-circuit/","tags":["Scraper","Resource Discovery","Networking"],"text":"Azure Express Route Circuit \u00b6 You can declare to scrape an Azure Express Route Circuit (without Peerings) via the ExpressRouteCircuit resource type. When using declared resources, the following fields need to be provided: expressRouteCircuitName - The name of the Azure Express Route circuit All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_express_route_percentage_arp_availability description : \"Average percentage of arp availability on an Azure express route circuit\" resourceType : ExpressRouteCircuit azureMetricConfiguration : metricName : ArpAvailability aggregation : type : Average resources : # Optional, required when no resource discovery is configured - expressRouteCircuitName : promitor-express-route-circuit-1 - expressRouteCircuitName : promitor-express-route-circuit-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : express-route-circuit-landscape","title":"Azure Express Route Circuit"},{"location":"scraping/providers/express-route-circuit/#azure-express-route-circuit","text":"You can declare to scrape an Azure Express Route Circuit (without Peerings) via the ExpressRouteCircuit resource type. When using declared resources, the following fields need to be provided: expressRouteCircuitName - The name of the Azure Express Route circuit All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Express Route Circuit"},{"location":"scraping/providers/express-route-circuit/#example","text":"Here is an example configuration: name : azure_express_route_percentage_arp_availability description : \"Average percentage of arp availability on an Azure express route circuit\" resourceType : ExpressRouteCircuit azureMetricConfiguration : metricName : ArpAvailability aggregation : type : Average resources : # Optional, required when no resource discovery is configured - expressRouteCircuitName : promitor-express-route-circuit-1 - expressRouteCircuitName : promitor-express-route-circuit-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : express-route-circuit-landscape","title":"Example"},{"location":"scraping/providers/file-storage/","tags":["Scraper","Resource Discovery","Data","Storage"],"text":"Azure File Storage \u00b6 You can declare to scrape an Azure Queue via the FileStorage resource type. The following fields need to be provided: accountName - The name of the Azure Storage account All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_storage_files_capacity description : \"The average capacity used by files in the storage account\" resourceType : FileStorage azureMetricConfiguration : metricName : FileCapacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - accountName : promitor-1 - accountName : promitor-2","title":"Azure File Storage"},{"location":"scraping/providers/file-storage/#azure-file-storage","text":"You can declare to scrape an Azure Queue via the FileStorage resource type. The following fields need to be provided: accountName - The name of the Azure Storage account All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure File Storage"},{"location":"scraping/providers/file-storage/#example","text":"Here is an example configuration: name : azure_storage_files_capacity description : \"The average capacity used by files in the storage account\" resourceType : FileStorage azureMetricConfiguration : metricName : FileCapacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - accountName : promitor-1 - accountName : promitor-2","title":"Example"},{"location":"scraping/providers/front-door/","tags":["Scraper","Resource Discovery","Networking"],"text":"Azure Front Door \u00b6 You can declare to scrape an Azure Front Door via the FrontDoor resource type. When using declared resources, the following fields need to be provided: name - The name of the Azure Front Door All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : promitor_demo_frontdoor_backend_health description : \"Health percentage for backends in Azure Front Door\" resourceType : FrontDoor azureMetricConfiguration : metricName : BackendHealthPercentage aggregation : type : Average resources : # Optional, required when no resource discovery is configured - name : promitor-landscape resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : front-door-landscape","title":"Azure Front Door"},{"location":"scraping/providers/front-door/#azure-front-door","text":"You can declare to scrape an Azure Front Door via the FrontDoor resource type. When using declared resources, the following fields need to be provided: name - The name of the Azure Front Door All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Front Door"},{"location":"scraping/providers/front-door/#example","text":"Here is an example configuration: name : promitor_demo_frontdoor_backend_health description : \"Health percentage for backends in Azure Front Door\" resourceType : FrontDoor azureMetricConfiguration : metricName : BackendHealthPercentage aggregation : type : Average resources : # Optional, required when no resource discovery is configured - name : promitor-landscape resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : front-door-landscape","title":"Example"},{"location":"scraping/providers/function-app/","tags":["Scraper","Resource Discovery","Serverless","PaaS"],"text":"Azure Function App \u00b6 You can declare to scrape an Azure Function App via the FunctionApp resource type. When using declared resources, the following fields need to be provided: functionAppName - The name of the Azure Function App slotName - The name of the deployment slot (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: slot_name - Name of the deployment slot. If none is specified, production will be used. Example \u00b6 Here is an example configuration: name : azure_function_requests description : \"Amount of requests for an Azure Function App\" resourceType : FunctionApp azureMetricConfiguration : metricName : Requests aggregation : type : Total resources : # Optional, required when no resource discovery is configured - functionAppName : promitor-function-app resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : function-app-landscape","title":"Azure Function App"},{"location":"scraping/providers/function-app/#azure-function-app","text":"You can declare to scrape an Azure Function App via the FunctionApp resource type. When using declared resources, the following fields need to be provided: functionAppName - The name of the Azure Function App slotName - The name of the deployment slot (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: slot_name - Name of the deployment slot. If none is specified, production will be used.","title":"Azure Function App"},{"location":"scraping/providers/function-app/#example","text":"Here is an example configuration: name : azure_function_requests description : \"Amount of requests for an Azure Function App\" resourceType : FunctionApp azureMetricConfiguration : metricName : Requests aggregation : type : Total resources : # Optional, required when no resource discovery is configured - functionAppName : promitor-function-app resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : function-app-landscape","title":"Example"},{"location":"scraping/providers/generic-azure-resource/","tags":["Scraper"],"text":"Generic Azure Resource \u00b6 You can declare to scrape a generic Azure resource via the Generic resource type. Promitor simplifies defining resource URIs by using the subscription & resource group defined in azureMetadata so that your configuration is small & readable. Mandatory fields : resourceUri - The uri of the Azure resource to scrape. Optional fields : resourceGroupName - the resource group for this resource. It overrides the one defined in azureMetadata . subscriptionId - the subscription ID for this resource. It overrides the one defined in azureMetadata . filter - The filter to use to have fine-grained metrics. Example: EntityName eq 'orders' . See Azure Monitor REST API Filter Syntax . Example \u00b6 Here is an example configuration: name : azure_service_bus_active_messages description : \"Amount of active messages of the 'myqueue' queue (determined with Generic provider)\" resourceType : Generic azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : # Will scrape subscriptions/<sub>/resourceGroups/<rg>/providers/Microsoft.ServiceBus/namespaces/my-promitor-messaging # Where <sub> & <rg> are coming from azureMetadata - resourceUri : Microsoft.ServiceBus/namespaces/my-promitor-messaging filter : EntityName eq 'orders' # Will scrape subscriptions/<sub>/resourceGroups/<rg>/providers/Microsoft.ServiceBus/namespaces/my-other-promitor-messaging # Where <sub> & <rg> are coming from the definition of this resource. - resourceUri : Microsoft.ServiceBus/namespaces/my-other-promitor-messaging subscriptionId : example-subscription resourceGroupName : example-resource-group","title":"Generic"},{"location":"scraping/providers/generic-azure-resource/#generic-azure-resource","text":"You can declare to scrape a generic Azure resource via the Generic resource type. Promitor simplifies defining resource URIs by using the subscription & resource group defined in azureMetadata so that your configuration is small & readable. Mandatory fields : resourceUri - The uri of the Azure resource to scrape. Optional fields : resourceGroupName - the resource group for this resource. It overrides the one defined in azureMetadata . subscriptionId - the subscription ID for this resource. It overrides the one defined in azureMetadata . filter - The filter to use to have fine-grained metrics. Example: EntityName eq 'orders' . See Azure Monitor REST API Filter Syntax .","title":"Generic Azure Resource"},{"location":"scraping/providers/generic-azure-resource/#example","text":"Here is an example configuration: name : azure_service_bus_active_messages description : \"Amount of active messages of the 'myqueue' queue (determined with Generic provider)\" resourceType : Generic azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : # Will scrape subscriptions/<sub>/resourceGroups/<rg>/providers/Microsoft.ServiceBus/namespaces/my-promitor-messaging # Where <sub> & <rg> are coming from azureMetadata - resourceUri : Microsoft.ServiceBus/namespaces/my-promitor-messaging filter : EntityName eq 'orders' # Will scrape subscriptions/<sub>/resourceGroups/<rg>/providers/Microsoft.ServiceBus/namespaces/my-other-promitor-messaging # Where <sub> & <rg> are coming from the definition of this resource. - resourceUri : Microsoft.ServiceBus/namespaces/my-other-promitor-messaging subscriptionId : example-subscription resourceGroupName : example-resource-group","title":"Example"},{"location":"scraping/providers/iot-hub-device-provisioning-service/","tags":["Scraper","Resource Discovery","IoT","PaaS"],"text":"Azure IoT Hub Device Provisioning Service (DPS) \u00b6 You can declare to scrape an Azure IoT Hub Device Provisioning Service (DPS) via the DeviceProvisioningService resource type. When using declared resources, the following fields need to be provided: deviceProvisioningServiceName - The name of the Azure IoT Hub Device Provisioning Service (DPS) All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_dps_attestation_attempts description : \"The number of device attestations attempted\" resourceType : DeviceProvisioningService azureMetricConfiguration : metricName : AttestationAttempts aggregation : type : Total resources : # Optional, required when no resource discovery is configured - deviceProvisioningServiceName : promitor-1 - deviceProvisioningServiceName : promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : iot-hub-dps-landscape","title":"Azure IoT Hub Device Provisioning Service (DPS)"},{"location":"scraping/providers/iot-hub-device-provisioning-service/#azure-iot-hub-device-provisioning-service-dps","text":"You can declare to scrape an Azure IoT Hub Device Provisioning Service (DPS) via the DeviceProvisioningService resource type. When using declared resources, the following fields need to be provided: deviceProvisioningServiceName - The name of the Azure IoT Hub Device Provisioning Service (DPS) All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure IoT Hub Device Provisioning Service (DPS)"},{"location":"scraping/providers/iot-hub-device-provisioning-service/#example","text":"Here is an example configuration: name : azure_dps_attestation_attempts description : \"The number of device attestations attempted\" resourceType : DeviceProvisioningService azureMetricConfiguration : metricName : AttestationAttempts aggregation : type : Total resources : # Optional, required when no resource discovery is configured - deviceProvisioningServiceName : promitor-1 - deviceProvisioningServiceName : promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : iot-hub-dps-landscape","title":"Example"},{"location":"scraping/providers/iot-hub/","tags":["Scraper","Resource Discovery","IoT","PaaS"],"text":"Azure IoT Hub \u00b6 You can declare to scrape an Azure IoT Hub via the IoTHub resource type. When using declared resources, the following fields need to be provided: ioTHubName - The name of the Azure IoT Hub All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_iot_hub_total_devices description : \"The number of devices registered to your IoT hub\" resourceType : IoTHub azureMetricConfiguration : metricName : devices.totalDevices aggregation : type : Total resources : # Optional, required when no resource discovery is configured - ioTHubName : promitor-1 - ioTHubName : promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : iot-hub-landscape","title":"Azure IoT Hub"},{"location":"scraping/providers/iot-hub/#azure-iot-hub","text":"You can declare to scrape an Azure IoT Hub via the IoTHub resource type. When using declared resources, the following fields need to be provided: ioTHubName - The name of the Azure IoT Hub All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure IoT Hub"},{"location":"scraping/providers/iot-hub/#example","text":"Here is an example configuration: name : azure_iot_hub_total_devices description : \"The number of devices registered to your IoT hub\" resourceType : IoTHub azureMetricConfiguration : metricName : devices.totalDevices aggregation : type : Total resources : # Optional, required when no resource discovery is configured - ioTHubName : promitor-1 - ioTHubName : promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : iot-hub-landscape","title":"Example"},{"location":"scraping/providers/key-vault/","tags":["Scraper","Resource Discovery","Security"],"text":"Azure Key Vault \u00b6 You can declare to scrape an Azure Key Vault via the KeyVault resource type. When using declared resources, the following fields need to be provided: vaultName - The name of the Azure Key Vault All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_key_vault_api_latency description : \"The overall latency of service api requests\" resourceType : KeyVault azureMetricConfiguration : metricName : ServiceApiLatency aggregation : type : Average resources : # Optional, required when no resource discovery is configured - vaultName : promitor-1 - vaultName : promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : key-vault-landscape","title":"Azure Key Vault"},{"location":"scraping/providers/key-vault/#azure-key-vault","text":"You can declare to scrape an Azure Key Vault via the KeyVault resource type. When using declared resources, the following fields need to be provided: vaultName - The name of the Azure Key Vault All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Key Vault"},{"location":"scraping/providers/key-vault/#example","text":"Here is an example configuration: name : azure_key_vault_api_latency description : \"The overall latency of service api requests\" resourceType : KeyVault azureMetricConfiguration : metricName : ServiceApiLatency aggregation : type : Average resources : # Optional, required when no resource discovery is configured - vaultName : promitor-1 - vaultName : promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : key-vault-landscape","title":"Example"},{"location":"scraping/providers/kubernetes/","tags":["Scraper","Resource Discovery","Containers","Kubernetes","Open Source"],"text":"Azure Kubernetes Service \u00b6 You can declare to scrape an Azure Kubernetes Service (AKS) via the KubernetesService resource type. When using declared resources, the following fields need to be provided: clusterName - The name of the Azure Kubernetes Service All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_kubernetes_available_cpu_cores description : \"Available CPU cores in cluster\" resourceType : KubernetesService azureMetricConfiguration : metricName : kube_node_status_allocatable_cpu_cores aggregation : type : Average resources : # Optional, required when no resource discovery is configured - clusterName : promitor-aks resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : kubernetes-service-landscape","title":"Azure Kubernetes Service"},{"location":"scraping/providers/kubernetes/#azure-kubernetes-service","text":"You can declare to scrape an Azure Kubernetes Service (AKS) via the KubernetesService resource type. When using declared resources, the following fields need to be provided: clusterName - The name of the Azure Kubernetes Service All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Kubernetes Service"},{"location":"scraping/providers/kubernetes/#example","text":"Here is an example configuration: name : azure_kubernetes_available_cpu_cores description : \"Available CPU cores in cluster\" resourceType : KubernetesService azureMetricConfiguration : metricName : kube_node_status_allocatable_cpu_cores aggregation : type : Average resources : # Optional, required when no resource discovery is configured - clusterName : promitor-aks resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : kubernetes-service-landscape","title":"Example"},{"location":"scraping/providers/load-balancer/","tags":["Scraper","Resource Discovery","Networking"],"text":"Azure Load Balancer \u00b6 You can declare to scrape an Azure Load Balancer via the LoadBalancer resource type. When using declared resources, the following fields need to be provided: loadBalancerName - The name of the Azure Load Balancer resource All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_load_balancer_traffic_bytes description : \"Average amount of bytes sent through an Azure Load Balancer\" resourceType : LoadBalancer azureMetricConfiguration : metricName : ByteCount aggregation : type : Average resources : # Optional, required when no resource discovery is configured - loadBalancerName : promitor-load-balancer-1 - loadBalancerName : promitor-load-balancer-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : load-balancer-landscape","title":"Azure Load Balancer"},{"location":"scraping/providers/load-balancer/#azure-load-balancer","text":"You can declare to scrape an Azure Load Balancer via the LoadBalancer resource type. When using declared resources, the following fields need to be provided: loadBalancerName - The name of the Azure Load Balancer resource All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Load Balancer"},{"location":"scraping/providers/load-balancer/#example","text":"Here is an example configuration: name : azure_load_balancer_traffic_bytes description : \"Average amount of bytes sent through an Azure Load Balancer\" resourceType : LoadBalancer azureMetricConfiguration : metricName : ByteCount aggregation : type : Average resources : # Optional, required when no resource discovery is configured - loadBalancerName : promitor-load-balancer-1 - loadBalancerName : promitor-load-balancer-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : load-balancer-landscape","title":"Example"},{"location":"scraping/providers/log-analytics/","tags":["Scraper","Data"],"text":"Azure Log Analytics \u00b6 You can declare to scrape an Azure Log Analytics via the LogAnalytics resource type. The following fields need to be provided: workspaceName - The name of the Azure Log Analytics workspaceId - The workspace ID of the Azure Log Analytics resource The Azure Log Analytics scraper is configured differently compare to others Azure resources. Ensure that logAnalyticsConfiguration is configured instead of azureMetricConfiguration : logAnalyticsConfiguration.query - The query used to query value from logAnalytics the result of the query need to be 1 row only (use take 1 ) the result of the query need to have 1 column named 'result' only (use project result ) logAnalyticsConfiguration.aggregation.interval - The aggregation that needs to be used when querying Log Analytics. If you don't set this, it will get the value from metricDefaults Example \u00b6 Here is an example configuration: name : azure_logs_analytics description : \"Get number of error from SparkLoggingEvent\" resourceType : LogAnalytics logAnalyticsConfiguration : query : SparkLoggingEvent_CL | where Level == \"ERROR\" | summarize result = count() | take 1 | project result aggregation : interval : 10:00:00:00 resources : - workspaceId : 0202fe93-55de-4c08-ae83-b5e4a3b6bed6 workspaceName : afs-log-analytics","title":"Azure Log Analytics"},{"location":"scraping/providers/log-analytics/#azure-log-analytics","text":"You can declare to scrape an Azure Log Analytics via the LogAnalytics resource type. The following fields need to be provided: workspaceName - The name of the Azure Log Analytics workspaceId - The workspace ID of the Azure Log Analytics resource The Azure Log Analytics scraper is configured differently compare to others Azure resources. Ensure that logAnalyticsConfiguration is configured instead of azureMetricConfiguration : logAnalyticsConfiguration.query - The query used to query value from logAnalytics the result of the query need to be 1 row only (use take 1 ) the result of the query need to have 1 column named 'result' only (use project result ) logAnalyticsConfiguration.aggregation.interval - The aggregation that needs to be used when querying Log Analytics. If you don't set this, it will get the value from metricDefaults","title":"Azure Log Analytics"},{"location":"scraping/providers/log-analytics/#example","text":"Here is an example configuration: name : azure_logs_analytics description : \"Get number of error from SparkLoggingEvent\" resourceType : LogAnalytics logAnalyticsConfiguration : query : SparkLoggingEvent_CL | where Level == \"ERROR\" | summarize result = count() | take 1 | project result aggregation : interval : 10:00:00:00 resources : - workspaceId : 0202fe93-55de-4c08-ae83-b5e4a3b6bed6 workspaceName : afs-log-analytics","title":"Example"},{"location":"scraping/providers/logic-apps/","tags":["Scraper","Resource Discovery","Integration","PaaS"],"text":"Azure Logic Apps \u00b6 You can declare to scrape an Azure Logic App via the LogicApp resource type. When using declared resources, the following fields need to be provided: workflowName - The name of the Azure Logic App All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_logic_apps_failed_run description : \"Total amount of failed runs for Azure Logic Apps\" resourceType : LogicApp azureMetricConfiguration : metricName : RunsFailed aggregation : type : Total resources : # Optional, required when no resource discovery is configured - workflowName : promitor-workflow-1 - workflowName : promitor-workflow-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : logic-apps-landscape","title":"Azure Logic Apps"},{"location":"scraping/providers/logic-apps/#azure-logic-apps","text":"You can declare to scrape an Azure Logic App via the LogicApp resource type. When using declared resources, the following fields need to be provided: workflowName - The name of the Azure Logic App All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Logic Apps"},{"location":"scraping/providers/logic-apps/#example","text":"Here is an example configuration: name : azure_logic_apps_failed_run description : \"Total amount of failed runs for Azure Logic Apps\" resourceType : LogicApp azureMetricConfiguration : metricName : RunsFailed aggregation : type : Total resources : # Optional, required when no resource discovery is configured - workflowName : promitor-workflow-1 - workflowName : promitor-workflow-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : logic-apps-landscape","title":"Example"},{"location":"scraping/providers/maria-db/","tags":["Scraper","Resource Discovery","Data","Open Source"],"text":"Azure Database for MariaDB \u00b6 You can declare to scrape an Azure Database for MariaDB via the MariaDb resource type. When using declared resources, the following fields need to be provided: serverName - The name of the Azure Database for MariaDB server All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_db_mariadb_percentage_cpu description : \"Average percentage cpu usage on an Azure Database for MariaDB\" resourceType : MariaDb azureMetricConfiguration : metricName : cpu_percent aggregation : type : Average resources : # Optional, required when no resource discovery is configured - serverName : promitor-maria-db-1 - serverName : promitor-maria-db-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : maria-db-landscape","title":"Azure Database for MariaDB"},{"location":"scraping/providers/maria-db/#azure-database-for-mariadb","text":"You can declare to scrape an Azure Database for MariaDB via the MariaDb resource type. When using declared resources, the following fields need to be provided: serverName - The name of the Azure Database for MariaDB server All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Database for MariaDB"},{"location":"scraping/providers/maria-db/#example","text":"Here is an example configuration: name : azure_db_mariadb_percentage_cpu description : \"Average percentage cpu usage on an Azure Database for MariaDB\" resourceType : MariaDb azureMetricConfiguration : metricName : cpu_percent aggregation : type : Average resources : # Optional, required when no resource discovery is configured - serverName : promitor-maria-db-1 - serverName : promitor-maria-db-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : maria-db-landscape","title":"Example"},{"location":"scraping/providers/monitor-autoscale/","tags":["Scraper","Resource Discovery","Monitoring"],"text":"Azure Monitor Autoscale \u00b6 You can declare to scrape an Azure Monitor Autoscale via the MonitorAutoscale resource type. When using declared resources, the following fields need to be provided: autoscaleSettingsName - The name of the Azure Monitor Autoscale settings All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: - name : promitor_demo_appplan_autoscale_observed_capacity description : \"Average amount of current instances for an Azure App Plan with Azure Monitor Autoscale\" resourceType : MonitorAutoscale labels : app : promitor azureMetricConfiguration : metricName : ObservedCapacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - autoscaleSettingsName : app-service-autoscaling-rules resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : autoscaling-rules","title":"Azure Monitor Autoscale"},{"location":"scraping/providers/monitor-autoscale/#azure-monitor-autoscale","text":"You can declare to scrape an Azure Monitor Autoscale via the MonitorAutoscale resource type. When using declared resources, the following fields need to be provided: autoscaleSettingsName - The name of the Azure Monitor Autoscale settings All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Monitor Autoscale"},{"location":"scraping/providers/monitor-autoscale/#example","text":"Here is an example configuration: - name : promitor_demo_appplan_autoscale_observed_capacity description : \"Average amount of current instances for an Azure App Plan with Azure Monitor Autoscale\" resourceType : MonitorAutoscale labels : app : promitor azureMetricConfiguration : metricName : ObservedCapacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - autoscaleSettingsName : app-service-autoscaling-rules resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : autoscaling-rules","title":"Example"},{"location":"scraping/providers/mysql/","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"],"text":"Azure Database for MySQL \u00b6 You can declare to scrape an Azure Database for MySQL server via the MySql resource type. When using declared resources, the following fields need to be provided: serverName - The name of the MySQL server type - The type of MySQL server. (optional) Allowed values are Simple (default) & Flexible All supported metrics are documented in the official Azure Monitor documentation: Simple servers Flexible servers Limitations \u00b6 Resource discovery will discover all types of servers and thus the used metrics should match all of the types. You can use tags to define which resources to include, if you need filtering capabilities. Example \u00b6 Here is an example configuration: name : azure_my_sql_cpu_percent description : \"The CPU percentage on the server\" resourceType : MySql scraping : schedule : \"0 */2 * ? * *\" azureMetricConfiguration : metricName : cpu_percent aggregation : type : Average interval : 00:01:00 resources : # Optional, required when no resource discovery is configured - serverName : Promitor-1 - serverName : Promitor-2 type : Flexible resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : mysql-database-landscape","title":"Azure Database for MySQL"},{"location":"scraping/providers/mysql/#azure-database-for-mysql","text":"You can declare to scrape an Azure Database for MySQL server via the MySql resource type. When using declared resources, the following fields need to be provided: serverName - The name of the MySQL server type - The type of MySQL server. (optional) Allowed values are Simple (default) & Flexible All supported metrics are documented in the official Azure Monitor documentation: Simple servers Flexible servers","title":"Azure Database for MySQL"},{"location":"scraping/providers/mysql/#limitations","text":"Resource discovery will discover all types of servers and thus the used metrics should match all of the types. You can use tags to define which resources to include, if you need filtering capabilities.","title":"Limitations"},{"location":"scraping/providers/mysql/#example","text":"Here is an example configuration: name : azure_my_sql_cpu_percent description : \"The CPU percentage on the server\" resourceType : MySql scraping : schedule : \"0 */2 * ? * *\" azureMetricConfiguration : metricName : cpu_percent aggregation : type : Average interval : 00:01:00 resources : # Optional, required when no resource discovery is configured - serverName : Promitor-1 - serverName : Promitor-2 type : Flexible resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : mysql-database-landscape","title":"Example"},{"location":"scraping/providers/network-gateway/","tags":["Scraper","Resource Discovery","Networking"],"text":"Azure Network Gateway \u00b6 You can declare to scrape an Azure Network Gateway via the NetworkGateway resource type. When using declared resources, the following fields need to be provided: networkGatewayName - The name of the Azure Network Gateway All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_network_gateway_packages description : \"Average packages on an Azure network gateway\" resourceType : NetworkGateway azureMetricConfiguration : metricName : ExpressRouteGatewayPacketsPerSecond aggregation : type : Average resources : # Optional, required when no resource discovery is configured - networkGatewayName : promitor-network-gateway-1 - networkGatewayName : promitor-network-gateway-2 resourceDiscoveryGroups : - name : network-gateway-group resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : network-gateway-landscape","title":"Azure Network Gateway"},{"location":"scraping/providers/network-gateway/#azure-network-gateway","text":"You can declare to scrape an Azure Network Gateway via the NetworkGateway resource type. When using declared resources, the following fields need to be provided: networkGatewayName - The name of the Azure Network Gateway All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Network Gateway"},{"location":"scraping/providers/network-gateway/#example","text":"Here is an example configuration: name : azure_network_gateway_packages description : \"Average packages on an Azure network gateway\" resourceType : NetworkGateway azureMetricConfiguration : metricName : ExpressRouteGatewayPacketsPerSecond aggregation : type : Average resources : # Optional, required when no resource discovery is configured - networkGatewayName : promitor-network-gateway-1 - networkGatewayName : promitor-network-gateway-2 resourceDiscoveryGroups : - name : network-gateway-group resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : network-gateway-landscape","title":"Example"},{"location":"scraping/providers/network-interface/","tags":["Scraper","Resource Discovery","Networking"],"text":"Azure Network Interface \u00b6 You can declare to scrape an Azure Network Interface via the NetworkInterface resource type. When using declared resources, the following fields need to be provided: networkInterfaceName - The name of the network interface All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_network_interface_bytes_received_rate description : \"Number of bytes the Network Interface sent\" resourceType : NetworkInterface azureMetricConfiguration : metricName : BytesReceivedRate aggregation : type : Average resources : # Optional, required when no resource discovery is configured - networkInterfaceName : promitor-network-interface-1 - networkInterfaceName : promitor-network-interface-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : network-interfaces-landscape","title":"Azure Network Interface"},{"location":"scraping/providers/network-interface/#azure-network-interface","text":"You can declare to scrape an Azure Network Interface via the NetworkInterface resource type. When using declared resources, the following fields need to be provided: networkInterfaceName - The name of the network interface All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Network Interface"},{"location":"scraping/providers/network-interface/#example","text":"Here is an example configuration: name : azure_network_interface_bytes_received_rate description : \"Number of bytes the Network Interface sent\" resourceType : NetworkInterface azureMetricConfiguration : metricName : BytesReceivedRate aggregation : type : Average resources : # Optional, required when no resource discovery is configured - networkInterfaceName : promitor-network-interface-1 - networkInterfaceName : promitor-network-interface-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : network-interfaces-landscape","title":"Example"},{"location":"scraping/providers/postgresql/","tags":["Scraper","Resource Discovery","SQL","Data","Open Source"],"text":"Azure Database for PostgreSQL \u00b6 You can declare to scrape an Azure Database for PostgreSQL server via the PostgreSql resource type. When using declared resources, the following fields need to be provided: serverName - The name of the PostgreSQL server type - The type of PostgreSQL server. (optional) Allowed values are Simple (default), Flexible & Hyperscale . All supported metrics are documented in the official Azure Monitor documentation: Simple servers Flexible servers Hyperscale servers Limitations \u00b6 Resource discovery will discover all types of servers and thus the used metrics should match all of the types. You can use tags to define which resources to include, if you need filtering capabilities. Example \u00b6 Here is an example configuration: name : azure_postgre_sql_cpu_percent description : \"The CPU percentage on the server\" resourceType : PostgreSql scraping : schedule : \"0 */2 * ? * *\" azureMetricConfiguration : metricName : cpu_percent aggregation : type : Average interval : 00:01:00 resources : # Optional, required when no resource discovery is configured - serverName : Promitor-1 - serverName : Promitor-2 type : Flexible resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : postgres-database-landscape","title":"Azure Database for PostgreSQL"},{"location":"scraping/providers/postgresql/#azure-database-for-postgresql","text":"You can declare to scrape an Azure Database for PostgreSQL server via the PostgreSql resource type. When using declared resources, the following fields need to be provided: serverName - The name of the PostgreSQL server type - The type of PostgreSQL server. (optional) Allowed values are Simple (default), Flexible & Hyperscale . All supported metrics are documented in the official Azure Monitor documentation: Simple servers Flexible servers Hyperscale servers","title":"Azure Database for PostgreSQL"},{"location":"scraping/providers/postgresql/#limitations","text":"Resource discovery will discover all types of servers and thus the used metrics should match all of the types. You can use tags to define which resources to include, if you need filtering capabilities.","title":"Limitations"},{"location":"scraping/providers/postgresql/#example","text":"Here is an example configuration: name : azure_postgre_sql_cpu_percent description : \"The CPU percentage on the server\" resourceType : PostgreSql scraping : schedule : \"0 */2 * ? * *\" azureMetricConfiguration : metricName : cpu_percent aggregation : type : Average interval : 00:01:00 resources : # Optional, required when no resource discovery is configured - serverName : Promitor-1 - serverName : Promitor-2 type : Flexible resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : postgres-database-landscape","title":"Example"},{"location":"scraping/providers/redis-cache/","tags":["Scraper","Resource Discovery","Data","Caching","Open Source"],"text":"Azure Cache for Redis \u00b6 You can declare to scrape an Azure Cache for Redis via the RedisCache resource type. When using declared resources, the following fields need to be provided: cacheName - The name of the Redis Cache instance All supported metrics are documented in the official Azure Monitor documentation . You can find more documentation on each metric in the Azure Cache for Redis monitoring documentation . Example \u00b6 Here is an example configuration: name : azure_redis_cache_cache_hits description : \"The number of successful key lookups during the specified reporting interval. This maps to keyspace_hits from the Redis INFO command.\" resourceType : RedisCache scraping : schedule : \"0 */2 * ? * *\" azureMetricConfiguration : metricName : CacheHits aggregation : type : Total interval : 00:01:00 resources : # Optional, required when no resource discovery is configured - cacheName : Promitor-1 - cacheName : Promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : redis-cache-landscape","title":"Azure Cache for Redis"},{"location":"scraping/providers/redis-cache/#azure-cache-for-redis","text":"You can declare to scrape an Azure Cache for Redis via the RedisCache resource type. When using declared resources, the following fields need to be provided: cacheName - The name of the Redis Cache instance All supported metrics are documented in the official Azure Monitor documentation . You can find more documentation on each metric in the Azure Cache for Redis monitoring documentation .","title":"Azure Cache for Redis"},{"location":"scraping/providers/redis-cache/#example","text":"Here is an example configuration: name : azure_redis_cache_cache_hits description : \"The number of successful key lookups during the specified reporting interval. This maps to keyspace_hits from the Redis INFO command.\" resourceType : RedisCache scraping : schedule : \"0 */2 * ? * *\" azureMetricConfiguration : metricName : CacheHits aggregation : type : Total interval : 00:01:00 resources : # Optional, required when no resource discovery is configured - cacheName : Promitor-1 - cacheName : Promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : redis-cache-landscape","title":"Example"},{"location":"scraping/providers/redis-enterprise-cache/","tags":["Scraper","Resource Discovery","Data","Caching","Open Source"],"text":"Azure Cache for Redis Enterprise \u00b6 You can declare to scrape an Azure Cache for Redis Enterprise via the RedisEnterpriseCache resource type. When using declared resources, the following fields need to be provided: cacheName - The name of the Azure Cache for Redis Enterprise resource All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_cache_redis_enterprise_percentage_cpu description : \"Average percentage cpu usage on an Azure Cache for Redis Enterprise\" resourceType : RedisEnterpriseCache azureMetricConfiguration : metricName : usedmemorypercentage aggregation : type : Average resources : # Optional, required when no resource discovery is configured - cacheName : promitor-redis-enterprise-cache-1 - cacheName : promitor-redis-enterprise-cache-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : redis-enterprise-cache-landscape","title":"Azure Cache for Redis Enterprise"},{"location":"scraping/providers/redis-enterprise-cache/#azure-cache-for-redis-enterprise","text":"You can declare to scrape an Azure Cache for Redis Enterprise via the RedisEnterpriseCache resource type. When using declared resources, the following fields need to be provided: cacheName - The name of the Azure Cache for Redis Enterprise resource All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Cache for Redis Enterprise"},{"location":"scraping/providers/redis-enterprise-cache/#example","text":"Here is an example configuration: name : azure_cache_redis_enterprise_percentage_cpu description : \"Average percentage cpu usage on an Azure Cache for Redis Enterprise\" resourceType : RedisEnterpriseCache azureMetricConfiguration : metricName : usedmemorypercentage aggregation : type : Average resources : # Optional, required when no resource discovery is configured - cacheName : promitor-redis-enterprise-cache-1 - cacheName : promitor-redis-enterprise-cache-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : redis-enterprise-cache-landscape","title":"Example"},{"location":"scraping/providers/service-bus-namespace/","tags":["Scraper","Resource Discovery","Integration","Messaging"],"text":"Azure Service Bus Namespace \u00b6 You can declare to scrape an Azure Service Bus namespace via the ServiceBusNamespace resource type. When using declared resources, the following fields need to be provided: namespace - The name of the Azure Service Bus namespace queueName - The name of the queue (optional) topicName - The name of the topic (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: entity_name - Name of the queue Limitations \u00b6 No support for queueName & topicName for the same resource, for example: resources : - namespace : promitor-messaging queueName : orders topicName : sales No support for combining the queueName & EntityPath dimensions Example \u00b6 Here is an example configuration: name : azure_service_bus_queue_active_messages description : \"The number of active messages on a service bus queue\" resourceType : ServiceBusNamespace azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : # Optional, required when no resource discovery is configured - namespace : promitor-messaging queueName : orders - namespace : promitor-messaging queueName : items resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : service-bus-landscape","title":"Azure Service Bus Namespace"},{"location":"scraping/providers/service-bus-namespace/#azure-service-bus-namespace","text":"You can declare to scrape an Azure Service Bus namespace via the ServiceBusNamespace resource type. When using declared resources, the following fields need to be provided: namespace - The name of the Azure Service Bus namespace queueName - The name of the queue (optional) topicName - The name of the topic (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: entity_name - Name of the queue","title":"Azure Service Bus Namespace"},{"location":"scraping/providers/service-bus-namespace/#limitations","text":"No support for queueName & topicName for the same resource, for example: resources : - namespace : promitor-messaging queueName : orders topicName : sales No support for combining the queueName & EntityPath dimensions","title":"Limitations"},{"location":"scraping/providers/service-bus-namespace/#example","text":"Here is an example configuration: name : azure_service_bus_queue_active_messages description : \"The number of active messages on a service bus queue\" resourceType : ServiceBusNamespace azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : # Optional, required when no resource discovery is configured - namespace : promitor-messaging queueName : orders - namespace : promitor-messaging queueName : items resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : service-bus-landscape","title":"Example"},{"location":"scraping/providers/sql-database/","tags":["Scraper","Resource Discovery","SQL","Data","PaaS"],"text":"Azure SQL Database \u00b6 You can scrape an Azure SQL Database via the SqlDatabase resource type. When using declared resources, the following fields need to be provided: serverName - The name of the SQL Server instance. databaseName - The name of the database. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: server - The name of the SQL Server instance. database - The name of the database. Example \u00b6 Here is an example configuration: name : azure_sql_database_dtu_consumption_percent description : \"The DTU consumption percentage used by an Azure SQL Database.\" resourceType : SqlDatabase azureMetricConfiguration : metricName : dtu_consumption_percent aggregation : type : Average resources : # Optional, required when no resource discovery is configured - serverName : promitor-sql-server databaseName : promitor-db resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : sql-database-landscape","title":"Azure SQL Database"},{"location":"scraping/providers/sql-database/#azure-sql-database","text":"You can scrape an Azure SQL Database via the SqlDatabase resource type. When using declared resources, the following fields need to be provided: serverName - The name of the SQL Server instance. databaseName - The name of the database. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: server - The name of the SQL Server instance. database - The name of the database.","title":"Azure SQL Database"},{"location":"scraping/providers/sql-database/#example","text":"Here is an example configuration: name : azure_sql_database_dtu_consumption_percent description : \"The DTU consumption percentage used by an Azure SQL Database.\" resourceType : SqlDatabase azureMetricConfiguration : metricName : dtu_consumption_percent aggregation : type : Average resources : # Optional, required when no resource discovery is configured - serverName : promitor-sql-server databaseName : promitor-db resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : sql-database-landscape","title":"Example"},{"location":"scraping/providers/sql-elastic-pool/","tags":["Scraper","Resource Discovery","SQL","Data","PaaS"],"text":"Azure SQL Elastic Pool \u00b6 You can scrape an Azure SQL Elastic Pool via the SqlElasticPool resource type. When using declared resources, the following fields need to be provided: serverName - The name of the SQL Server instance. poolName - The name of the elastic pool. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: server - The name of the SQL Server instance. elastic_pool - The name of the elastic pool. Example \u00b6 Here is an example configuration: - name : promitor_demo_sql_elastic_pool_cpu description : \"CPU percentage used for a Azure SQL Elastic Pool\" resourceType : SqlElasticPool labels : app : promitor azureMetricConfiguration : metricName : cpu_percent aggregation : type : Average resources : # Optional, required when no resource discovery is configured - serverName : promitor-sql-server poolName : promitor-db resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : sql-elastic-pools","title":"Azure SQL Elastic Pool"},{"location":"scraping/providers/sql-elastic-pool/#azure-sql-elastic-pool","text":"You can scrape an Azure SQL Elastic Pool via the SqlElasticPool resource type. When using declared resources, the following fields need to be provided: serverName - The name of the SQL Server instance. poolName - The name of the elastic pool. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: server - The name of the SQL Server instance. elastic_pool - The name of the elastic pool.","title":"Azure SQL Elastic Pool"},{"location":"scraping/providers/sql-elastic-pool/#example","text":"Here is an example configuration: - name : promitor_demo_sql_elastic_pool_cpu description : \"CPU percentage used for a Azure SQL Elastic Pool\" resourceType : SqlElasticPool labels : app : promitor azureMetricConfiguration : metricName : cpu_percent aggregation : type : Average resources : # Optional, required when no resource discovery is configured - serverName : promitor-sql-server poolName : promitor-db resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : sql-elastic-pools","title":"Example"},{"location":"scraping/providers/sql-managed-instance/","tags":["Scraper","Resource Discovery","SQL","Data"],"text":"Azure SQL Managed Instance \u00b6 You can scrape an Azure SQL Managed Instance via the SqlManagedInstance resource type. When using declared resources, the following fields need to be provided: instanceName - The name of the SQL Server instance. All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : promitor_demo_azuresqlmanagedinstance_nodes description : \"The amount of nodes for an Azure SQL Managed Instance.\" resourceType : SqlManagedInstance azureMetricConfiguration : metricName : virtual_core_count aggregation : type : Average resources : # Optional, required when no resource discovery is configured - instanceName : promitor-sql-managed-instance resourceDiscoveryGroups : - name : sql-managed-instances resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : sql-managed-instances-landscape","title":"Azure SQL Managed Instance"},{"location":"scraping/providers/sql-managed-instance/#azure-sql-managed-instance","text":"You can scrape an Azure SQL Managed Instance via the SqlManagedInstance resource type. When using declared resources, the following fields need to be provided: instanceName - The name of the SQL Server instance. All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure SQL Managed Instance"},{"location":"scraping/providers/sql-managed-instance/#example","text":"Here is an example configuration: name : promitor_demo_azuresqlmanagedinstance_nodes description : \"The amount of nodes for an Azure SQL Managed Instance.\" resourceType : SqlManagedInstance azureMetricConfiguration : metricName : virtual_core_count aggregation : type : Average resources : # Optional, required when no resource discovery is configured - instanceName : promitor-sql-managed-instance resourceDiscoveryGroups : - name : sql-managed-instances resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : sql-managed-instances-landscape","title":"Example"},{"location":"scraping/providers/sql-server/","tags":["Scraper","Resource Discovery","SQL","Data"],"text":"Azure SQL Server \u00b6 You can scrape an Azure SQL Server via the SqlServer resource type. The following fields need to be provided: serverName - The name of the SQL Server instance. Supported metrics: dtu_consumption_percent - Percentage of consumed CPU across all elastic pools. Requires dimension.name to be set to ElasticPoolResourceId storage_used - Amount of storage data across all elastic pools in bytes. Requires dimension.name to be set to ElasticPoolResourceId dtu_used - Amount of consumed DTU across all databases. Requires dimension.name to be set to DatabaseResourceId The official Azure Monitor documentation lists more metrics but these are not surfaced externally. However, you can still give them a try but we don't support them for now. Example \u00b6 Here is an example configuration: name : azure_sql_server_dtu_consumption_percent description : \"The DTU consumption percentage used by an Azure SQL Server.\" resourceType : SqlServer azureMetricConfiguration : metricName : dtu_used dimension : name : DatabaseResourceId aggregation : type : Average resources : - serverName : promitor","title":"Azure SQL Server"},{"location":"scraping/providers/sql-server/#azure-sql-server","text":"You can scrape an Azure SQL Server via the SqlServer resource type. The following fields need to be provided: serverName - The name of the SQL Server instance. Supported metrics: dtu_consumption_percent - Percentage of consumed CPU across all elastic pools. Requires dimension.name to be set to ElasticPoolResourceId storage_used - Amount of storage data across all elastic pools in bytes. Requires dimension.name to be set to ElasticPoolResourceId dtu_used - Amount of consumed DTU across all databases. Requires dimension.name to be set to DatabaseResourceId The official Azure Monitor documentation lists more metrics but these are not surfaced externally. However, you can still give them a try but we don't support them for now.","title":"Azure SQL Server"},{"location":"scraping/providers/sql-server/#example","text":"Here is an example configuration: name : azure_sql_server_dtu_consumption_percent description : \"The DTU consumption percentage used by an Azure SQL Server.\" resourceType : SqlServer azureMetricConfiguration : metricName : dtu_used dimension : name : DatabaseResourceId aggregation : type : Average resources : - serverName : promitor","title":"Example"},{"location":"scraping/providers/storage-account/","tags":["Scraper","Resource Discovery","Data","Storage"],"text":"Azure Storage Account \u00b6 You can declare to scrape an Azure Queue via the StorageAccount resource type. When using declared resources, the following fields need to be provided: accountName - The name of the Azure Storage account All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_storage_account_capacity description : \"The average capacity used in the storage account\" resourceType : StorageAccount azureMetricConfiguration : metricName : UsedCapacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - accountName : promitor-1 - accountName : promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : storage-account-landscape","title":"Azure Storage Account"},{"location":"scraping/providers/storage-account/#azure-storage-account","text":"You can declare to scrape an Azure Queue via the StorageAccount resource type. When using declared resources, the following fields need to be provided: accountName - The name of the Azure Storage account All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Storage Account"},{"location":"scraping/providers/storage-account/#example","text":"Here is an example configuration: name : azure_storage_account_capacity description : \"The average capacity used in the storage account\" resourceType : StorageAccount azureMetricConfiguration : metricName : UsedCapacity aggregation : type : Average resources : # Optional, required when no resource discovery is configured - accountName : promitor-1 - accountName : promitor-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : storage-account-landscape","title":"Example"},{"location":"scraping/providers/storage-queue/","tags":["Scraper","Data","Storage"],"text":"Azure Storage Queue \u00b6 You can declare to scrape an Azure Queue via the StorageQueue resource type. When using declared resources, the following fields need to be provided: accountName - The name of the storage account queueName - The name of the queue sasToken - The SAS token used to access the queue/account sasToken.environmentVariable - Defines the environment variable which contains the SAS token to authenticate with sasToken.rawValue - Contains the raw hardcoded SAS token (less secure) Supported metrics: TimeSpentInQueue - Time in seconds that the oldest message has been waiting in the queue to be processed. MessageCount The following scraper-specific metric label will be added: queue_name - Name of the queue Example \u00b6 Here is an example configuration: name : azure_storage_queue_message_count description : \"The number of messages on an Azure storage queue\" resourceType : StorageQueue azureMetricConfiguration : metricName : MessageCount aggregation : type : Total resources : - accountName : promitor queueName : orders sasToken : environmentVariable : \"SECRETS_STORAGEQUEUE_PROMITOR_SASTOKEN\" - accountName : promitor queueName : items sasToken : environmentVariable : \"SECRETS_STORAGEQUEUE_PROMITOR_SASTOKEN\"","title":"Azure Storage Queue"},{"location":"scraping/providers/storage-queue/#azure-storage-queue","text":"You can declare to scrape an Azure Queue via the StorageQueue resource type. When using declared resources, the following fields need to be provided: accountName - The name of the storage account queueName - The name of the queue sasToken - The SAS token used to access the queue/account sasToken.environmentVariable - Defines the environment variable which contains the SAS token to authenticate with sasToken.rawValue - Contains the raw hardcoded SAS token (less secure) Supported metrics: TimeSpentInQueue - Time in seconds that the oldest message has been waiting in the queue to be processed. MessageCount The following scraper-specific metric label will be added: queue_name - Name of the queue","title":"Azure Storage Queue"},{"location":"scraping/providers/storage-queue/#example","text":"Here is an example configuration: name : azure_storage_queue_message_count description : \"The number of messages on an Azure storage queue\" resourceType : StorageQueue azureMetricConfiguration : metricName : MessageCount aggregation : type : Total resources : - accountName : promitor queueName : orders sasToken : environmentVariable : \"SECRETS_STORAGEQUEUE_PROMITOR_SASTOKEN\" - accountName : promitor queueName : items sasToken : environmentVariable : \"SECRETS_STORAGEQUEUE_PROMITOR_SASTOKEN\"","title":"Example"},{"location":"scraping/providers/synapse-apache-spark-pool/","tags":["Scraper","Resource Discovery","Data","Synapse"],"text":"Azure Synapse (Apache Spark pool) \u00b6 You can scrape an Azure Synapse Apache Spark pool via the SynapseApacheSparkPool resource type. When using declared resources, the following fields need to be provided: workspaceName - The name of the Azure Synapse workspace. poolName - The name of the Apache Spark pool. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: workspace_name - The name of the Azure Synapse workspace. pool_name - The name of the Apache Spark pool. Example \u00b6 Here is an example configuration: - name : promitor_demo_synapse_apache_spark_apps_ended description : \"Amount of apps ended running on Apache Spark pool in Azure Synapse\" resourceType : SynapseApacheSparkPool azureMetricConfiguration : metricName : BigDataPoolApplicationsEnded aggregation : type : Total resources : # Optional, required when no resource discovery is configured - workspaceName : promitor-synapse poolName : sparkpool resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : synapse-apache-spark-pools","title":"Azure Synapse (Apache Spark pool)"},{"location":"scraping/providers/synapse-apache-spark-pool/#azure-synapse-apache-spark-pool","text":"You can scrape an Azure Synapse Apache Spark pool via the SynapseApacheSparkPool resource type. When using declared resources, the following fields need to be provided: workspaceName - The name of the Azure Synapse workspace. poolName - The name of the Apache Spark pool. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: workspace_name - The name of the Azure Synapse workspace. pool_name - The name of the Apache Spark pool.","title":"Azure Synapse (Apache Spark pool)"},{"location":"scraping/providers/synapse-apache-spark-pool/#example","text":"Here is an example configuration: - name : promitor_demo_synapse_apache_spark_apps_ended description : \"Amount of apps ended running on Apache Spark pool in Azure Synapse\" resourceType : SynapseApacheSparkPool azureMetricConfiguration : metricName : BigDataPoolApplicationsEnded aggregation : type : Total resources : # Optional, required when no resource discovery is configured - workspaceName : promitor-synapse poolName : sparkpool resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : synapse-apache-spark-pools","title":"Example"},{"location":"scraping/providers/synapse-sql-pool/","tags":["Scraper","Resource Discovery","Data","Synapse"],"text":"Azure Synapse (SQL pool) \u00b6 You can scrape an Azure Synapse SQL pool via the SynapseSqlPool resource type. When using declared resources, the following fields need to be provided: workspaceName - The name of the Azure Synapse workspace. poolName - The name of the SQL pool. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: workspace_name - The name of the Azure Synapse workspace. pool_name - The name of the SQL pool. Example \u00b6 Here is an example configuration: - name : promitor_demo_synapse_sql_pool_dwu_limit description : \"Amount of DWUs defined as limit for SQL pool in Azure Synapse\" resourceType : SynapseSqlPool azureMetricConfiguration : metricName : DWULimit aggregation : type : Maximum resources : # Optional, required when no resource discovery is configured - workspaceName : promitor-synapse poolName : sqlpool resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : synapse-sql-pools","title":"Azure Synapse (SQL pool)"},{"location":"scraping/providers/synapse-sql-pool/#azure-synapse-sql-pool","text":"You can scrape an Azure Synapse SQL pool via the SynapseSqlPool resource type. When using declared resources, the following fields need to be provided: workspaceName - The name of the Azure Synapse workspace. poolName - The name of the SQL pool. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: workspace_name - The name of the Azure Synapse workspace. pool_name - The name of the SQL pool.","title":"Azure Synapse (SQL pool)"},{"location":"scraping/providers/synapse-sql-pool/#example","text":"Here is an example configuration: - name : promitor_demo_synapse_sql_pool_dwu_limit description : \"Amount of DWUs defined as limit for SQL pool in Azure Synapse\" resourceType : SynapseSqlPool azureMetricConfiguration : metricName : DWULimit aggregation : type : Maximum resources : # Optional, required when no resource discovery is configured - workspaceName : promitor-synapse poolName : sqlpool resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : synapse-sql-pools","title":"Example"},{"location":"scraping/providers/synapse-workspace/","tags":["Scraper","Resource Discovery","Data","Synapse"],"text":"Azure Synapse (Workspace) \u00b6 You can scrape an Azure Synapse workspace via the SynapseWorkspace resource type. When using declared resources, the following fields need to be provided: workspaceName - The name of the Azure Synapse workspace. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: workspace_name - The name of the Azure Synapse workspace. Example \u00b6 Here is an example configuration: - name : promitor_demo_synapse_workspace_builtin_sql_processed_bytes description : \"Amount of bytes processed in Azure Synapse workspace\" resourceType : SynapseWorkspace azureMetricConfiguration : metricName : BuiltinSqlPoolDataProcessedBytes aggregation : type : Total resources : # Optional, required when no resource discovery is configured - workspaceName : promitor-synapse resourceGroupName : promitor-sources resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : synapse-workspaces","title":"Azure Synapse (Workspace)"},{"location":"scraping/providers/synapse-workspace/#azure-synapse-workspace","text":"You can scrape an Azure Synapse workspace via the SynapseWorkspace resource type. When using declared resources, the following fields need to be provided: workspaceName - The name of the Azure Synapse workspace. All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric labels will be added: workspace_name - The name of the Azure Synapse workspace.","title":"Azure Synapse (Workspace)"},{"location":"scraping/providers/synapse-workspace/#example","text":"Here is an example configuration: - name : promitor_demo_synapse_workspace_builtin_sql_processed_bytes description : \"Amount of bytes processed in Azure Synapse workspace\" resourceType : SynapseWorkspace azureMetricConfiguration : metricName : BuiltinSqlPoolDataProcessedBytes aggregation : type : Total resources : # Optional, required when no resource discovery is configured - workspaceName : promitor-synapse resourceGroupName : promitor-sources resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : synapse-workspaces","title":"Example"},{"location":"scraping/providers/virtual-machine-scale-set/","tags":["Scraper","Resource Discovery","IaaS"],"text":"Azure Virtual Machine Scale Set (VMSS) \u00b6 You can declare to scrape an Azure Virtual Machine Scale Set via the VirtualMachineScaleSet resource type. When using declared resources, the following fields need to be provided: scaleSetName - The name of the Virtual Machine Scale Set All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_virtual_machine_scale_set_percentage_cpu description : \"Average percentage cpu usage on an Azure virtual machine scale set\" resourceType : VirtualMachineScaleSet azureMetricConfiguration : metricName : Percentage CPU dimension : name : VMName aggregation : type : Average resources : # Optional, required when no resource discovery is configured - scaleSetName : promitor-virtual-machine-scale-set-1 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : virtual-machine-scale-sets-landscape","title":"Azure Virtual Machine Scale Set (VMSS)"},{"location":"scraping/providers/virtual-machine-scale-set/#azure-virtual-machine-scale-set-vmss","text":"You can declare to scrape an Azure Virtual Machine Scale Set via the VirtualMachineScaleSet resource type. When using declared resources, the following fields need to be provided: scaleSetName - The name of the Virtual Machine Scale Set All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Virtual Machine Scale Set (VMSS)"},{"location":"scraping/providers/virtual-machine-scale-set/#example","text":"Here is an example configuration: name : azure_virtual_machine_scale_set_percentage_cpu description : \"Average percentage cpu usage on an Azure virtual machine scale set\" resourceType : VirtualMachineScaleSet azureMetricConfiguration : metricName : Percentage CPU dimension : name : VMName aggregation : type : Average resources : # Optional, required when no resource discovery is configured - scaleSetName : promitor-virtual-machine-scale-set-1 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : virtual-machine-scale-sets-landscape","title":"Example"},{"location":"scraping/providers/virtual-machine/","tags":["Scraper","Resource Discovery","IaaS"],"text":"Azure Virtual Machine (VM) \u00b6 You can declare to scrape an Azure Virtual Machine via the VirtualMachine resource type. When using declared resources, the following fields need to be provided: virtualMachineName - The name of the virtual machine All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_virtual_machine_percentage_cpu description : \"Average percentage cpu usage on an Azure virtual machine\" resourceType : VirtualMachine azureMetricConfiguration : metricName : Percentage CPU aggregation : type : Average resources : # Optional, required when no resource discovery is configured - virtualMachineName : promitor-virtual-machine-1 - virtualMachineName : promitor-virtual-machine-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : virtual-machine-landscape","title":"Azure Virtual Machine (VM)"},{"location":"scraping/providers/virtual-machine/#azure-virtual-machine-vm","text":"You can declare to scrape an Azure Virtual Machine via the VirtualMachine resource type. When using declared resources, the following fields need to be provided: virtualMachineName - The name of the virtual machine All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Virtual Machine (VM)"},{"location":"scraping/providers/virtual-machine/#example","text":"Here is an example configuration: name : azure_virtual_machine_percentage_cpu description : \"Average percentage cpu usage on an Azure virtual machine\" resourceType : VirtualMachine azureMetricConfiguration : metricName : Percentage CPU aggregation : type : Average resources : # Optional, required when no resource discovery is configured - virtualMachineName : promitor-virtual-machine-1 - virtualMachineName : promitor-virtual-machine-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : virtual-machine-landscape","title":"Example"},{"location":"scraping/providers/virtual-network/","tags":["Scraper","Resource Discovery","Networking"],"text":"Azure Virtual Network \u00b6 You can declare to scrape an Azure Virtual Network via the VirtualNetwork resource type. When using declared resources, the following fields need to be provided: virtualNetworkName - The name of the Azure Virtual Network resource All supported metrics are documented in the official Azure Monitor documentation . Example \u00b6 Here is an example configuration: name : azure_virtual_network_ddos_attack description : \"Indication whether or not there is a DDOS attack on the Azure Virtual Network\" resourceType : VirtualNetwork azureMetricConfiguration : metricName : IfUnderDDoSAttack aggregation : type : Maximum resources : # Optional, required when no resource discovery is configured - virtualNetworkName : promitor-virtual-network-1 - virtualNetworkName : promitor-virtual-network-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : virtual-network-landscape","title":"Azure Virtual Network"},{"location":"scraping/providers/virtual-network/#azure-virtual-network","text":"You can declare to scrape an Azure Virtual Network via the VirtualNetwork resource type. When using declared resources, the following fields need to be provided: virtualNetworkName - The name of the Azure Virtual Network resource All supported metrics are documented in the official Azure Monitor documentation .","title":"Azure Virtual Network"},{"location":"scraping/providers/virtual-network/#example","text":"Here is an example configuration: name : azure_virtual_network_ddos_attack description : \"Indication whether or not there is a DDOS attack on the Azure Virtual Network\" resourceType : VirtualNetwork azureMetricConfiguration : metricName : IfUnderDDoSAttack aggregation : type : Maximum resources : # Optional, required when no resource discovery is configured - virtualNetworkName : promitor-virtual-network-1 - virtualNetworkName : promitor-virtual-network-2 resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : virtual-network-landscape","title":"Example"},{"location":"scraping/providers/web-app/","tags":["Scraper","Resource Discovery","PaaS"],"text":"Azure Web App \u00b6 You can declare to scrape an Azure Web App via the WebApp resource type. When using declared resources, the following fields need to be provided: webAppName - The name of the Azure Web App slotName - The name of the deployment slot (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: slot_name - Name of the deployment slot. If none is specified, production will be used. Example: name : azure_web_app_requests description : \"Amount of requests for an Azure Web App\" resourceType : WebApp azureMetricConfiguration : metricName : Requests aggregation : type : Total resources : # Optional, required when no resource discovery is configured - webAppName : promitor-web-app slot : staging - webAppName : promitor-web-app slot : production resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : web-app-landscape","title":"Azure Web App"},{"location":"scraping/providers/web-app/#azure-web-app","text":"You can declare to scrape an Azure Web App via the WebApp resource type. When using declared resources, the following fields need to be provided: webAppName - The name of the Azure Web App slotName - The name of the deployment slot (optional) All supported metrics are documented in the official Azure Monitor documentation . The following scraper-specific metric label will be added: slot_name - Name of the deployment slot. If none is specified, production will be used. Example: name : azure_web_app_requests description : \"Amount of requests for an Azure Web App\" resourceType : WebApp azureMetricConfiguration : metricName : Requests aggregation : type : Total resources : # Optional, required when no resource discovery is configured - webAppName : promitor-web-app slot : staging - webAppName : promitor-web-app slot : production resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : web-app-landscape","title":"Azure Web App"},{"location":"security/azure-authentication/","text":"Authentication with Microsoft Azure \u00b6 This document describes the various agents that Promitor provides, what Microsoft Azure services they are consuming and what the minimal required permissions are that every entity requires to be functional. Overview \u00b6 Here is an overview of our Promitor agents and their integrations: Azure Integration Promitor Scraper Promitor Resource Discovery Azure Monitor \u2705 \u274c Azure Resource Graph \u274c \u2705 Each agent needs an Azure AD identity to authenticate with to Microsoft Azure. In order to achieve this, you'll need to create an Azure AD Application , Supported Authentication Mechanisms \u00b6 Our agents provide the following authentication mechanisms: Service principle - Use application id & secret of the Azure AD entity that has been pre-created to authenticate with Managed Identity - Use zero-secret authentication by letting Microsoft handle the authentication for you ( docs ) For details how to configure the authentication, we recommend reading our agent configuration documentation. Service Principle Authentication \u00b6 Every agent needs to be configured with the following environment variables: PROMITOR_AUTH_APPKEY - Secret of the Azure AD entity to authenticate with Managed Identity Authentication \u00b6 When using Managed Identity, you can use one of the following scenarios: System-assigned Managed Identity - Use the identity of the Azure resource on which it runs and let Azure handle the authentication. User-assigned Managed Identity - Use a pre-created Azure AD identity but let Azure handle the authentication for you \u26a0 In order to use managed identity, your Kubernetes cluster must be hosted on Microsoft Azure to leverage this. Permission Overview \u00b6 Required permissions for Azure Monitor \u00b6 Identities that are used to integrate with Azure Monitor need to have Monitoring Reader permission on the subscription, resource group and/or resources that will be queried. More information can be found here . Required permissions for Azure Resource Graph \u00b6 Identities that are used to integrate with Azure Resource Graph need to have Reader permission on the subscription, resource group and/or resources that will be queried. \u26a0 If you are re-using this identity to integrate with Azure Monitor, make sure to grant the required permissions to reflect that as well. More information can be found here . \u2190 back","title":"Authentication with Microsoft Azure"},{"location":"security/azure-authentication/#authentication-with-microsoft-azure","text":"This document describes the various agents that Promitor provides, what Microsoft Azure services they are consuming and what the minimal required permissions are that every entity requires to be functional.","title":"Authentication with Microsoft Azure"},{"location":"security/azure-authentication/#overview","text":"Here is an overview of our Promitor agents and their integrations: Azure Integration Promitor Scraper Promitor Resource Discovery Azure Monitor \u2705 \u274c Azure Resource Graph \u274c \u2705 Each agent needs an Azure AD identity to authenticate with to Microsoft Azure. In order to achieve this, you'll need to create an Azure AD Application ,","title":"Overview"},{"location":"security/azure-authentication/#supported-authentication-mechanisms","text":"Our agents provide the following authentication mechanisms: Service principle - Use application id & secret of the Azure AD entity that has been pre-created to authenticate with Managed Identity - Use zero-secret authentication by letting Microsoft handle the authentication for you ( docs ) For details how to configure the authentication, we recommend reading our agent configuration documentation.","title":"Supported Authentication Mechanisms"},{"location":"security/azure-authentication/#service-principle-authentication","text":"Every agent needs to be configured with the following environment variables: PROMITOR_AUTH_APPKEY - Secret of the Azure AD entity to authenticate with","title":"Service Principle Authentication"},{"location":"security/azure-authentication/#managed-identity-authentication","text":"When using Managed Identity, you can use one of the following scenarios: System-assigned Managed Identity - Use the identity of the Azure resource on which it runs and let Azure handle the authentication. User-assigned Managed Identity - Use a pre-created Azure AD identity but let Azure handle the authentication for you \u26a0 In order to use managed identity, your Kubernetes cluster must be hosted on Microsoft Azure to leverage this.","title":"Managed Identity Authentication"},{"location":"security/azure-authentication/#permission-overview","text":"","title":"Permission Overview"},{"location":"security/azure-authentication/#required-permissions-for-azure-monitor","text":"Identities that are used to integrate with Azure Monitor need to have Monitoring Reader permission on the subscription, resource group and/or resources that will be queried. More information can be found here .","title":"Required permissions for Azure Monitor"},{"location":"security/azure-authentication/#required-permissions-for-azure-resource-graph","text":"Identities that are used to integrate with Azure Resource Graph need to have Reader permission on the subscription, resource group and/or resources that will be queried. \u26a0 If you are re-using this identity to integrate with Azure Monitor, make sure to grant the required permissions to reflect that as well. More information can be found here . \u2190 back","title":"Required permissions for Azure Resource Graph"},{"location":"walkthroughs/migrate-from-1.x-to-2.x/","text":"Migrate from Promitor Scraper 1.x to 2.x \u00b6 Here is a migration guide from Promitor Scraper v1.x to v2.x. For a complete overview of our changelog, we recommend going to changelog.promitor.io . Migrate to new metric sink concept \u00b6 As of Promitor Scraper v1.6 we have introduced the concept of metric sinks allowing you to emit scraped Azure Monitor metrics to multiple systems. With Promitor v2.0, we are removing support for our legacy Prometheus configuration. When using the following configuration: prometheus : metricUnavailableValue : NaN enableMetricTimestamps : false scrapeEndpoint : baseUriPath : /metrics You can easily migrate it to our Prometheus Scraping endpoint sink as following: metricSinks : prometheusScrapingEndpoint : metricUnavailableValue : NaN enableMetricTimestamps : false baseUriPath : /metrics For more information, we recommend reading our documentation concerning our Prometheus Scraping endpoint. Migrate from Azure Service Bus Queue scraper to our new Azure Service Bus Namespace scraper \u00b6 Since Azure Service Bus Queue scraper allows you to report metrics for all entities we decided to change the resource type from ServiceBusQueue to ServiceBusNamespace since it will also report metrics for topics, and not only queues. For example: name : azure_service_bus_queue_active_messages description : \"The number of active messages on a service bus queue\" resourceType : ServiceBusNamespace azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : - namespace : promitor-messaging # queueName: orders <-- Optionally specify the queue name to filter on # topicName: sales <-- Optionally specify the queue name to filter on resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : service-bus-landscape For more information, we recommend reading our documentation concerning our Azure Service Bus Namespace scraper. Migrate to OpenAPI 3.0 & UI \u00b6 All Promitor APIs have been migrated from Swagger to OpenAPI 3.0 specification. Before, our Swagger docs were accessible via: Swagger UI on /swagger Raw documentation on /swagger/v1/swagger.json Our OpenAPI 3.0 docs are available on: Swagger UI on /api/docs Raw documentation on /api/v1/docs.json \u2190 back","title":"Migrate from Promitor Scraper 1.x to 2.x"},{"location":"walkthroughs/migrate-from-1.x-to-2.x/#migrate-from-promitor-scraper-1x-to-2x","text":"Here is a migration guide from Promitor Scraper v1.x to v2.x. For a complete overview of our changelog, we recommend going to changelog.promitor.io .","title":"Migrate from Promitor Scraper 1.x to 2.x"},{"location":"walkthroughs/migrate-from-1.x-to-2.x/#migrate-to-new-metric-sink-concept","text":"As of Promitor Scraper v1.6 we have introduced the concept of metric sinks allowing you to emit scraped Azure Monitor metrics to multiple systems. With Promitor v2.0, we are removing support for our legacy Prometheus configuration. When using the following configuration: prometheus : metricUnavailableValue : NaN enableMetricTimestamps : false scrapeEndpoint : baseUriPath : /metrics You can easily migrate it to our Prometheus Scraping endpoint sink as following: metricSinks : prometheusScrapingEndpoint : metricUnavailableValue : NaN enableMetricTimestamps : false baseUriPath : /metrics For more information, we recommend reading our documentation concerning our Prometheus Scraping endpoint.","title":"Migrate to new metric sink concept"},{"location":"walkthroughs/migrate-from-1.x-to-2.x/#migrate-from-azure-service-bus-queue-scraper-to-our-new-azure-service-bus-namespace-scraper","text":"Since Azure Service Bus Queue scraper allows you to report metrics for all entities we decided to change the resource type from ServiceBusQueue to ServiceBusNamespace since it will also report metrics for topics, and not only queues. For example: name : azure_service_bus_queue_active_messages description : \"The number of active messages on a service bus queue\" resourceType : ServiceBusNamespace azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : - namespace : promitor-messaging # queueName: orders <-- Optionally specify the queue name to filter on # topicName: sales <-- Optionally specify the queue name to filter on resourceDiscoveryGroups : # Optional, requires Promitor Resource Discovery agent (https://promitor.io/concepts/how-it-works#using-resource-discovery) - name : service-bus-landscape For more information, we recommend reading our documentation concerning our Azure Service Bus Namespace scraper.","title":"Migrate from Azure Service Bus Queue scraper to our new Azure Service Bus Namespace scraper"},{"location":"walkthroughs/migrate-from-1.x-to-2.x/#migrate-to-openapi-30-ui","text":"All Promitor APIs have been migrated from Swagger to OpenAPI 3.0 specification. Before, our Swagger docs were accessible via: Swagger UI on /swagger Raw documentation on /swagger/v1/swagger.json Our OpenAPI 3.0 docs are available on: Swagger UI on /api/docs Raw documentation on /api/v1/docs.json \u2190 back","title":"Migrate to OpenAPI 3.0 &amp; UI"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/","text":"Deploying Promitor, Prometheus, and Grafana on an AKS Cluster \u00b6 Introduction \u00b6 In this walkthrough, we'll set up a basic monitoring solution with Promitor, Prometheus, and Grafana. In order to have a resource to monitor, we'll create a Service Bus queue and add load to the queue with Service Bus Explorer. We'll deploy Promitor, Prometheus, and Grafana to a Kubernetes cluster using Helm, and explain how each of these services connects and how to see output. We'll also walk through setting up basic Grafana dashboard to visualize the metrics we're monitoring. Table of Contents \u00b6 Deploy Azure Infrastructure Create a Resource Group Create a Service Principal Create a Service Bus Namespace and Queue Create an AKS Cluster Cluster Setup Get credentials Deploy Promitor and Prometheus Create a metrics declaration for Promitor Deploy Promitor to your cluster using Helm Install Prometheus Test and check output Add load to the queue See Promitor & Prometheus output via port-forwarding Visualization Install Grafana Add Prometheus as a data source Create a Grafana dashboard for queue metrics Creating a Kubernetes dashboard Delete resources Prerequisites \u00b6 The Azure CLI kubectl , the Kubernetes command-line tool. It can also be installed via the Azure CLI with az aks install-cli . Helm , a Kubernetes deployment manager Service Bus Explorer Deploy Azure Infrastructure \u00b6 Create a Resource Group \u00b6 az group create --name PromitorRG --location eastus Output: { \"id\" : \"/subscriptions/<guid-subscription-id>/resourceGroups/PromitorRG\" , \"...\" : \"...\" } Create a Service Principal \u00b6 Use the resource group creation output to add a scope to your service principal: az ad sp create-for-rbac \\ --role = \"Monitoring Reader\" \\ --scopes = \"/subscriptions/<guid-subscription-id>/resourceGroups/PromitorRG\" Which should output something similar to { \"appId\" : \"<guid-sp-app-id>\" , \"displayName\" : \"azure-cli-2019-03-29-19-21-58\" , \"name\" : \"http://azure-cli-2019-03-29-19-21-58\" , \"password\" : \"<guid-sp-generated-password>\" , \"tenant\" : \"<guid-tenant-id>\" } Save this output as we will use the app ID, tenant ID, and password later on. Create a Service Bus Namespace and Queue \u00b6 First we'll need to create a namespace. Service Bus Namespaces need to be globally unique, so we won't use a default name in these commands. az servicebus namespace create \\ --resource-group PromitorRG \\ --name <service-bus-namespace> \\ --location eastus We'll then create a queue in that namespace: az servicebus queue create \\ --resource-group PromitorRG \\ --namespace-name <service-bus-namespace> \\ --name demo_queue Finally, get the connection string for this Service Bus namespace for use later. az servicebus namespace authorization-rule keys list \\ --resource-group PromitorRG \\ --namespace-name <service-bus-namespace> \\ --name RootManageSharedAccessKey \\ --query primaryConnectionString \\ --output tsv Create an AKS Cluster \u00b6 Create a cluster with: az aks create \\ --name PromitorCluster \\ --resource-group PromitorRG \\ --node-count 1 \\ --generate-ssh-keys Cluster Setup \u00b6 Get credentials \u00b6 You can get your cluster's credentials with az aks get-credentials \\ --name PromitorCluster \\ --resource-group PromitorRG This will save these credentials to your kubeconfig file and set your new cluster as your current context for all kubectl commands. Verify your credentials and check that your cluster is up and running with kubectl get nodes . Deploy Promitor and Prometheus \u00b6 Create a metrics declaration for Promitor \u00b6 Before deploying Promitor, you'll need a values file with secrets & a metric declaration file (these can also be the same file for ease of use). The yaml below will scrape one metric, queue length, from the queue created above. azureAuthentication : appId : <guid-sp-app-id> appKey : <guid-sp-generated-password> azureMetadata : tenantId : <guid-tenant-id> subscriptionId : <guid-subscription-id> resourceGroupName : PromitorRG metricDefaults : aggregation : interval : 00:05:00 scraping : schedule : \"* * * * *\" metrics : - name : demo_queue_size description : \"Amount of active messages of the 'demo_queue' queue\" resourceType : ServiceBusNamespace azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : - namespace : <service-bus-namespace> queueName : demo_queue Deploy Promitor to your cluster using Helm \u00b6 To deploy, we'll first add the Promitor chart repository to helm: helm repo add promitor https://charts.promitor.io/ helm repo update With this repository added, we can deploy Promitor: helm install promitor-agent-scraper promitor/promitor-agent-scraper \\ --values your/path/to/metric-declaration.yaml Install Prometheus \u00b6 Note: If you're seeing errors installing Prometheus or Grafana from the Helm chart repository, make sure you run helm repo update before digging into the errors more. You might have an outdated copy of the chart. Running the deployment command from the previous section should give you an output that includes a script similar to this one: cat > promitor-scrape-config.yaml <<EOF extraScrapeConfigs: | - job_name: promitor-agent-scraper metrics_path: /metrics static_configs: - targets: - promitor-agent-scraper.default.svc.cluster.local:80 EOF helm install stable/prometheus -f promitor-scrape-config.yaml You can see this output again at any time by running helm status promitor-agent-scraper . Running these commands will create a Prometheus scraping configuration file in your current directory and deploy Prometheus to your cluster with that scraping configuration in addition to the default. Test and check output \u00b6 Add load to the queue \u00b6 Now we'll use Service Bus Explorer to add load to our Service Bus queue so there are meaningful metrics for Promitor to pick up. In Service Bus Explorer, you can connect to your namespace & queue using a connection string. From there, right clicking on the queue in the side-bar should give you an option to 'Send Message' - from there, use the 'Sender' tab of that window to send bulk messages. Remember how many you send - you should see that number in the Promitor & Prometheus output. See Promitor & Prometheus output via port-forwarding \u00b6 Going back to your cluster, you should be able to see all Promitor & Prometheus pods up and running with kubectl get pods . You can also see the services which provide a stable endpoint at which to reach the pods by running kubectl get services . This should give you a list with output similar to: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) promitor-agent-scraper ClusterIP 10.0.#.# \\<none> 80/TCP \\<prometheus-release-name>-prometheus-server ClusterIP 10.0.#.# \\<none> 80/TCP Next to that, it should also list other services deployed by Prometheus. Let's first look at the Promitor output! Run kubectl port-forward svc/promitor-agent-scraper 8080:80 and check http://localhost:8080/metrics . You should see some information about your queue: # HELP promitor_ratelimit_arm Indication how many calls are still available before Azure Resource Manager is going to throttle us. # TYPE promitor_ratelimit_arm gauge promitor_ratelimit_arm { tenant_id = <guid-tenant-id>,subscription_id = <guid-subscription-id>,app_id = <guid-sp-app-id> } 11998 1558116465529 # HELP demo_queue_size Amount of active messages of the 'demo_queue' queue # TYPE demo_queue_size gauge demo_queue_size 200 1558116465677 where 200 is the number of messages sent. We can also look at the Prometheus server and check that it's pulling in metrics from Promitor. Cancel the previous port-forward command and run kubectl port-forward svc/<prometheus-release-name>-prometheus-server 8080:80 . Now, if you check http://localhost:8080 , you should be able to enter Prometheus queries. Query demo_queue_size and as long as all your pods are up and running and both Promitor and Prometheus have scraped metrics at least once, you should see a value that matches the number of messages in your queue. Visualization \u00b6 Install Grafana \u00b6 Grafana's chart has a few default values you may not want long term - persistant storage is disabled and admin username/password is randomly generated - but for our sample the out-of-the-box install will work. Run helm install grafana stable/grafana and you should see output that includes this command: kubectl get secret --namespace default grafana -o jsonpath = \"{.data.admin-password}\" | base64 --decode ; echo Run this to get your Grafana password. Now you can use kubectl port-forward again to log in to your Grafana dashboard. kubectl port-forward svc/grafana 8080:80 will make your dashboard available at http://localhost:8080 , and you can log in with username 'admin' and the password you retrieved. Add Prometheus as a data source \u00b6 After logging in, you should see an option to \"Add a Data Source.\" Click that, and choose the Prometheus source type (if it's not immediately visible, search for it). The only setting you should need to edit here is the URL, under the HTTP section. Within your cluster, http://<prometheus-release-name>-prometheus-server.default.svc.cluster.local should resolve to the Prometheus server service. (Default in that URL refers to the namespace - if you installed in a namespace other than default, change that.) Set your service's name as the Prometheus URL in Grafana, and save the data source. It should tell you that the data source is working. Create a Grafana dashboard for queue metrics \u00b6 First, we'll make a basic dashboard with the metric we set up in Promitor. Then you can use a pre-built dashboard to show Prometheus' default Kubernetes metrics. Go to the + button on the sidebar, and choose \"Dashboard\". To make a simple graph showing your queue size, you can write demo_queue_size in the query field. Click out of that input field and the graph should update. To see more, you can go back to Service Bus Explorer and send or receive messages. Your Grafana graph won't update immediately, but you should see results in a few minutes. In order to see results without manually refreshing, find the dropdown menu in the top right corner that sets the time range of the graph. Here you can edit time range and refresh rate. Make sure to save your new dashboard before exiting the page. Creating a Kubernetes dashboard \u00b6 Now we'll import a pre-created dashboard that shows Kubernetes metrics. There are multiple available on Grafana Lab's dashboard site - try 6417 . To import a dashboard, click the + button on the sidebar and choose \"Import.\" From there, you can either load a JSON file or enter the dashbord ID: 6417. Click \"Load\" and you will be given some configuration options. The only one that needs to be set is the Prometheus data source. From there, you should be able to create the dashboard and view metrics about your AKS cluster. Delete resources \u00b6 To delete all the resources used in this tutorial, run az group delete --name PromitorRG . \u2190 back","title":"Deploying Promitor, Prometheus, and Grafana on an AKS Cluster"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#deploying-promitor-prometheus-and-grafana-on-an-aks-cluster","text":"","title":"Deploying Promitor, Prometheus, and Grafana on an AKS Cluster"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#introduction","text":"In this walkthrough, we'll set up a basic monitoring solution with Promitor, Prometheus, and Grafana. In order to have a resource to monitor, we'll create a Service Bus queue and add load to the queue with Service Bus Explorer. We'll deploy Promitor, Prometheus, and Grafana to a Kubernetes cluster using Helm, and explain how each of these services connects and how to see output. We'll also walk through setting up basic Grafana dashboard to visualize the metrics we're monitoring.","title":"Introduction"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#table-of-contents","text":"Deploy Azure Infrastructure Create a Resource Group Create a Service Principal Create a Service Bus Namespace and Queue Create an AKS Cluster Cluster Setup Get credentials Deploy Promitor and Prometheus Create a metrics declaration for Promitor Deploy Promitor to your cluster using Helm Install Prometheus Test and check output Add load to the queue See Promitor & Prometheus output via port-forwarding Visualization Install Grafana Add Prometheus as a data source Create a Grafana dashboard for queue metrics Creating a Kubernetes dashboard Delete resources","title":"Table of Contents"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#prerequisites","text":"The Azure CLI kubectl , the Kubernetes command-line tool. It can also be installed via the Azure CLI with az aks install-cli . Helm , a Kubernetes deployment manager Service Bus Explorer","title":"Prerequisites"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#deploy-azure-infrastructure","text":"","title":"Deploy Azure Infrastructure"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-resource-group","text":"az group create --name PromitorRG --location eastus Output: { \"id\" : \"/subscriptions/<guid-subscription-id>/resourceGroups/PromitorRG\" , \"...\" : \"...\" }","title":"Create a Resource Group"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-service-principal","text":"Use the resource group creation output to add a scope to your service principal: az ad sp create-for-rbac \\ --role = \"Monitoring Reader\" \\ --scopes = \"/subscriptions/<guid-subscription-id>/resourceGroups/PromitorRG\" Which should output something similar to { \"appId\" : \"<guid-sp-app-id>\" , \"displayName\" : \"azure-cli-2019-03-29-19-21-58\" , \"name\" : \"http://azure-cli-2019-03-29-19-21-58\" , \"password\" : \"<guid-sp-generated-password>\" , \"tenant\" : \"<guid-tenant-id>\" } Save this output as we will use the app ID, tenant ID, and password later on.","title":"Create a Service Principal"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-service-bus-namespace-and-queue","text":"First we'll need to create a namespace. Service Bus Namespaces need to be globally unique, so we won't use a default name in these commands. az servicebus namespace create \\ --resource-group PromitorRG \\ --name <service-bus-namespace> \\ --location eastus We'll then create a queue in that namespace: az servicebus queue create \\ --resource-group PromitorRG \\ --namespace-name <service-bus-namespace> \\ --name demo_queue Finally, get the connection string for this Service Bus namespace for use later. az servicebus namespace authorization-rule keys list \\ --resource-group PromitorRG \\ --namespace-name <service-bus-namespace> \\ --name RootManageSharedAccessKey \\ --query primaryConnectionString \\ --output tsv","title":"Create a Service Bus Namespace and Queue"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-an-aks-cluster","text":"Create a cluster with: az aks create \\ --name PromitorCluster \\ --resource-group PromitorRG \\ --node-count 1 \\ --generate-ssh-keys","title":"Create an AKS Cluster"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#cluster-setup","text":"","title":"Cluster Setup"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#get-credentials","text":"You can get your cluster's credentials with az aks get-credentials \\ --name PromitorCluster \\ --resource-group PromitorRG This will save these credentials to your kubeconfig file and set your new cluster as your current context for all kubectl commands. Verify your credentials and check that your cluster is up and running with kubectl get nodes .","title":"Get credentials"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#deploy-promitor-and-prometheus","text":"","title":"Deploy Promitor and Prometheus"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-metrics-declaration-for-promitor","text":"Before deploying Promitor, you'll need a values file with secrets & a metric declaration file (these can also be the same file for ease of use). The yaml below will scrape one metric, queue length, from the queue created above. azureAuthentication : appId : <guid-sp-app-id> appKey : <guid-sp-generated-password> azureMetadata : tenantId : <guid-tenant-id> subscriptionId : <guid-subscription-id> resourceGroupName : PromitorRG metricDefaults : aggregation : interval : 00:05:00 scraping : schedule : \"* * * * *\" metrics : - name : demo_queue_size description : \"Amount of active messages of the 'demo_queue' queue\" resourceType : ServiceBusNamespace azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : - namespace : <service-bus-namespace> queueName : demo_queue","title":"Create a metrics declaration for Promitor"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#deploy-promitor-to-your-cluster-using-helm","text":"To deploy, we'll first add the Promitor chart repository to helm: helm repo add promitor https://charts.promitor.io/ helm repo update With this repository added, we can deploy Promitor: helm install promitor-agent-scraper promitor/promitor-agent-scraper \\ --values your/path/to/metric-declaration.yaml","title":"Deploy Promitor to your cluster using Helm"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#install-prometheus","text":"Note: If you're seeing errors installing Prometheus or Grafana from the Helm chart repository, make sure you run helm repo update before digging into the errors more. You might have an outdated copy of the chart. Running the deployment command from the previous section should give you an output that includes a script similar to this one: cat > promitor-scrape-config.yaml <<EOF extraScrapeConfigs: | - job_name: promitor-agent-scraper metrics_path: /metrics static_configs: - targets: - promitor-agent-scraper.default.svc.cluster.local:80 EOF helm install stable/prometheus -f promitor-scrape-config.yaml You can see this output again at any time by running helm status promitor-agent-scraper . Running these commands will create a Prometheus scraping configuration file in your current directory and deploy Prometheus to your cluster with that scraping configuration in addition to the default.","title":"Install Prometheus"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#test-and-check-output","text":"","title":"Test and check output"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#add-load-to-the-queue","text":"Now we'll use Service Bus Explorer to add load to our Service Bus queue so there are meaningful metrics for Promitor to pick up. In Service Bus Explorer, you can connect to your namespace & queue using a connection string. From there, right clicking on the queue in the side-bar should give you an option to 'Send Message' - from there, use the 'Sender' tab of that window to send bulk messages. Remember how many you send - you should see that number in the Promitor & Prometheus output.","title":"Add load to the queue"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#see-promitor-prometheus-output-via-port-forwarding","text":"Going back to your cluster, you should be able to see all Promitor & Prometheus pods up and running with kubectl get pods . You can also see the services which provide a stable endpoint at which to reach the pods by running kubectl get services . This should give you a list with output similar to: NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) promitor-agent-scraper ClusterIP 10.0.#.# \\<none> 80/TCP \\<prometheus-release-name>-prometheus-server ClusterIP 10.0.#.# \\<none> 80/TCP Next to that, it should also list other services deployed by Prometheus. Let's first look at the Promitor output! Run kubectl port-forward svc/promitor-agent-scraper 8080:80 and check http://localhost:8080/metrics . You should see some information about your queue: # HELP promitor_ratelimit_arm Indication how many calls are still available before Azure Resource Manager is going to throttle us. # TYPE promitor_ratelimit_arm gauge promitor_ratelimit_arm { tenant_id = <guid-tenant-id>,subscription_id = <guid-subscription-id>,app_id = <guid-sp-app-id> } 11998 1558116465529 # HELP demo_queue_size Amount of active messages of the 'demo_queue' queue # TYPE demo_queue_size gauge demo_queue_size 200 1558116465677 where 200 is the number of messages sent. We can also look at the Prometheus server and check that it's pulling in metrics from Promitor. Cancel the previous port-forward command and run kubectl port-forward svc/<prometheus-release-name>-prometheus-server 8080:80 . Now, if you check http://localhost:8080 , you should be able to enter Prometheus queries. Query demo_queue_size and as long as all your pods are up and running and both Promitor and Prometheus have scraped metrics at least once, you should see a value that matches the number of messages in your queue.","title":"See Promitor &amp; Prometheus output via port-forwarding"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#visualization","text":"","title":"Visualization"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#install-grafana","text":"Grafana's chart has a few default values you may not want long term - persistant storage is disabled and admin username/password is randomly generated - but for our sample the out-of-the-box install will work. Run helm install grafana stable/grafana and you should see output that includes this command: kubectl get secret --namespace default grafana -o jsonpath = \"{.data.admin-password}\" | base64 --decode ; echo Run this to get your Grafana password. Now you can use kubectl port-forward again to log in to your Grafana dashboard. kubectl port-forward svc/grafana 8080:80 will make your dashboard available at http://localhost:8080 , and you can log in with username 'admin' and the password you retrieved.","title":"Install Grafana"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#add-prometheus-as-a-data-source","text":"After logging in, you should see an option to \"Add a Data Source.\" Click that, and choose the Prometheus source type (if it's not immediately visible, search for it). The only setting you should need to edit here is the URL, under the HTTP section. Within your cluster, http://<prometheus-release-name>-prometheus-server.default.svc.cluster.local should resolve to the Prometheus server service. (Default in that URL refers to the namespace - if you installed in a namespace other than default, change that.) Set your service's name as the Prometheus URL in Grafana, and save the data source. It should tell you that the data source is working.","title":"Add Prometheus as a data source"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#create-a-grafana-dashboard-for-queue-metrics","text":"First, we'll make a basic dashboard with the metric we set up in Promitor. Then you can use a pre-built dashboard to show Prometheus' default Kubernetes metrics. Go to the + button on the sidebar, and choose \"Dashboard\". To make a simple graph showing your queue size, you can write demo_queue_size in the query field. Click out of that input field and the graph should update. To see more, you can go back to Service Bus Explorer and send or receive messages. Your Grafana graph won't update immediately, but you should see results in a few minutes. In order to see results without manually refreshing, find the dropdown menu in the top right corner that sets the time range of the graph. Here you can edit time range and refresh rate. Make sure to save your new dashboard before exiting the page.","title":"Create a Grafana dashboard for queue metrics"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#creating-a-kubernetes-dashboard","text":"Now we'll import a pre-created dashboard that shows Kubernetes metrics. There are multiple available on Grafana Lab's dashboard site - try 6417 . To import a dashboard, click the + button on the sidebar and choose \"Import.\" From there, you can either load a JSON file or enter the dashbord ID: 6417. Click \"Load\" and you will be given some configuration options. The only one that needs to be set is the Prometheus data source. From there, you should be able to create the dashboard and view metrics about your AKS cluster.","title":"Creating a Kubernetes dashboard"},{"location":"walkthroughs/scrape-promitor-with-prometheus-on-azure-kubernetes-service/#delete-resources","text":"To delete all the resources used in this tutorial, run az group delete --name PromitorRG . \u2190 back","title":"Delete resources"},{"location":"walkthroughs/use-promitor-with-managed-identity/","text":"Using Managed Identity with Promitor on Azure Kubernetes Service \u00b6 Introduction \u00b6 This walkthrough will allow you to deploy Promitor that uses Managed Identity on an Azure Kubernetes Service cluster to scrape Azure Service Bus metrics, using no-password authentication. In order to achieve this, we will use the AAD Pod Identity project to manage the identities and authentication. \u26a0 This only works with Azure Kubernetes Service - Learn more about Managed Identity in Azure Kubernetes Service in the official Microsoft documentation. Table of Contents \u00b6 Introduction Table of Contents Prerequisites Deploying the Azure Infrastructure Preparing script Creating an Azure Resource Group Creating an Azure Service Bus Namespace & Queue Creating an Azure Kubernetes Service Cluster Setting up our cluster Getting The Cluster Credentials Get Azure Kubernetes Service managed identity & cluster resource group Getting our cluster ready to use AAD Pod Identity Granting our cluster's managed identity required permissions in Azure Installing AAD Pod Identity Creating a user-assigned managed identity for Promitor Bind your Managed Identity to our Pods, through AAD Pod Identity Verifying the AAD Pod Identity installation Deploying Promitor with Managed Identity Create a metrics declaration for Promitor Deploy Promitor to your cluster using Helm Verifying the scraped output in Promitor Cleaning up Prerequisites \u00b6 Azure CLI , to be able to deploy resources through the command line. kubectl , the Kubernetes command-line tool. It can also be installed via the Azure CLI with az aks install-cli . Helm , a Kubernetes deployment manager. WSL , if you are using a Windows machine to deploy your whole solution. Deploying the Azure Infrastructure \u00b6 Preparing script \u00b6 Since we are going to use a lot of bash scripts with different variables values, it can be a good idea to parameterize everything. Let's start by exporting all the values we need: # SUBSCRIPTION_ID represents the Azure subscription id you will use to access your Azure resources export SUBSCRIPTION_ID = <subscription-id> # RG_NAME represents the resource group name where your cluster will be deployed export RG_NAME = PromitorWithManagedIdentityRG # LOCATION represents the Azure region where your cluster will be deployed export LOCATION = northeurope # CLUSTER_NAME represents the name of your Azure Kubernetes Service Cluster export CLUSTER_NAME = PromitorCluster # AD_POD_IDENTITY_NAME represents the name of the Azure AD identity that will be assigned to Promitor. # Be careful, should be lower case alphanumeric characters, '-' or '.' export AD_POD_IDENTITY_NAME = promitor-identity # As an example, we are going to use a service bus from where we want to grab some metrics, through Promitor # SERVICE_BUS_NAMESPACE represents the name of your Azure Service Bus namespace. # Be careful as Azure Service Bus Namespaces need to be globally unique. export SERVICE_BUS_NAMESPACE = PromitorUniqueNameServiceBus # SERVICE_BUS_QUEUE represents the name of you Azure Service Bus queue. export SERVICE_BUS_QUEUE = demo_queue Creating an Azure Resource Group \u00b6 First, let's create an Azure resource group in which we'll group all our resources: $ az group create --name $RG_NAME --location $LOCATION { \"id\" : \"/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>\" , \"location\" : \"<location-id>\" , \"managedBy\" : null, \"name\" : \"<resource-group-name>\" , \"properties\" : { \"provisioningState\" : \"Succeeded\" } , \"tags\" : null, \"type\" : \"Microsoft.Resources/resourceGroups\" } Creating an Azure Service Bus Namespace & Queue \u00b6 First we'll need to create an Azure Service Bus namespace that provides metrics in Azure Monitor. These metrics will be scraped by Promitor and made available to the configured metric sinks. \ud83d\udca1 Consider this to be an example of metrics that you'd want to use in Prometheus, StatsD, ... Let's create the Azure Service Bus namespace: $ az servicebus namespace create \\ --resource-group $RG_NAME \\ --name $SERVICE_BUS_NAMESPACE \\ --location $LOCATION After that, we'll create a queue in that namespace: $ az servicebus queue create \\ --resource-group $RG_NAME \\ --namespace-name $SERVICE_BUS_NAMESPACE \\ --name $SERVICE_BUS_QUEUE Creating an Azure Kubernetes Service Cluster \u00b6 Create an Azure Kubernetes Service cluster that uses a system-assigned managed identity: $ az aks create --resource-group $RG_NAME \\ --name $CLUSTER_NAME \\ --generate-ssh-keys \\ --node-count 1 \\ --enable-managed-identity ... \"servicePrincipalProfile\" : { \"clientId\" : \"msi\" } ... Once created, the output will indicate that it is using managed identity. Setting up our cluster \u00b6 Getting The Cluster Credentials \u00b6 In order to interact with the cluster by using kubectl , we need to be able to authenticate to it. You can get the credentials for your Kubernetes cluster using this command: $ az aks get-credentials --name $CLUSTER_NAME --resource-group $RG_NAME Merged \"<cluster-name>\" as current context in /home/tom/.kube/config This saves the credentials in your kubeconfig file and uses it as your current context for all kubectl commands. Verify that you can connect and your cluster is up and running : $ kubectl get nodes NAME STATUS ROLES AGE VERSION aks-agentpool-34594731-vmss000000 Ready agent 15d v1.19.7 aks-agentpool-34594731-vmss000001 Ready agent 15d v1.19.7 aks-agentpool-34594731-vmss000002 Ready agent 15d v1.19.7 Get Azure Kubernetes Service managed identity & cluster resource group \u00b6 To be able to configure AAD Pod Identity component, we need information from our new Azure Kubernetes Service cluster: First, we need to get the name of the cluster resource group where the AKS internal resources have been deployed. echo \"Retrieving cluster resource group\" export aks_rg_name = $( az aks show -g $RG_NAME -n $CLUSTER_NAME --query nodeResourceGroup -otsv ) This is a generated resource group that typically uses MC_{resource-group}_{cluster-name}_{region} , for example MC_promitor-landscape_promitor_westeurope . Second, we need the identity of our cluster . This is the system-assigned identity of our cluster that is used to access Azure resources. echo \"Retrieving cluster identity ID, which will be used for role assignment\" export aks_mi_identity = \" $( az aks show -g ${ RG_NAME } -n ${ CLUSTER_NAME } --query identityProfile.kubeletidentity.clientId -otsv ) \" This identity is managed by Azure, since we have used the --enable-managed-identity option during cluster creation. Getting our cluster ready to use AAD Pod Identity \u00b6 Granting our cluster's managed identity required permissions in Azure \u00b6 In this walkthrough we are going to configure the managed identity for our cluster to allow AAD Pod Identity to access required resources in Azure. Learn more about the the required role assignments for AAD Pod Identity or have a general overview in the official documentation . In order to be able to use AAD Pod Identity, our cluster needs to be able to: Manage identities in our application & cluster resource group Manage the virtual machines that are part of the cluster, to use the assigned identity You can easily do this as following: echo \"Assigning 'Managed Identity Operator' role to ${ aks_mi_identity } on resource group ${ aks_rg_name } \" az role assignment create --role \"Managed Identity Operator\" --assignee \" ${ aks_mi_identity } \" --scope \"/subscriptions/ ${ SUBSCRIPTION_ID } /resourcegroups/ ${ aks_rg_name } \" echo \"Assigning 'Virtual Machine Contributor' role to ${ aks_mi_identity } on resource group ${ aks_rg_name } \" az role assignment create --role \"Virtual Machine Contributor\" --assignee \" ${ aks_mi_identity } \" --scope \"/subscriptions/ ${ SUBSCRIPTION_ID } /resourcegroups/ ${ aks_rg_name } \" echo \"Assigning 'Managed Identity Operator' role to ${ aks_mi_identity } on resource group ${ RG_NAME } \" az role assignment create --role \"Managed Identity Operator\" --assignee \" ${ aks_mi_identity } \" --scope \"/subscriptions/ ${ SUBSCRIPTION_ID } /resourcegroups/ ${ RG_NAME } \" Installing AAD Pod Identity \u00b6 To deploy AAD Pod Identity, we need to add the Helm chart repository: $ helm repo add aad-pod-identity https://raw.githubusercontent.com/Azure/aad-pod-identity/master/charts \"aad-pod-identity\" has been added to your repositories Update all your Helm repositories to use the latest and greatest: $ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"aad-pod-identity\" chart repository Update Complete. \u2388Happy Helming!\u2388 Lastly, install the Helm chart into your cluster: helm install aad-pod-identity aad-pod-identity/aad-pod-identity --set nmi.allowNetworkPluginKubenet = true Creating a user-assigned managed identity for Promitor \u00b6 In order to let Promitor to authenticate to Azure, we have two options: Re-ue the managed identity of our cluster, or (syste-assigned) Create a new identity that we will assign to our Promitor pods (user-assigned) In order to separate our concerns , we will create a new identity for it: echo \"Create identity $AD_POD_IDENTITY_NAME in resource group $RG_NAME \" az identity create -g ${ RG_NAME } -n ${ AD_POD_IDENTITY_NAME } Our new identity will be used by Promitor to access Azure Monitor to get metrics by using its assigned RBAC roles assignements : First, we will get the client & resource id of our identity: export AD_POD_IDENTITY_CLIENT_ID = $( az identity show -g ${ RG_NAME } -n ${ AD_POD_IDENTITY_NAME } --query \"clientId\" -o tsv ) export AD_POD_IDENTITY_RESOURCE_ID = $( az identity show -g ${ RG_NAME } -n ${ AD_POD_IDENTITY_NAME } --query \"id\" -o tsv ) Next, we will assign the Monitoring Reader role to our identity on our resource group to scrape our Azure Service Bus namespace: $ az role assignment create --role \"Monitoring Reader\" --scope \"/subscriptions/ $SUBSCRIPTION_ID /resourceGroups/ $RG_NAME \" --assignee \" ${ AD_POD_IDENTITY_CLIENT_ID } \" { \"canDelegate\" : null, \"condition\" : null, \"conditionVersion\" : null, \"description\" : null, \"id\" : \"/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.Authorization/roleAssignments/92b1566a-2346-43f7-a093-1fd5871d4de8\" , \"name\" : \"92b1566a-2346-43f7-a093-1fd5871d4de8\" , \"principalId\" : \"<promitor-identity-id>\" , \"principalType\" : \"ServicePrincipal\" , \"resourceGroup\" : \"<resource-group-name>\" , \"roleDefinitionId\" : \"/subscriptions/<subscription-id>/providers/Microsoft.Authorization/roleDefinitions/43d0d8ad-25c7-4714-9337-8ba259a9fe05\" , \"scope\" : \"/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>\" , \"type\" : \"Microsoft.Authorization/roleAssignments\" } In order to verify our role assignement, you can use this command: az role assignment list --assignee $AD_POD_IDENTITY_CLIENT_ID -g $RG_NAME | jq -r '.[].roleDefinitionName' \ud83d\udca1 It can take some times before the identity is correctly propagated in Azure Active Directory. So far if you encountered an error where the identity is not found, please wait 60 sec and retry Bind your Managed Identity to our Pods, through AAD Pod Identity \u00b6 Now that our identity is created, we can tell AAD Pod Identity that we want to bind our Azure AD identity to our pods: First, we will define the identity that we want to assign: cat <<EOF | kubectl apply -f - apiVersion: \"aadpodidentity.k8s.io/v1\" kind: AzureIdentity metadata: name: ${AD_POD_IDENTITY_NAME} spec: type: 0 # 0 - user assigned MSI, 1 - service principal resourceID: ${AD_POD_IDENTITY_RESOURCE_ID} clientID: ${AD_POD_IDENTITY_CLIENT_ID} EOF Next, we want to define to what pods we want to link it: cat <<EOF | kubectl apply -f - apiVersion: \"aadpodidentity.k8s.io/v1\" kind: AzureIdentityBinding metadata: name: ${AD_POD_IDENTITY_NAME}-binding spec: azureIdentity: ${AD_POD_IDENTITY_NAME} selector: ${AD_POD_IDENTITY_NAME} EOF You can verify that the resources were created successfully as following: kubectl get azureidentity kubectl get azureidentitybinding Verifying the AAD Pod Identity installation \u00b6 Before going further, we will check if our AAD Pod Identity is deployed & configured correctly. We will spin up a pod and use the Azure CLI to authenticate: kubectl run azure-cli -it --image = mcr.microsoft.com/azure-cli --labels = aadpodidbinding = $AD_POD_IDENTITY_NAME /bin/bash Note that we are adding aadpodidbinding as a label, which is linking the pod to the AAD Pod Identity binding that we have just created. Warning: It can take some times to Aad Pod Identity to bind the identity to your deployed container. If you encountered an error, relaunch the az login -i --debug command after 60 sec. Next, we will run az login -i --debug to see the different steps it takes: # Once you are log in the container, and have the bash command line available, try to login using the Managed Identity: # If you don't see a command prompt, try pressing enter. $ bash-5.0# az login -i --debug msrestazure.azure_active_directory: MSI: Retrieving a token from http://169.254.169.254/metadata/identity/oauth2/token, with payload { 'resource' : 'https://management.core.windows.net/' , 'api-version' : '2018-02-01' } msrestazure.azure_active_directory: MSI: Token retrieved cli.azure.cli.core._profile: MSI: token was retrieved. Now trying to initialize local accounts... ... [ { \"environmentName\" : \"AzureCloud\" , \"homeTenantId\" : \"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\" , \"id\" : \"0f9d7fea-99e8-4768-8672-06a28514f77e\" , \"isDefault\" : true, \"managedByTenants\" : [ { \"tenantId\" : \"2f4a9838-26b7-47ee-be60-ccc1fdec5953\" } ] , \"name\" : \"Visual Studio Enterprise\" , \"state\" : \"Enabled\" , \"tenantId\" : \"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\" , \"user\" : { \"assignedIdentityInfo\" : \"MSI\" , \"name\" : \"systemAssignedIdentity\" , \"type\" : \"servicePrincipal\" } } ] If your Azure CLI container is able to retrieve some information from Azure without having to log in with your credentials, it means the CLI is using your Managed Identity, through the Pod Identity Binding. You may have a result indicating you are log in, using a System Assigned Identity \"user\" : { \"assignedIdentityInfo\" : \"MSI\" , \"name\" : \"systemAssignedIdentity\" , } Deploying Promitor with Managed Identity \u00b6 Create a metrics declaration for Promitor \u00b6 Before deploying Promitor, we will create a values file for our Helm deployment. In the configuration, we define what Azure resource that we want to scrape and that we want to use managed identity. Here is an example: azureAuthentication : mode : SystemAssignedManagedIdentity identity : binding : <aad-pod-identity-name> # <- This is the value of AD_POD_IDENTITY_NAME environment variable azureMetadata : tenantId : <tenant-id> subscriptionId : <subscription-id> # <- This is the value of SUBSCRIPTION_ID environment variable resourceGroupName : <promitor-resource-group-id> # <- This is the value of RG_NAME environment variable metricDefaults : aggregation : interval : 00:05:00 scraping : schedule : \"* * * * *\" metrics : - name : demo_queue_size description : \"Amount of active messages of the 'demo_queue' queue\" resourceType : ServiceBusNamespace azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : - namespace : <service-bus-namespace> # <- This is the value of SERVICE_BUS_NAMESPACE environment variable queueName : <service-bus-queue> # <- This is the value of SERVICE_BUS_QUEUE_NAME environment variable Deploy Promitor to your cluster using Helm \u00b6 To deploy, we'll first add the Promitor chart repository to helm: helm repo add promitor https://charts.promitor.io/ helm repo update With this repository added, we can deploy Promitor: helm install promitor-agent-scraper promitor/promitor-agent-scraper --values your/path/to/metric-declaration.yaml Verifying the scraped output in Promitor \u00b6 You can check that Promitor is getting insights from you Azure Service Bus queue, using the managed identity, with this commands. First, we get the name of the Promitor Scraper pod: # Get promitor pod export POD_NAME = $( kubectl get pods --namespace default -l \"app.kubernetes.io/instance=promitor-agent-scraper\" -o jsonpath = \"{.items[0].metadata.name}\" ) Next, we add port forwarding from our pod to our local machine: kubectl port-forward --namespace default $POD_NAME 8080 :88 Now browse to the address http://127.0.0.1:8080/metrics and check your metrics are scrapped: # HELP demo_queue_size Amount of active messages of the 'demo_queue' queue # TYPE demo_queue_size gauge demo_queue_size{resource_group=\"ammdocs\",subscription_id=\"xxxxx-xxxxx-xxxxx-xxxxxx-xxxxx\",resource_uri=\"subscriptions/xxxxx-xxxxx-xxxxx-xxxxxx-xxxxx/resourceGroups/YOUR_RESOURCE_GROUP_NAME/providers/Microsoft.ServiceBus/namespaces/YOUR_SERVICE_BUS_NAMESPACE\",instance_name=\"INSTANCE_NAME\",entity_name=\"YOUR_SERVICE_BUS_QUEUE\"} 0 1612952581417 Cleaning up \u00b6 To delete all the resources used in this tutorial, run az group delete --name $RG_NAME . \u2190 back","title":"Using Managed Identity with Promitor on an AKS Cluster"},{"location":"walkthroughs/use-promitor-with-managed-identity/#using-managed-identity-with-promitor-on-azure-kubernetes-service","text":"","title":"Using Managed Identity with Promitor on Azure Kubernetes Service"},{"location":"walkthroughs/use-promitor-with-managed-identity/#introduction","text":"This walkthrough will allow you to deploy Promitor that uses Managed Identity on an Azure Kubernetes Service cluster to scrape Azure Service Bus metrics, using no-password authentication. In order to achieve this, we will use the AAD Pod Identity project to manage the identities and authentication. \u26a0 This only works with Azure Kubernetes Service - Learn more about Managed Identity in Azure Kubernetes Service in the official Microsoft documentation.","title":"Introduction"},{"location":"walkthroughs/use-promitor-with-managed-identity/#table-of-contents","text":"Introduction Table of Contents Prerequisites Deploying the Azure Infrastructure Preparing script Creating an Azure Resource Group Creating an Azure Service Bus Namespace & Queue Creating an Azure Kubernetes Service Cluster Setting up our cluster Getting The Cluster Credentials Get Azure Kubernetes Service managed identity & cluster resource group Getting our cluster ready to use AAD Pod Identity Granting our cluster's managed identity required permissions in Azure Installing AAD Pod Identity Creating a user-assigned managed identity for Promitor Bind your Managed Identity to our Pods, through AAD Pod Identity Verifying the AAD Pod Identity installation Deploying Promitor with Managed Identity Create a metrics declaration for Promitor Deploy Promitor to your cluster using Helm Verifying the scraped output in Promitor Cleaning up","title":"Table of Contents"},{"location":"walkthroughs/use-promitor-with-managed-identity/#prerequisites","text":"Azure CLI , to be able to deploy resources through the command line. kubectl , the Kubernetes command-line tool. It can also be installed via the Azure CLI with az aks install-cli . Helm , a Kubernetes deployment manager. WSL , if you are using a Windows machine to deploy your whole solution.","title":"Prerequisites"},{"location":"walkthroughs/use-promitor-with-managed-identity/#deploying-the-azure-infrastructure","text":"","title":"Deploying the Azure Infrastructure"},{"location":"walkthroughs/use-promitor-with-managed-identity/#preparing-script","text":"Since we are going to use a lot of bash scripts with different variables values, it can be a good idea to parameterize everything. Let's start by exporting all the values we need: # SUBSCRIPTION_ID represents the Azure subscription id you will use to access your Azure resources export SUBSCRIPTION_ID = <subscription-id> # RG_NAME represents the resource group name where your cluster will be deployed export RG_NAME = PromitorWithManagedIdentityRG # LOCATION represents the Azure region where your cluster will be deployed export LOCATION = northeurope # CLUSTER_NAME represents the name of your Azure Kubernetes Service Cluster export CLUSTER_NAME = PromitorCluster # AD_POD_IDENTITY_NAME represents the name of the Azure AD identity that will be assigned to Promitor. # Be careful, should be lower case alphanumeric characters, '-' or '.' export AD_POD_IDENTITY_NAME = promitor-identity # As an example, we are going to use a service bus from where we want to grab some metrics, through Promitor # SERVICE_BUS_NAMESPACE represents the name of your Azure Service Bus namespace. # Be careful as Azure Service Bus Namespaces need to be globally unique. export SERVICE_BUS_NAMESPACE = PromitorUniqueNameServiceBus # SERVICE_BUS_QUEUE represents the name of you Azure Service Bus queue. export SERVICE_BUS_QUEUE = demo_queue","title":"Preparing script"},{"location":"walkthroughs/use-promitor-with-managed-identity/#creating-an-azure-resource-group","text":"First, let's create an Azure resource group in which we'll group all our resources: $ az group create --name $RG_NAME --location $LOCATION { \"id\" : \"/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>\" , \"location\" : \"<location-id>\" , \"managedBy\" : null, \"name\" : \"<resource-group-name>\" , \"properties\" : { \"provisioningState\" : \"Succeeded\" } , \"tags\" : null, \"type\" : \"Microsoft.Resources/resourceGroups\" }","title":"Creating an Azure Resource Group"},{"location":"walkthroughs/use-promitor-with-managed-identity/#creating-an-azure-service-bus-namespace-queue","text":"First we'll need to create an Azure Service Bus namespace that provides metrics in Azure Monitor. These metrics will be scraped by Promitor and made available to the configured metric sinks. \ud83d\udca1 Consider this to be an example of metrics that you'd want to use in Prometheus, StatsD, ... Let's create the Azure Service Bus namespace: $ az servicebus namespace create \\ --resource-group $RG_NAME \\ --name $SERVICE_BUS_NAMESPACE \\ --location $LOCATION After that, we'll create a queue in that namespace: $ az servicebus queue create \\ --resource-group $RG_NAME \\ --namespace-name $SERVICE_BUS_NAMESPACE \\ --name $SERVICE_BUS_QUEUE","title":"Creating an Azure Service Bus Namespace &amp; Queue"},{"location":"walkthroughs/use-promitor-with-managed-identity/#creating-an-azure-kubernetes-service-cluster","text":"Create an Azure Kubernetes Service cluster that uses a system-assigned managed identity: $ az aks create --resource-group $RG_NAME \\ --name $CLUSTER_NAME \\ --generate-ssh-keys \\ --node-count 1 \\ --enable-managed-identity ... \"servicePrincipalProfile\" : { \"clientId\" : \"msi\" } ... Once created, the output will indicate that it is using managed identity.","title":"Creating an Azure Kubernetes Service Cluster"},{"location":"walkthroughs/use-promitor-with-managed-identity/#setting-up-our-cluster","text":"","title":"Setting up our cluster"},{"location":"walkthroughs/use-promitor-with-managed-identity/#getting-the-cluster-credentials","text":"In order to interact with the cluster by using kubectl , we need to be able to authenticate to it. You can get the credentials for your Kubernetes cluster using this command: $ az aks get-credentials --name $CLUSTER_NAME --resource-group $RG_NAME Merged \"<cluster-name>\" as current context in /home/tom/.kube/config This saves the credentials in your kubeconfig file and uses it as your current context for all kubectl commands. Verify that you can connect and your cluster is up and running : $ kubectl get nodes NAME STATUS ROLES AGE VERSION aks-agentpool-34594731-vmss000000 Ready agent 15d v1.19.7 aks-agentpool-34594731-vmss000001 Ready agent 15d v1.19.7 aks-agentpool-34594731-vmss000002 Ready agent 15d v1.19.7","title":"Getting The Cluster Credentials"},{"location":"walkthroughs/use-promitor-with-managed-identity/#get-azure-kubernetes-service-managed-identity-cluster-resource-group","text":"To be able to configure AAD Pod Identity component, we need information from our new Azure Kubernetes Service cluster: First, we need to get the name of the cluster resource group where the AKS internal resources have been deployed. echo \"Retrieving cluster resource group\" export aks_rg_name = $( az aks show -g $RG_NAME -n $CLUSTER_NAME --query nodeResourceGroup -otsv ) This is a generated resource group that typically uses MC_{resource-group}_{cluster-name}_{region} , for example MC_promitor-landscape_promitor_westeurope . Second, we need the identity of our cluster . This is the system-assigned identity of our cluster that is used to access Azure resources. echo \"Retrieving cluster identity ID, which will be used for role assignment\" export aks_mi_identity = \" $( az aks show -g ${ RG_NAME } -n ${ CLUSTER_NAME } --query identityProfile.kubeletidentity.clientId -otsv ) \" This identity is managed by Azure, since we have used the --enable-managed-identity option during cluster creation.","title":"Get Azure Kubernetes Service managed identity &amp; cluster resource group"},{"location":"walkthroughs/use-promitor-with-managed-identity/#getting-our-cluster-ready-to-use-aad-pod-identity","text":"","title":"Getting our cluster ready to use AAD Pod Identity"},{"location":"walkthroughs/use-promitor-with-managed-identity/#granting-our-clusters-managed-identity-required-permissions-in-azure","text":"In this walkthrough we are going to configure the managed identity for our cluster to allow AAD Pod Identity to access required resources in Azure. Learn more about the the required role assignments for AAD Pod Identity or have a general overview in the official documentation . In order to be able to use AAD Pod Identity, our cluster needs to be able to: Manage identities in our application & cluster resource group Manage the virtual machines that are part of the cluster, to use the assigned identity You can easily do this as following: echo \"Assigning 'Managed Identity Operator' role to ${ aks_mi_identity } on resource group ${ aks_rg_name } \" az role assignment create --role \"Managed Identity Operator\" --assignee \" ${ aks_mi_identity } \" --scope \"/subscriptions/ ${ SUBSCRIPTION_ID } /resourcegroups/ ${ aks_rg_name } \" echo \"Assigning 'Virtual Machine Contributor' role to ${ aks_mi_identity } on resource group ${ aks_rg_name } \" az role assignment create --role \"Virtual Machine Contributor\" --assignee \" ${ aks_mi_identity } \" --scope \"/subscriptions/ ${ SUBSCRIPTION_ID } /resourcegroups/ ${ aks_rg_name } \" echo \"Assigning 'Managed Identity Operator' role to ${ aks_mi_identity } on resource group ${ RG_NAME } \" az role assignment create --role \"Managed Identity Operator\" --assignee \" ${ aks_mi_identity } \" --scope \"/subscriptions/ ${ SUBSCRIPTION_ID } /resourcegroups/ ${ RG_NAME } \"","title":"Granting our cluster's managed identity required permissions in Azure"},{"location":"walkthroughs/use-promitor-with-managed-identity/#installing-aad-pod-identity","text":"To deploy AAD Pod Identity, we need to add the Helm chart repository: $ helm repo add aad-pod-identity https://raw.githubusercontent.com/Azure/aad-pod-identity/master/charts \"aad-pod-identity\" has been added to your repositories Update all your Helm repositories to use the latest and greatest: $ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"aad-pod-identity\" chart repository Update Complete. \u2388Happy Helming!\u2388 Lastly, install the Helm chart into your cluster: helm install aad-pod-identity aad-pod-identity/aad-pod-identity --set nmi.allowNetworkPluginKubenet = true","title":"Installing AAD Pod Identity"},{"location":"walkthroughs/use-promitor-with-managed-identity/#creating-a-user-assigned-managed-identity-for-promitor","text":"In order to let Promitor to authenticate to Azure, we have two options: Re-ue the managed identity of our cluster, or (syste-assigned) Create a new identity that we will assign to our Promitor pods (user-assigned) In order to separate our concerns , we will create a new identity for it: echo \"Create identity $AD_POD_IDENTITY_NAME in resource group $RG_NAME \" az identity create -g ${ RG_NAME } -n ${ AD_POD_IDENTITY_NAME } Our new identity will be used by Promitor to access Azure Monitor to get metrics by using its assigned RBAC roles assignements : First, we will get the client & resource id of our identity: export AD_POD_IDENTITY_CLIENT_ID = $( az identity show -g ${ RG_NAME } -n ${ AD_POD_IDENTITY_NAME } --query \"clientId\" -o tsv ) export AD_POD_IDENTITY_RESOURCE_ID = $( az identity show -g ${ RG_NAME } -n ${ AD_POD_IDENTITY_NAME } --query \"id\" -o tsv ) Next, we will assign the Monitoring Reader role to our identity on our resource group to scrape our Azure Service Bus namespace: $ az role assignment create --role \"Monitoring Reader\" --scope \"/subscriptions/ $SUBSCRIPTION_ID /resourceGroups/ $RG_NAME \" --assignee \" ${ AD_POD_IDENTITY_CLIENT_ID } \" { \"canDelegate\" : null, \"condition\" : null, \"conditionVersion\" : null, \"description\" : null, \"id\" : \"/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>/providers/Microsoft.Authorization/roleAssignments/92b1566a-2346-43f7-a093-1fd5871d4de8\" , \"name\" : \"92b1566a-2346-43f7-a093-1fd5871d4de8\" , \"principalId\" : \"<promitor-identity-id>\" , \"principalType\" : \"ServicePrincipal\" , \"resourceGroup\" : \"<resource-group-name>\" , \"roleDefinitionId\" : \"/subscriptions/<subscription-id>/providers/Microsoft.Authorization/roleDefinitions/43d0d8ad-25c7-4714-9337-8ba259a9fe05\" , \"scope\" : \"/subscriptions/<subscription-id>/resourceGroups/<resource-group-name>\" , \"type\" : \"Microsoft.Authorization/roleAssignments\" } In order to verify our role assignement, you can use this command: az role assignment list --assignee $AD_POD_IDENTITY_CLIENT_ID -g $RG_NAME | jq -r '.[].roleDefinitionName' \ud83d\udca1 It can take some times before the identity is correctly propagated in Azure Active Directory. So far if you encountered an error where the identity is not found, please wait 60 sec and retry","title":"Creating a user-assigned managed identity for Promitor"},{"location":"walkthroughs/use-promitor-with-managed-identity/#bind-your-managed-identity-to-our-pods-through-aad-pod-identity","text":"Now that our identity is created, we can tell AAD Pod Identity that we want to bind our Azure AD identity to our pods: First, we will define the identity that we want to assign: cat <<EOF | kubectl apply -f - apiVersion: \"aadpodidentity.k8s.io/v1\" kind: AzureIdentity metadata: name: ${AD_POD_IDENTITY_NAME} spec: type: 0 # 0 - user assigned MSI, 1 - service principal resourceID: ${AD_POD_IDENTITY_RESOURCE_ID} clientID: ${AD_POD_IDENTITY_CLIENT_ID} EOF Next, we want to define to what pods we want to link it: cat <<EOF | kubectl apply -f - apiVersion: \"aadpodidentity.k8s.io/v1\" kind: AzureIdentityBinding metadata: name: ${AD_POD_IDENTITY_NAME}-binding spec: azureIdentity: ${AD_POD_IDENTITY_NAME} selector: ${AD_POD_IDENTITY_NAME} EOF You can verify that the resources were created successfully as following: kubectl get azureidentity kubectl get azureidentitybinding","title":"Bind your Managed Identity to our Pods, through AAD Pod Identity"},{"location":"walkthroughs/use-promitor-with-managed-identity/#verifying-the-aad-pod-identity-installation","text":"Before going further, we will check if our AAD Pod Identity is deployed & configured correctly. We will spin up a pod and use the Azure CLI to authenticate: kubectl run azure-cli -it --image = mcr.microsoft.com/azure-cli --labels = aadpodidbinding = $AD_POD_IDENTITY_NAME /bin/bash Note that we are adding aadpodidbinding as a label, which is linking the pod to the AAD Pod Identity binding that we have just created. Warning: It can take some times to Aad Pod Identity to bind the identity to your deployed container. If you encountered an error, relaunch the az login -i --debug command after 60 sec. Next, we will run az login -i --debug to see the different steps it takes: # Once you are log in the container, and have the bash command line available, try to login using the Managed Identity: # If you don't see a command prompt, try pressing enter. $ bash-5.0# az login -i --debug msrestazure.azure_active_directory: MSI: Retrieving a token from http://169.254.169.254/metadata/identity/oauth2/token, with payload { 'resource' : 'https://management.core.windows.net/' , 'api-version' : '2018-02-01' } msrestazure.azure_active_directory: MSI: Token retrieved cli.azure.cli.core._profile: MSI: token was retrieved. Now trying to initialize local accounts... ... [ { \"environmentName\" : \"AzureCloud\" , \"homeTenantId\" : \"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\" , \"id\" : \"0f9d7fea-99e8-4768-8672-06a28514f77e\" , \"isDefault\" : true, \"managedByTenants\" : [ { \"tenantId\" : \"2f4a9838-26b7-47ee-be60-ccc1fdec5953\" } ] , \"name\" : \"Visual Studio Enterprise\" , \"state\" : \"Enabled\" , \"tenantId\" : \"e0372f7f-a362-47fb-9631-74a5c4ba8bbf\" , \"user\" : { \"assignedIdentityInfo\" : \"MSI\" , \"name\" : \"systemAssignedIdentity\" , \"type\" : \"servicePrincipal\" } } ] If your Azure CLI container is able to retrieve some information from Azure without having to log in with your credentials, it means the CLI is using your Managed Identity, through the Pod Identity Binding. You may have a result indicating you are log in, using a System Assigned Identity \"user\" : { \"assignedIdentityInfo\" : \"MSI\" , \"name\" : \"systemAssignedIdentity\" , }","title":"Verifying the AAD Pod Identity installation"},{"location":"walkthroughs/use-promitor-with-managed-identity/#deploying-promitor-with-managed-identity","text":"","title":"Deploying Promitor with Managed Identity"},{"location":"walkthroughs/use-promitor-with-managed-identity/#create-a-metrics-declaration-for-promitor","text":"Before deploying Promitor, we will create a values file for our Helm deployment. In the configuration, we define what Azure resource that we want to scrape and that we want to use managed identity. Here is an example: azureAuthentication : mode : SystemAssignedManagedIdentity identity : binding : <aad-pod-identity-name> # <- This is the value of AD_POD_IDENTITY_NAME environment variable azureMetadata : tenantId : <tenant-id> subscriptionId : <subscription-id> # <- This is the value of SUBSCRIPTION_ID environment variable resourceGroupName : <promitor-resource-group-id> # <- This is the value of RG_NAME environment variable metricDefaults : aggregation : interval : 00:05:00 scraping : schedule : \"* * * * *\" metrics : - name : demo_queue_size description : \"Amount of active messages of the 'demo_queue' queue\" resourceType : ServiceBusNamespace azureMetricConfiguration : metricName : ActiveMessages aggregation : type : Total resources : - namespace : <service-bus-namespace> # <- This is the value of SERVICE_BUS_NAMESPACE environment variable queueName : <service-bus-queue> # <- This is the value of SERVICE_BUS_QUEUE_NAME environment variable","title":"Create a metrics declaration for Promitor"},{"location":"walkthroughs/use-promitor-with-managed-identity/#deploy-promitor-to-your-cluster-using-helm","text":"To deploy, we'll first add the Promitor chart repository to helm: helm repo add promitor https://charts.promitor.io/ helm repo update With this repository added, we can deploy Promitor: helm install promitor-agent-scraper promitor/promitor-agent-scraper --values your/path/to/metric-declaration.yaml","title":"Deploy Promitor to your cluster using Helm"},{"location":"walkthroughs/use-promitor-with-managed-identity/#verifying-the-scraped-output-in-promitor","text":"You can check that Promitor is getting insights from you Azure Service Bus queue, using the managed identity, with this commands. First, we get the name of the Promitor Scraper pod: # Get promitor pod export POD_NAME = $( kubectl get pods --namespace default -l \"app.kubernetes.io/instance=promitor-agent-scraper\" -o jsonpath = \"{.items[0].metadata.name}\" ) Next, we add port forwarding from our pod to our local machine: kubectl port-forward --namespace default $POD_NAME 8080 :88 Now browse to the address http://127.0.0.1:8080/metrics and check your metrics are scrapped: # HELP demo_queue_size Amount of active messages of the 'demo_queue' queue # TYPE demo_queue_size gauge demo_queue_size{resource_group=\"ammdocs\",subscription_id=\"xxxxx-xxxxx-xxxxx-xxxxxx-xxxxx\",resource_uri=\"subscriptions/xxxxx-xxxxx-xxxxx-xxxxxx-xxxxx/resourceGroups/YOUR_RESOURCE_GROUP_NAME/providers/Microsoft.ServiceBus/namespaces/YOUR_SERVICE_BUS_NAMESPACE\",instance_name=\"INSTANCE_NAME\",entity_name=\"YOUR_SERVICE_BUS_QUEUE\"} 0 1612952581417","title":"Verifying the scraped output in Promitor"},{"location":"walkthroughs/use-promitor-with-managed-identity/#cleaning-up","text":"To delete all the resources used in this tutorial, run az group delete --name $RG_NAME . \u2190 back","title":"Cleaning up"},{"location":"tags/","text":"Tags \u00b6 Following is a list of relevant tags: API \u00b6 Azure API Management Azure App Plan Automation \u00b6 Azure Automation account Caching \u00b6 Azure Cache for Redis Azure Cache for Redis Enterprise Containers \u00b6 Azure Container Instances Azure Container Registry Azure Kubernetes Service Data \u00b6 Azure Blob Storage Azure Cosmos DB Azure Data Factory Azure Data Share Azure File Storage Azure Log Analytics Azure Database for MariaDB Azure Database for MySQL Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Storage Queue Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) IaaS \u00b6 Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Integration \u00b6 Azure API Management Azure Data Factory Azure Logic Apps Azure Service Bus Namespace IoT \u00b6 Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Kubernetes \u00b6 Azure Kubernetes Service Messaging \u00b6 Azure Event Hubs Azure Service Bus Namespace Monitoring \u00b6 Azure Application Insights Azure Monitor Autoscale Networking \u00b6 Azure Application Gateway Azure Express Route Circuit Azure Front Door Azure Load Balancer Azure Network Gateway Azure Network Interface Azure Virtual Network Open Source \u00b6 Azure Cosmos DB Azure Event Hubs Azure Kubernetes Service Azure Database for MariaDB Azure Database for MySQL Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise PaaS \u00b6 Azure API Management Azure App Plan Azure Data Factory Azure Function App Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Logic Apps Azure SQL Database Azure SQL Elastic Pool Azure Web App Resource Discovery \u00b6 Azure API Management Azure App Plan Azure Application Gateway Azure Application Insights Azure Automation account Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Event Hubs Azure Express Route Circuit Azure File Storage Azure Front Door Azure Function App Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Logic Apps Azure Database for MariaDB Azure Monitor Autoscale Azure Database for MySQL Azure Network Gateway Azure Network Interface Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Azure Virtual Network Azure Web App SQL \u00b6 Azure Cosmos DB Azure Database for MySQL Azure Database for PostgreSQL Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Scraper \u00b6 Azure API Management Azure App Plan Azure Application Gateway Azure Application Insights Azure Automation account Azure Blob Storage Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Event Hubs Azure Express Route Circuit Azure File Storage Azure Front Door Azure Function App Generic Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Log Analytics Azure Logic Apps Azure Database for MariaDB Azure Monitor Autoscale Azure Database for MySQL Azure Network Gateway Azure Network Interface Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Storage Queue Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Azure Virtual Network Azure Web App Security \u00b6 Azure Key Vault Serverless \u00b6 Azure Function App Storage \u00b6 Azure Blob Storage Azure File Storage Azure Storage Account Azure Storage Queue Synapse \u00b6 Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Web \u00b6 Azure App Plan","title":"Tags"},{"location":"tags/#tags","text":"Following is a list of relevant tags:","title":"Tags"},{"location":"tags/#api","text":"Azure API Management Azure App Plan","title":"API"},{"location":"tags/#automation","text":"Azure Automation account","title":"Automation"},{"location":"tags/#caching","text":"Azure Cache for Redis Azure Cache for Redis Enterprise","title":"Caching"},{"location":"tags/#containers","text":"Azure Container Instances Azure Container Registry Azure Kubernetes Service","title":"Containers"},{"location":"tags/#data","text":"Azure Blob Storage Azure Cosmos DB Azure Data Factory Azure Data Share Azure File Storage Azure Log Analytics Azure Database for MariaDB Azure Database for MySQL Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Storage Queue Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace)","title":"Data"},{"location":"tags/#iaas","text":"Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM)","title":"IaaS"},{"location":"tags/#integration","text":"Azure API Management Azure Data Factory Azure Logic Apps Azure Service Bus Namespace","title":"Integration"},{"location":"tags/#iot","text":"Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub","title":"IoT"},{"location":"tags/#kubernetes","text":"Azure Kubernetes Service","title":"Kubernetes"},{"location":"tags/#messaging","text":"Azure Event Hubs Azure Service Bus Namespace","title":"Messaging"},{"location":"tags/#monitoring","text":"Azure Application Insights Azure Monitor Autoscale","title":"Monitoring"},{"location":"tags/#networking","text":"Azure Application Gateway Azure Express Route Circuit Azure Front Door Azure Load Balancer Azure Network Gateway Azure Network Interface Azure Virtual Network","title":"Networking"},{"location":"tags/#open-source","text":"Azure Cosmos DB Azure Event Hubs Azure Kubernetes Service Azure Database for MariaDB Azure Database for MySQL Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise","title":"Open Source"},{"location":"tags/#paas","text":"Azure API Management Azure App Plan Azure Data Factory Azure Function App Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Logic Apps Azure SQL Database Azure SQL Elastic Pool Azure Web App","title":"PaaS"},{"location":"tags/#resource-discovery","text":"Azure API Management Azure App Plan Azure Application Gateway Azure Application Insights Azure Automation account Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Event Hubs Azure Express Route Circuit Azure File Storage Azure Front Door Azure Function App Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Logic Apps Azure Database for MariaDB Azure Monitor Autoscale Azure Database for MySQL Azure Network Gateway Azure Network Interface Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Azure Virtual Network Azure Web App","title":"Resource Discovery"},{"location":"tags/#sql","text":"Azure Cosmos DB Azure Database for MySQL Azure Database for PostgreSQL Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server","title":"SQL"},{"location":"tags/#scraper","text":"Azure API Management Azure App Plan Azure Application Gateway Azure Application Insights Azure Automation account Azure Blob Storage Azure Content Delivery Network (CDN) Azure Container Instances Azure Container Registry Azure Cosmos DB Azure Data Factory Azure Data Share Azure Event Hubs Azure Express Route Circuit Azure File Storage Azure Front Door Azure Function App Generic Azure IoT Hub Device Provisioning Service (DPS) Azure IoT Hub Azure Key Vault Azure Kubernetes Service Azure Load Balancer Azure Log Analytics Azure Logic Apps Azure Database for MariaDB Azure Monitor Autoscale Azure Database for MySQL Azure Network Gateway Azure Network Interface Azure Database for PostgreSQL Azure Cache for Redis Azure Cache for Redis Enterprise Azure Service Bus Namespace Azure SQL Database Azure SQL Elastic Pool Azure SQL Managed Instance Azure SQL Server Azure Storage Account Azure Storage Queue Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace) Azure Virtual Machine Scale Set (VMSS) Azure Virtual Machine (VM) Azure Virtual Network Azure Web App","title":"Scraper"},{"location":"tags/#security","text":"Azure Key Vault","title":"Security"},{"location":"tags/#serverless","text":"Azure Function App","title":"Serverless"},{"location":"tags/#storage","text":"Azure Blob Storage Azure File Storage Azure Storage Account Azure Storage Queue","title":"Storage"},{"location":"tags/#synapse","text":"Azure Synapse (Apache Spark pool) Azure Synapse (SQL pool) Azure Synapse (Workspace)","title":"Synapse"},{"location":"tags/#web","text":"Azure App Plan","title":"Web"}]}